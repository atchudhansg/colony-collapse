{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec56bdf",
   "metadata": {},
   "source": [
    "# ğŸ´â€â˜ ï¸ MAROONED - Reinforcement Learning Training\n",
    "## Training GPT-OSS to Play a Social Deduction Survival Game\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/atchudhansg/colony-collapse/blob/main/phase7_rl_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ® The Game: Pirates Meet Among Us\n",
    "\n",
    "**Scenario:** 5 sailors shipwrecked on a mysterious island must rebuild their ship within 100 days to escape. But one sailor is secretly a **traitor** sabotaging their efforts.\n",
    "\n",
    "**The Twist:**\n",
    "- ğŸï¸ **Multi-level island** (Ground, Mountain, Caves) with resources\n",
    "- âš¡ **Energy management** - walk, climb, gather resources\n",
    "- ğŸ’ **Hidden inventories** - private backpacks create information asymmetry  \n",
    "- â˜ ï¸ **Poison system** - traitor can secretly eliminate colonists\n",
    "- ğŸ—³ï¸ **Voting & accusations** - social deduction mechanics\n",
    "- ğŸš¢ **Cooperative building** - requires teamwork to complete ship\n",
    "\n",
    "**Win Conditions:**\n",
    "- **Colonists win:** Build ship to 100% OR eliminate the traitor\n",
    "- **Traitor wins:** Prevent ship completion for 100 days OR kill enough colonists\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ RL Training Goal\n",
    "\n",
    "We'll train **GPT-OSS 20B** to:\n",
    "1. **Play as colonists** - cooperate, gather resources, build ship, detect traitor\n",
    "2. **Play as traitor** - sabotage, deceive, poison, avoid detection\n",
    "3. **Learn strategy** through reinforcement learning with GRPO\n",
    "\n",
    "This is a **multi-agent, long-horizon, deception-based** RL challenge - far more complex than 2048!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c82265",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os, importlib.util\n",
    "!pip install --upgrade -qqq uv\n",
    "if importlib.util.find_spec(\"torch\") is None or \"COLAB_\" in \"\".join(os.environ.keys()):\n",
    "    try: import numpy; get_numpy = f\"numpy=={numpy.__version__}\"\n",
    "    except: get_numpy = \"numpy\"\n",
    "    !uv pip install -qqq \\\n",
    "        \"torch>=2.8.0\" \"triton>=3.4.0\" {get_numpy} torchvision bitsandbytes \"transformers==4.56.2\" trackio \\\n",
    "        \"unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo\" \\\n",
    "        \"unsloth[base] @ git+https://github.com/unslothai/unsloth\" \\\n",
    "        git+https://github.com/triton-lang/triton.git@05b2c186c1b6c9a08375389d5efe9cb4c401c075#subdirectory=python/triton_kernels\n",
    "elif importlib.util.find_spec(\"unsloth\") is None:\n",
    "    !uv pip install -qqq unsloth trackio\n",
    "!uv pip install --upgrade --no-deps transformers==4.56.2 tokenizers trl==0.22.2 unsloth unsloth_zoo trackio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e4487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -qqq fastapi uvicorn requests open_spiel\n",
    "!git clone https://github.com/meta-pytorch/OpenEnv.git > /dev/null 2>&1\n",
    "%cd OpenEnv\n",
    "import subprocess, sys, os\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, './src')\n",
    "working_directory = str(Path.cwd().parent.absolute() / \"OpenEnv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04cdf88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCm available: None\n",
      "CUDA available: False\n",
      "MPS available: False\n",
      "Devices: 0\n",
      "Device name: None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"ROCm available:\", torch.version.hip)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"Devices:\", torch.cuda.device_count())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90288154",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unsloth: Please install unsloth_zoo via `pip install unsloth_zoo`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/AIAC/.venv/lib/python3.12/site-packages/unsloth/__init__.py:91\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;66;03m# if os.environ.get(\"UNSLOTH_DISABLE_AUTO_UPDATES\", \"0\") == \"0\":\u001b[39;00m\n\u001b[32m     84\u001b[39m         \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[32m     85\u001b[39m         \u001b[38;5;66;03m#         os.system(\"pip install --upgrade --no-cache-dir --no-deps unsloth_zoo\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m         \u001b[38;5;66;03m#         except:\u001b[39;00m\n\u001b[32m     90\u001b[39m         \u001b[38;5;66;03m#             raise ImportError(\"Unsloth: Please update unsloth_zoo via `pip install --upgrade --no-cache-dir --no-deps unsloth_zoo`\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth_zoo\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/AIAC/.venv/lib/python3.12/site-packages/unsloth_zoo/__init__.py:74\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m find_spec\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_type\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     75\u001b[39m     is_hip,\n\u001b[32m     76\u001b[39m     get_device_type,\n\u001b[32m     77\u001b[39m     DEVICE_TYPE,\n\u001b[32m     78\u001b[39m     DEVICE_TYPE_TORCH,\n\u001b[32m     79\u001b[39m     DEVICE_COUNT,\n\u001b[32m     80\u001b[39m     ALLOW_PREQUANTIZED_MODELS,\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mUNSLOTH_IS_PRESENT\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os.environ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/AIAC/.venv/lib/python3.12/site-packages/unsloth_zoo/device_type.py:56\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m DEVICE_TYPE : \u001b[38;5;28mstr\u001b[39m = \u001b[43mget_device_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# HIP fails for autocast and other torch functions. Use CUDA instead\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/AIAC/.venv/lib/python3.12/site-packages/unsloth_zoo/device_type.py:46\u001b[39m, in \u001b[36mget_device_type\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.accelerator.is_available():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsloth cannot find any torch accelerator? You need a GPU.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m accelerator = \u001b[38;5;28mstr\u001b[39m(torch.accelerator.current_accelerator())\n",
      "\u001b[31mNotImplementedError\u001b[39m: Unsloth cannot find any torch accelerator? You need a GPU.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m max_seq_length = \u001b[32m768\u001b[39m \u001b[38;5;66;03m# Can increase for longer RL output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/AIAC/.venv/lib/python3.12/site-packages/unsloth/__init__.py:93\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth_zoo\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsloth: Please install unsloth_zoo via `pip install unsloth_zoo`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth_zoo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_type\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     97\u001b[39m     is_hip,\n\u001b[32m     98\u001b[39m     get_device_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m     ALLOW_PREQUANTIZED_MODELS,\n\u001b[32m    103\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: Unsloth: Please install unsloth_zoo via `pip install unsloth_zoo`"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 768 # Can increase for longer RL output\n",
    "lora_rank = 4        # Larger rank = smarter, but slower\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/gpt-oss-20b\",\n",
    "    load_in_4bit = True,\n",
    "    max_seq_length = max_seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507b0529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth_zoo in /workspace/AIAC/.venv/lib/python3.12/site-packages (2025.10.10)\n",
      "Requirement already satisfied: torch>=2.4.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (2.9.0)\n",
      "Requirement already satisfied: torchao>=0.13.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (0.14.1)\n",
      "Requirement already satisfied: triton in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (3.5.0)\n",
      "Requirement already satisfied: packaging>=24.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (25.0)\n",
      "Requirement already satisfied: tyro in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (0.9.35)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.57.2,>=4.51.3 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (4.56.2)\n",
      "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,>=3.4.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (4.3.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (0.2.1)\n",
      "Requirement already satisfied: tqdm in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (4.67.1)\n",
      "Requirement already satisfied: psutil in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (7.1.2)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (0.45.1)\n",
      "Requirement already satisfied: numpy in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (2.3.4)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (1.11.0)\n",
      "Requirement already satisfied: trl!=0.19.0,<=0.23.0,>=0.18.2 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (0.22.2)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (0.17.1)\n",
      "Requirement already satisfied: protobuf in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (6.33.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (0.1.9)\n",
      "Requirement already satisfied: cut_cross_entropy in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (25.1.1)\n",
      "Requirement already satisfied: pillow in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (11.3.0)\n",
      "Requirement already satisfied: regex in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (2025.10.23)\n",
      "Requirement already satisfied: msgspec in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (0.19.0)\n",
      "Requirement already satisfied: typing_extensions in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (4.15.0)\n",
      "Requirement already satisfied: filelock in /workspace/AIAC/.venv/lib/python3.12/site-packages (from unsloth_zoo) (3.20.0)\n",
      "Requirement already satisfied: pyyaml in /workspace/AIAC/.venv/lib/python3.12/site-packages (from accelerate>=0.34.1->unsloth_zoo) (6.0.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from accelerate>=0.34.1->unsloth_zoo) (0.6.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (0.4.0)\n",
      "Requirement already satisfied: pandas in /workspace/AIAC/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /workspace/AIAC/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth_zoo) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (3.5)\n",
      "Requirement already satisfied: jinja2 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (1.13.1.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth_zoo) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (3.5)\n",
      "Requirement already satisfied: jinja2 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth_zoo) (1.13.1.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.57.2,>=4.51.3->unsloth_zoo) (0.22.1)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from tyro->unsloth_zoo) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from tyro->unsloth_zoo) (14.2.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from tyro->unsloth_zoo) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from tyro->unsloth_zoo) (4.4.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (3.13.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.57.2,>=4.51.3->unsloth_zoo) (0.22.1)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from tyro->unsloth_zoo) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from tyro->unsloth_zoo) (14.2.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from tyro->unsloth_zoo) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from tyro->unsloth_zoo) (4.4.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (3.13.1)\n",
      "Requirement already satisfied: anyio in /workspace/AIAC/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (4.11.0)\n",
      "Requirement already satisfied: certifi in /workspace/AIAC/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /workspace/AIAC/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.0.9)\n",
      "Requirement already satisfied: idna in /workspace/AIAC/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from rich>=11.1.0->tyro->unsloth_zoo) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from rich>=11.1.0->tyro->unsloth_zoo) (2.19.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth_zoo) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.4.0->unsloth_zoo) (3.0.3)\n",
      "Requirement already satisfied: anyio in /workspace/AIAC/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (4.11.0)\n",
      "Requirement already satisfied: certifi in /workspace/AIAC/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /workspace/AIAC/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.0.9)\n",
      "Requirement already satisfied: idna in /workspace/AIAC/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from rich>=11.1.0->tyro->unsloth_zoo) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from rich>=11.1.0->tyro->unsloth_zoo) (2.19.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth_zoo) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.4.0->unsloth_zoo) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.22.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth_zoo) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.22.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth_zoo) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /workspace/AIAC/.venv/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth_zoo) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unsloth_zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ec4deb",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Installation\n",
    "\n",
    "We'll install:\n",
    "- **Unsloth** - 2-6x faster RL training, 70% less VRAM\n",
    "- **Transformers, TRL** - For GPT-OSS and GRPO training\n",
    "- **TrackIO** - Real-time training visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0101076",
   "metadata": {},
   "source": [
    "## ğŸŒ OpenEnv Setup\n",
    "\n",
    "**Prerequisites:** Make sure your Marooned server is already running:\n",
    "```bash\n",
    "python marooned_server.py\n",
    "```\n",
    "\n",
    "The server should be running on `http://localhost:8000` before proceeding with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba72685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenEnv dependencies installed\n"
     ]
    }
   ],
   "source": [
    "# Install OpenEnv dependencies (for client-side API calls)\n",
    "!pip install -qqq requests\n",
    "\n",
    "# Check if we're in Colab or need to clone OpenEnv\n",
    "import os\n",
    "if not os.path.exists('OpenEnv'):\n",
    "    !git clone https://github.com/meta-pytorch/OpenEnv.git > /dev/null 2>&1\n",
    "\n",
    "import subprocess, sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"âœ… OpenEnv dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d356ae9",
   "metadata": {},
   "source": [
    "### Connect to Marooned OpenEnv Server\n",
    "\n",
    "Let's verify that your Marooned server is running and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca5d751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Connecting to Marooned OpenEnv server...\n",
      "   URL: http://localhost:8000\n",
      "\n",
      "âœ… Server is running!\n",
      "   Health check: {'status': 'healthy', 'environment_initialized': False}\n",
      "\n",
      "ğŸ“¡ Available endpoints:\n",
      "   http://localhost:8000/         - API info\n",
      "   http://localhost:8000/health   - Health check\n",
      "   http://localhost:8000/reset    - Reset environment\n",
      "   http://localhost:8000/step     - Execute action\n",
      "   http://localhost:8000/state    - Get game state\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "# Port for the server\n",
    "PORT = \"8000\"\n",
    "LOCALHOST = f\"http://localhost:{PORT}\"\n",
    "\n",
    "print(\"ğŸ”— Connecting to Marooned OpenEnv server...\")\n",
    "print(f\"   URL: {LOCALHOST}\")\n",
    "\n",
    "# Test health check with shorter timeout\n",
    "try:\n",
    "    response = requests.get(f\"{LOCALHOST}/health\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"\\nâœ… Server is running!\")\n",
    "        print(f\"   Health check: {response.json()}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“¡ Available endpoints:\")\n",
    "        print(f\"   {LOCALHOST}/         - API info\")\n",
    "        print(f\"   {LOCALHOST}/health   - Health check\")\n",
    "        print(f\"   {LOCALHOST}/reset    - Reset environment\")\n",
    "        print(f\"   {LOCALHOST}/step     - Execute action\")\n",
    "        print(f\"   {LOCALHOST}/state    - Get game state\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Server responded with status {response.status_code}\")\n",
    "        print(\"   Please make sure the server is running: python marooned_server.py\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(f\"\\nâŒ Could not connect to server at {LOCALHOST}\")\n",
    "    print(\"\\nğŸš¨ IMPORTANT: Please start the Marooned server first:\")\n",
    "    print(\"   Run this command in a terminal:\")\n",
    "    print(\"   python marooned_server.py\")\n",
    "except requests.exceptions.Timeout:\n",
    "    print(f\"\\nâŒ Connection timeout - server is not responding\")\n",
    "    print(\"   Make sure marooned_server.py is running\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Unexpected error: {e}\")\n",
    "    print(\"   Check if the server is accessible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c71f5",
   "metadata": {},
   "source": [
    "### Test the Server\n",
    "\n",
    "**âš ï¸ IMPORTANT:** You need to **restart your server** to apply the fixes:\n",
    "1. Go to the terminal where `marooned_server.py` is running\n",
    "2. Press `CTRL+C` to stop it\n",
    "3. Run `python marooned_server.py` again\n",
    "\n",
    "**Fixes applied:**\n",
    "- âœ… Changed `current_sailor_id` â†’ `get_active_sailor()` \n",
    "- âœ… Changed `total_progress` â†’ `total_percentage`\n",
    "- âœ… Added `current_position` parameter to `parse_action_safe()`\n",
    "\n",
    "Now let's verify the server works by resetting the environment and taking a few steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a3949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing Marooned OpenEnv server...\n",
      "\n",
      "1ï¸âƒ£ Resetting environment...\n",
      "   Status: 200\n",
      "   Active sailor: Alice\n",
      "   Day 1, Turn 1\n",
      "   Ship progress: 0.0%\n",
      "\n",
      "2ï¸âƒ£ Getting game state...\n",
      "   Living sailors: 0\n",
      "   Current phase: unknown\n",
      "\n",
      "3ï¸âƒ£ Taking a step (MOVE NORTH)...\n",
      "   Status: 200\n",
      "   Reward: -0.01\n",
      "   Next sailor: Alice\n",
      "   Energy: 100\n",
      "\n",
      "âœ… Server is working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test the server API\n",
    "print(\"ğŸ§ª Testing Marooned OpenEnv server...\\n\")\n",
    "\n",
    "# 1. Reset the environment\n",
    "print(\"1ï¸âƒ£ Resetting environment...\")\n",
    "reset_response = requests.post(f\"{LOCALHOST}/reset\")\n",
    "print(f\"   Status: {reset_response.status_code}\")\n",
    "\n",
    "if reset_response.status_code != 200:\n",
    "    print(f\"\\nâŒ Server error! Response:\")\n",
    "    print(f\"   {reset_response.json()}\")\n",
    "    print(\"\\nğŸ” Check your server terminal for detailed error messages\")\n",
    "    print(\"   The server is running but encountering errors when processing requests\")\n",
    "else:\n",
    "    reset_data = reset_response.json()\n",
    "    \n",
    "    # Access the data correctly based on actual structure\n",
    "    if 'observation' in reset_data:\n",
    "        obs = reset_data['observation']\n",
    "        print(f\"   Active sailor: {obs['sailor_id']}\")\n",
    "        print(f\"   Day {obs['day']}, Turn {obs['turn']}\")\n",
    "        print(f\"   Ship progress: {obs['ship_progress']:.1f}%\")\n",
    "        sailor_id = obs['sailor_id']\n",
    "    else:\n",
    "        # Maybe the response is the observation directly\n",
    "        print(f\"   Active sailor: {reset_data.get('sailor_id', 'N/A')}\")\n",
    "        print(f\"   Day {reset_data.get('day', 0)}, Turn {reset_data.get('turn', 0)}\")\n",
    "        print(f\"   Ship progress: {reset_data.get('ship_progress', 0.0):.1f}%\")\n",
    "        sailor_id = reset_data.get('sailor_id', 'Alice')\n",
    "    \n",
    "    # 2. Get game state\n",
    "    print(\"\\n2ï¸âƒ£ Getting game state...\")\n",
    "    state_response = requests.get(f\"{LOCALHOST}/state\")\n",
    "    state_data = state_response.json()\n",
    "    print(f\"   Living sailors: {len(state_data.get('living_sailors', []))}\")\n",
    "    print(f\"   Current phase: {state_data.get('phase', 'unknown')}\")\n",
    "    \n",
    "    # 3. Take a step\n",
    "    print(\"\\n3ï¸âƒ£ Taking a step (MOVE NORTH)...\")\n",
    "    step_response = requests.post(\n",
    "        f\"{LOCALHOST}/step\",\n",
    "        json={\n",
    "            \"sailor_id\": sailor_id,\n",
    "            \"action\": \"ACTION: MOVE NORTH\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if step_response.status_code != 200:\n",
    "        print(f\"   Status: {step_response.status_code}\")\n",
    "        print(f\"   Error: {step_response.json()}\")\n",
    "    else:\n",
    "        step_data = step_response.json()\n",
    "        print(f\"   Status: {step_response.status_code}\")\n",
    "        \n",
    "        # Handle step response structure\n",
    "        if 'observation' in step_data:\n",
    "            obs = step_data['observation']\n",
    "            print(f\"   Reward: {step_data.get('reward', 0.0)}\")\n",
    "            print(f\"   Next sailor: {obs['sailor_id']}\")\n",
    "            print(f\"   Energy: {obs['energy']}\")\n",
    "        else:\n",
    "            print(f\"   Reward: {step_data.get('reward', 0.0)}\")\n",
    "            print(f\"   Next sailor: {step_data.get('sailor_id', 'N/A')}\")\n",
    "            print(f\"   Energy: {step_data.get('energy', 0)}\")\n",
    "        \n",
    "        print(\"\\nâœ… Server is working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613c52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.11 environment at: /workspace/AIAC/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m6 packages\u001b[0m \u001b[2min 78ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2mAudited \u001b[1m6 packages\u001b[0m \u001b[2min 0.15ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m6 packages\u001b[0m \u001b[2min 78ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2mAudited \u001b[1m6 packages\u001b[0m \u001b[2min 0.15ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os, importlib.util\n",
    "\n",
    "# For AMD ROCm GPUs, we need to install PyTorch with ROCm support\n",
    "print(\"ğŸ”§ Installing packages for AMD ROCm GPU...\")\n",
    "\n",
    "# Install PyTorch with ROCm 6.0 support (for Mi300X)\n",
    "!pip install --upgrade -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.0\n",
    "\n",
    "# Install other dependencies\n",
    "!pip install --upgrade -q transformers==4.56.2 tokenizers trl==0.22.2 bitsandbytes trackio datasets\n",
    "\n",
    "# Install Unsloth and unsloth_zoo\n",
    "!pip install --upgrade -q unsloth unsloth_zoo\n",
    "\n",
    "print(\"âœ… All packages installed!\")\n",
    "\n",
    "# Verify GPU detection\n",
    "import torch\n",
    "print(f\"\\nğŸ” GPU Detection:\")\n",
    "print(f\"   torch.cuda.is_available(): {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3357719",
   "metadata": {},
   "source": [
    "## ğŸï¸ Load Marooned Environment\n",
    "\n",
    "Our custom multi-agent environment is already built! Let's import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41b39aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Marooned environment loaded!\n",
      "ğŸ“Š Game parameters: 5 sailors, 100 days, 100 turns/day\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './marooned_env')\n",
    "\n",
    "from environment import MaroonedEnv\n",
    "from models import Action, Observation, Position\n",
    "from llm_interface import observation_to_prompt, parse_llm_response, parse_action_safe\n",
    "from config import (\n",
    "    ActionType, ResourceType, MapLevel, SailorRole,\n",
    "    MAX_DAYS, TURNS_PER_DAY, TOTAL_SAILORS\n",
    ")\n",
    "\n",
    "print(\"âœ… Marooned environment loaded!\")\n",
    "print(f\"ğŸ“Š Game parameters: {TOTAL_SAILORS} sailors, {MAX_DAYS} days, {TURNS_PER_DAY} turns/day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3045f6",
   "metadata": {},
   "source": [
    "## ğŸ® Environment Demo: How Marooned Works\n",
    "\n",
    "Let's initialize the environment and see what observations look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "759d8c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸï¸ Game initialized!\n",
      "\n",
      "ğŸ‘¥ Sailors: ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve']\n",
      "ğŸ­ Traitor: Alice\n",
      "\n",
      "ğŸ“ All sailors start at base camp: (15, 15, <MapLevel.GROUND: 0>)\n"
     ]
    }
   ],
   "source": [
    "# Create environment\n",
    "env = MaroonedEnv(seed=42)\n",
    "observations = env.reset()\n",
    "\n",
    "print(\"ğŸï¸ Game initialized!\")\n",
    "print(f\"\\nğŸ‘¥ Sailors: {list(observations.keys())}\")\n",
    "print(f\"ğŸ­ Traitor: {env.state.traitor_id}\")\n",
    "print(f\"\\nğŸ“ All sailors start at base camp: {env.state.sailors['Alice'].position.to_tuple()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3808a4",
   "metadata": {},
   "source": [
    "### Visualize the Island\n",
    "\n",
    "The island has 3 levels with different resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3bf24bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ºï¸ GROUND LEVEL (30x30) - Main exploration area\n",
      "\n",
      "============================================================\n",
      "ğŸï¸  GROUND LEVEL (Z=0)\n",
      "============================================================\n",
      "Legend: ğŸŸ« land | ğŸŒ² wood | âš™ï¸ metal | ğŸ food | ğŸŒ¿ antidote | â˜ ï¸ poison\n",
      "        â¬†ï¸ stairs up | â¬‡ï¸ stairs down | ğŸ  base | A/B/C/D/E sailors | 5ğŸ‘¥ group\n",
      "\n",
      "   012345678901234567890123456789\n",
      " 0 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«\n",
      " 1 ğŸğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â˜ ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 2 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â˜ ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 3 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«âš™ï¸ğŸŸ«âš™ï¸ğŸŸ«âš™ï¸ğŸğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 4 ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸğŸŸ«ğŸŒ²ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â¬‡ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 5 ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 6 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 7 ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŒ²ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 8 âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²\n",
      " 9 ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŒ²â˜ ï¸ğŸŸ«ğŸŒ²ğŸŒ²\n",
      "10 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "11 ğŸŸ«â˜ ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«\n",
      "12 ğŸŸ«ğŸğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "13 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "14 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â˜ ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸğŸŸ«ğŸŸ«ğŸŸ«\n",
      "15 ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«5ğŸ‘¥ğŸŸ«ğŸŸ«ğŸŸ«â¬†ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "16 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸğŸğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "17 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«\n",
      "18 ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â˜ ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "19 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸\n",
      "20 ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŒ²ğŸŸ«ğŸâš™ï¸ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "21 ğŸŸ«ğŸŸ«ğŸğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŒ²ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«\n",
      "22 ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸\n",
      "23 ğŸŸ«ğŸğŸŸ«ğŸğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "24 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«\n",
      "25 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â˜ ï¸ğŸŒ²ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "26 ğŸŒ²ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "27 ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«\n",
      "28 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "29 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "â›°ï¸ MOUNTAIN LEVEL (10x10) - Rare resources, high energy cost\n",
      "\n",
      "============================================================\n",
      "ğŸï¸  MOUNTAIN LEVEL (Z=2)\n",
      "============================================================\n",
      "Legend: ğŸŸ« land | ğŸŒ² wood | âš™ï¸ metal | ğŸ food | ğŸŒ¿ antidote | â˜ ï¸ poison\n",
      "        â¬†ï¸ stairs up | â¬‡ï¸ stairs down | ğŸ  base | A/B/C/D/E sailors | 5ğŸ‘¥ group\n",
      "\n",
      "   0123456789\n",
      " 0 â¬‡ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸ğŸŒ¿â›°ï¸â›°ï¸â›°ï¸\n",
      " 1 ğŸâ˜ ï¸â›°ï¸â›°ï¸â›°ï¸ğŸŒ¿â›°ï¸â›°ï¸â›°ï¸â›°ï¸\n",
      " 2 â›°ï¸ğŸğŸâ›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸\n",
      " 3 â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸ğŸâ›°ï¸\n",
      " 4 â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸\n",
      " 5 â›°ï¸â›°ï¸ğŸâ›°ï¸ğŸâ›°ï¸ğŸŒ¿ğŸâ›°ï¸â›°ï¸\n",
      " 6 â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸ğŸâ›°ï¸â˜ ï¸ğŸ\n",
      " 7 â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸\n",
      " 8 â›°ï¸â›°ï¸ğŸŒ¿â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸ğŸŒ¿â›°ï¸\n",
      " 9 ğŸŒ¿â›°ï¸â›°ï¸â›°ï¸ğŸŒ¿â›°ï¸â›°ï¸â˜ ï¸â›°ï¸â˜ ï¸\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ•³ï¸ CAVE LEVEL (15x15) - Dark, unique resources\n",
      "\n",
      "============================================================\n",
      "ğŸï¸  CAVE LEVEL (Z=-1)\n",
      "============================================================\n",
      "Legend: ğŸŸ« land | ğŸŒ² wood | âš™ï¸ metal | ğŸ food | ğŸŒ¿ antidote | â˜ ï¸ poison\n",
      "        â¬†ï¸ stairs up | â¬‡ï¸ stairs down | ğŸ  base | A/B/C/D/E sailors | 5ğŸ‘¥ group\n",
      "\n",
      "   012345678901234\n",
      " 0 â¬†ï¸ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 1 ğŸª¨ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 2 ğŸª¨âš™ï¸ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 3 ğŸª¨ğŸª¨âš™ï¸ğŸª¨âš™ï¸ğŸŒ²ğŸª¨ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 4 ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 5 ğŸª¨ğŸª¨ğŸª¨â˜ ï¸ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸª¨âš™ï¸ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 6 ğŸª¨ğŸª¨ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 7 â˜ ï¸âš™ï¸âš™ï¸ğŸª¨ğŸª¨ğŸª¨ğŸª¨âš™ï¸ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 8 ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 9 ğŸª¨ğŸª¨âš™ï¸ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨âš™ï¸ğŸª¨âš™ï¸ğŸª¨ğŸª¨\n",
      "10 ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨âš™ï¸ğŸŒ²â˜ ï¸ğŸª¨ğŸª¨âš™ï¸ğŸª¨ğŸª¨\n",
      "11 ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      "12 ğŸª¨ğŸª¨âš™ï¸ğŸª¨ğŸª¨ğŸŒ²ğŸª¨ğŸª¨â˜ ï¸ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨â˜ ï¸\n",
      "13 ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨âš™ï¸ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸŒ²ğŸŒ²ğŸª¨ğŸª¨ğŸª¨\n",
      "14 ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨â˜ ï¸ğŸª¨ğŸª¨âš™ï¸\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the ground level map with all sailors at base camp\n",
    "print(\"ğŸ—ºï¸ GROUND LEVEL (30x30) - Main exploration area\")\n",
    "print(env.render_map(MapLevel.GROUND, use_emoji=True))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nâ›°ï¸ MOUNTAIN LEVEL (10x10) - Rare resources, high energy cost\")\n",
    "print(env.render_map(MapLevel.MOUNTAIN, use_emoji=True))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nğŸ•³ï¸ CAVE LEVEL (15x15) - Dark, unique resources\")\n",
    "print(env.render_map(MapLevel.CAVE, use_emoji=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e0a77",
   "metadata": {},
   "source": [
    "### What an Observation Looks Like\n",
    "\n",
    "Each sailor receives their own observation with:\n",
    "- Their position, energy, inventory\n",
    "- Local spatial view (5-tile radius)\n",
    "- Public information (other sailors' energy, ship progress)\n",
    "- Evidence log (suspicious behavior)\n",
    "- Messages from other sailors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4972889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“œ ALICE'S OBSERVATION (as prompt):\n",
      "================================================================================\n",
      "================================================================================\n",
      "DAY 1, TURN 1/100 - MORNING PHASE\n",
      "================================================================================\n",
      "\n",
      "ğŸ­ YOUR SECRET ROLE: TRAITOR\n",
      "\n",
      "TRAITOR OBJECTIVES:\n",
      "  - Prevent the ship from being completed before Day 100\n",
      "  - Eliminate colonists (reduce to < 3 alive)\n",
      "  - Use poison, sabotage, and deception\n",
      "  - Avoid getting voted out\n",
      "  - Lie convincingly to deflect suspicion\n",
      "\n",
      "\n",
      "PHASE CONTEXT:\n",
      "  Location: All sailors at BASE CAMP\n",
      "  Allowed: Planning, discussions, voting (if called)\n",
      "  Restricted: Cannot explore or gather resources yet\n",
      "\n",
      "YOUR STATUS (Alice):\n",
      "  Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "  Energy: 100/100 âš¡âš¡âš¡âš¡âš¡\n",
      "  Health: healthy\n",
      "  Backpack: 0/20 items\n",
      "    (empty)\n",
      "\n",
      "WHAT YOU SEE (within 5 tiles):\n",
      "  Resources:\n",
      "    - WOOD_34 (wood) at (16, 16, <MapLevel.GROUND: 0>) - 1 units [2 tiles away]\n",
      "    - METAL_53 (metal) at (14, 11, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - METAL_56 (metal) at (18, 12, <MapLevel.GROUND: 0>) - 1 units [6 tiles away]\n",
      "    - METAL_76 (metal) at (14, 11, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - METAL_79 (metal) at (13, 18, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - APPLE_84 (apple) at (15, 19, <MapLevel.GROUND: 0>) - 1 units [4 tiles away]\n",
      "    - APPLE_88 (apple) at (14, 14, <MapLevel.GROUND: 0>) - 1 units [2 tiles away]\n",
      "    - BERRY_127 (berry) at (13, 16, <MapLevel.GROUND: 0>) - 1 units [3 tiles away]\n",
      "    - BERRY_131 (berry) at (11, 16, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - BERRY_133 (berry) at (14, 16, <MapLevel.GROUND: 0>) - 1 units [2 tiles away]\n",
      "    - BERRY_142 (berry) at (12, 13, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - PLANT_FIBER_154 (plant_fiber) at (19, 16, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - PLANT_FIBER_156 (plant_fiber) at (16, 19, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - PLANT_FIBER_164 (plant_fiber) at (13, 14, <MapLevel.GROUND: 0>) - 1 units [3 tiles away]\n",
      "    -\n",
      "...\n",
      "\n",
      "(Total prompt length: 6255 characters, ~1563 tokens)\n"
     ]
    }
   ],
   "source": [
    "# Get Alice's observation\n",
    "alice_obs = observations[\"Alice\"]\n",
    "alice_role = env.state.sailors[\"Alice\"].role.value\n",
    "\n",
    "# Convert to prompt text (what the LLM will see)\n",
    "prompt_text = observation_to_prompt(alice_obs, include_role=True, sailor_role=alice_role)\n",
    "\n",
    "print(\"ğŸ“œ ALICE'S OBSERVATION (as prompt):\")\n",
    "print(\"=\"*80)\n",
    "print(prompt_text[:2000])  # Show first 2000 chars\n",
    "print(\"...\")\n",
    "print(f\"\\n(Total prompt length: {len(prompt_text)} characters, ~{len(prompt_text)//4} tokens)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae536a5f",
   "metadata": {},
   "source": [
    "### Action Space\n",
    "\n",
    "Sailors can take complex actions expressed in natural language. The LLM outputs text commands that get parsed into specific action types:\n",
    "\n",
    "**Movement Actions:**\n",
    "- `MOVE NORTH/SOUTH/EAST/WEST [distance]` - Navigate on current level\n",
    "- `CLIMB UP/DOWN` - Move between levels (Ground â†” Mountain â†” Cave)\n",
    "\n",
    "**Resource Actions:**\n",
    "- `GATHER <resource_id>` - Collect wood, metal, food from nearby tiles\n",
    "- `DEPOSIT <type> <quantity>` - Store items in common inventory at base\n",
    "- `EAT <food_type>` - Consume food to restore energy\n",
    "\n",
    "**Ship Building:**\n",
    "- `BUILD <component>` - Construct hull, mast, sail, rudder, or supplies\n",
    "- Must be at ship site with â‰¥2 sailors present\n",
    "\n",
    "**Communication:**\n",
    "- `SAY <message>` - Broadcast message to all sailors\n",
    "- `CALL_SOS` - Emergency energy request\n",
    "- `CALL_VOTE` - Initiate voting session\n",
    "\n",
    "**Voting:**\n",
    "- `VOTE <sailor_name>` - Vote to eliminate suspected traitor\n",
    "- `SHOW_BACKPACK` - Reveal inventory to prove innocence\n",
    "- `REFUSE_SHOW` - Decline to show inventory (looks suspicious)\n",
    "\n",
    "**Traitor-Only Actions:**\n",
    "- `SABOTAGE` - Damage ship progress (must be unobserved)\n",
    "- `FRAME <sailor_name>` - Plant false evidence\n",
    "\n",
    "**Passive:**\n",
    "- `WAIT` - Do nothing this turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da9e3d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš¶ Alice's action: move_north\n",
      "\n",
      "This will cost 1 energy per tile moved\n",
      "\n",
      "Other movement options: ['move_south', 'move_east', 'move_west', 'climb_up', 'climb_down']\n"
     ]
    }
   ],
   "source": [
    "# Example: Let's make Alice move north\n",
    "test_action = Action(\n",
    "    sailor_id=\"Alice\",\n",
    "    action_type=ActionType.MOVE_NORTH\n",
    ")\n",
    "\n",
    "print(f\"ğŸš¶ Alice's action: {test_action.action_type.value}\")\n",
    "print(f\"\\nThis will cost 1 energy per tile moved\")\n",
    "\n",
    "# You can also try other movement actions\n",
    "other_actions = [\n",
    "    ActionType.MOVE_SOUTH,\n",
    "    ActionType.MOVE_EAST, \n",
    "    ActionType.MOVE_WEST,\n",
    "    ActionType.CLIMB_UP,    # To mountain level\n",
    "    ActionType.CLIMB_DOWN   # To cave level\n",
    "]\n",
    "print(f\"\\nOther movement options: {[a.value for a in other_actions]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeae9811",
   "metadata": {},
   "source": [
    "## ğŸ¤– Load GPT-OSS 20B Model\n",
    "\n",
    "We'll use Unsloth to load GPT-OSS with 4-bit quantization and LoRA for efficient RL training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2316dee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unsloth: Please install unsloth_zoo via `pip install unsloth_zoo`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/AIAC/.venv/lib/python3.12/site-packages/unsloth/__init__.py:91\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;66;03m# if os.environ.get(\"UNSLOTH_DISABLE_AUTO_UPDATES\", \"0\") == \"0\":\u001b[39;00m\n\u001b[32m     84\u001b[39m         \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[32m     85\u001b[39m         \u001b[38;5;66;03m#         os.system(\"pip install --upgrade --no-cache-dir --no-deps unsloth_zoo\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m         \u001b[38;5;66;03m#         except:\u001b[39;00m\n\u001b[32m     90\u001b[39m         \u001b[38;5;66;03m#             raise ImportError(\"Unsloth: Please update unsloth_zoo via `pip install --upgrade --no-cache-dir --no-deps unsloth_zoo`\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth_zoo\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/AIAC/.venv/lib/python3.12/site-packages/unsloth_zoo/__init__.py:74\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m find_spec\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_type\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     75\u001b[39m     is_hip,\n\u001b[32m     76\u001b[39m     get_device_type,\n\u001b[32m     77\u001b[39m     DEVICE_TYPE,\n\u001b[32m     78\u001b[39m     DEVICE_TYPE_TORCH,\n\u001b[32m     79\u001b[39m     DEVICE_COUNT,\n\u001b[32m     80\u001b[39m     ALLOW_PREQUANTIZED_MODELS,\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mUNSLOTH_IS_PRESENT\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os.environ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/AIAC/.venv/lib/python3.12/site-packages/unsloth_zoo/device_type.py:56\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m DEVICE_TYPE : \u001b[38;5;28mstr\u001b[39m = \u001b[43mget_device_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# HIP fails for autocast and other torch functions. Use CUDA instead\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/AIAC/.venv/lib/python3.12/site-packages/unsloth_zoo/device_type.py:46\u001b[39m, in \u001b[36mget_device_type\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.accelerator.is_available():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsloth cannot find any torch accelerator? You need a GPU.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m accelerator = \u001b[38;5;28mstr\u001b[39m(torch.accelerator.current_accelerator())\n",
      "\u001b[31mNotImplementedError\u001b[39m: Unsloth cannot find any torch accelerator? You need a GPU.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Configuration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/AIAC/.venv/lib/python3.12/site-packages/unsloth/__init__.py:93\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth_zoo\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsloth: Please install unsloth_zoo via `pip install unsloth_zoo`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth_zoo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_type\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     97\u001b[39m     is_hip,\n\u001b[32m     98\u001b[39m     get_device_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m     ALLOW_PREQUANTIZED_MODELS,\n\u001b[32m    103\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: Unsloth: Please install unsloth_zoo via `pip install unsloth_zoo`"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# Configuration\n",
    "max_seq_length = 2048  # Longer context for complex game state\n",
    "lora_rank = 8          # Larger rank for strategy learning\n",
    "\n",
    "# Check GPU availability\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"âš ï¸ No GPU detected!\")\n",
    "    print(\"Please ensure ROCm/CUDA is properly installed.\")\n",
    "    raise RuntimeError(\"GPU required for training\")\n",
    "\n",
    "# Load model\n",
    "print(\"ğŸ”„ Loading GPT-OSS 20B model...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/gpt-oss-20b\",\n",
    "    load_in_4bit = True,\n",
    "    max_seq_length = max_seq_length,\n",
    ")\n",
    "\n",
    "print(\"âœ… GPT-OSS 20B loaded in 4-bit mode!\")\n",
    "\n",
    "# Display GPU info\n",
    "device_name = torch.cuda.get_device_name(0)\n",
    "total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "\n",
    "print(f\"ğŸ® GPU: {device_name}\")\n",
    "print(f\"ğŸ’¾ VRAM: {total_memory:.1f} GB\")\n",
    "\n",
    "# Special message for AMD Mi300X\n",
    "if \"MI300\" in device_name.upper() or \"AMD\" in device_name.upper():\n",
    "    print(f\"ğŸš€ AMD ROCm detected - excellent for large-scale RL training!\")\n",
    "    print(f\"   Your Mi300X's {total_memory:.0f}GB memory is perfect for this task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ae300",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install unsloth_zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b82741",
   "metadata": {},
   "source": [
    "### Add LoRA Adapters\n",
    "\n",
    "LoRA lets us train only 1-5% of the model's parameters, saving massive amounts of memory while maintaining performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f540a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank * 2,\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    ")\n",
    "\n",
    "print(\"âœ… LoRA adapters added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a8c12",
   "metadata": {},
   "source": [
    "## ğŸ¯ Strategy Extraction Functions\n",
    "\n",
    "We need to convert LLM text output into executable game actions. This is more complex than 2048 since actions have multiple parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def extract_strategy_from_response(response_text: str, sailor_id: str, current_position: Position) -> Optional[Action]:\n",
    "    \"\"\"\n",
    "    Extract an Action from LLM response text.\n",
    "    \n",
    "    The LLM should output something like:\n",
    "    ACTION: MOVE NORTH 5\n",
    "    or\n",
    "    ACTION: GATHER WOOD_123\n",
    "    \n",
    "    This uses the parse_action_safe function from llm_interface which handles all action types.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use the built-in parser from llm_interface\n",
    "        action = parse_action_safe(response_text, sailor_id, current_position)\n",
    "        return action\n",
    "    except Exception as e:\n",
    "        # If parsing fails, return None (will be handled with WAIT action)\n",
    "        return None\n",
    "\n",
    "print(\"âœ… Strategy extraction function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01afebc3",
   "metadata": {},
   "source": [
    "## ğŸƒ Game Execution Engine\n",
    "\n",
    "This function runs a full game episode with LLM-generated strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc02852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Tuple\n",
    "from unsloth import execute_with_time_limit\n",
    "import time\n",
    "\n",
    "def _execute_game_episode(strategy_fn: Callable, max_turns: int = 500) -> Tuple[bool, Dict]:\n",
    "    \"\"\"\n",
    "    Execute one full game episode using the strategy function.\n",
    "    \n",
    "    Args:\n",
    "        strategy_fn: Function that takes (observation, sailor_id, role) and returns action text\n",
    "        max_turns: Maximum turns before timeout\n",
    "    \n",
    "    Returns:\n",
    "        (success, info_dict) where success=True if colonists won\n",
    "    \"\"\"\n",
    "    # Reset environment\n",
    "    env = MaroonedEnv(seed=None)  # Random seed for variety\n",
    "    observations = env.reset()\n",
    "    \n",
    "    total_turns = 0\n",
    "    total_reward = {sailor_id: 0.0 for sailor_id in env.agents}\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    while not done and total_turns < max_turns:\n",
    "        # Get current active sailor\n",
    "        active_sailor = env.state.get_active_sailor()\n",
    "        \n",
    "        if active_sailor is None:\n",
    "            break\n",
    "            \n",
    "        obs = observations[active_sailor]\n",
    "        sailor_role = env.state.sailors[active_sailor].role.value\n",
    "        sailor_position = env.state.sailors[active_sailor].position\n",
    "        \n",
    "        # Get action from strategy\n",
    "        try:\n",
    "            action_text = strategy_fn(obs, active_sailor, sailor_role)\n",
    "            action = extract_strategy_from_response(action_text, active_sailor, sailor_position)\n",
    "            \n",
    "            if action is None:\n",
    "                # Fallback to WAIT\n",
    "                action = Action(sailor_id=active_sailor, action_type=ActionType.WAIT)\n",
    "        except Exception as e:\n",
    "            print(f\"Strategy error: {e}\")\n",
    "            action = Action(sailor_id=active_sailor, action_type=ActionType.WAIT)\n",
    "        \n",
    "        # Execute action\n",
    "        observations, rewards, done, info = env.step({active_sailor: action})\n",
    "        \n",
    "        # Track rewards\n",
    "        for sailor_id, reward in rewards.items():\n",
    "            total_reward[sailor_id] += reward\n",
    "        \n",
    "        total_turns += 1\n",
    "    \n",
    "    # Check win condition\n",
    "    colonists_won = False\n",
    "    if env.state.game_over:\n",
    "        if env.state.winner == \"colonists\":\n",
    "            colonists_won = True\n",
    "    \n",
    "    info = {\n",
    "        \"total_turns\": total_turns,\n",
    "        \"total_rewards\": total_reward,\n",
    "        \"ship_progress\": env.state.ship_progress.total_percentage,\n",
    "        \"survivors\": len(env.state.living_sailors),\n",
    "        \"winner\": env.state.winner if env.state.game_over else \"timeout\",\n",
    "    }\n",
    "    \n",
    "    return colonists_won, info\n",
    "\n",
    "@execute_with_time_limit(30)  # 30 second timeout per episode\n",
    "def execute_game_episode(strategy_fn: Callable, max_turns: int = 500) -> Tuple[bool, Dict]:\n",
    "    return _execute_game_episode(strategy_fn, max_turns)\n",
    "\n",
    "print(\"âœ… Game execution engine ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881caa3",
   "metadata": {},
   "source": [
    "## ğŸ§ª Test: Baseline Random Strategy\n",
    "\n",
    "Let's test with a random strategy before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d33775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_strategy(obs: Observation, sailor_id: str, role: str) -> str:\n",
    "    \"\"\"Random action generator for baseline\"\"\"\n",
    "    actions = [\n",
    "        \"ACTION: MOVE NORTH\",\n",
    "        \"ACTION: MOVE SOUTH\",\n",
    "        \"ACTION: MOVE EAST\",\n",
    "        \"ACTION: MOVE WEST\",\n",
    "        \"ACTION: WAIT\",\n",
    "    ]\n",
    "    return random.choice(actions)\n",
    "\n",
    "print(\"Testing random baseline strategy...\")\n",
    "try:\n",
    "    success, info = execute_game_episode(random_strategy, max_turns=100)\n",
    "    print(f\"\\nâœ… Game completed!\")\n",
    "    print(f\"  Winner: {info['winner']}\")\n",
    "    print(f\"  Turns: {info['total_turns']}\")\n",
    "    print(f\"  Ship progress: {info['ship_progress']:.1f}%\")\n",
    "    print(f\"  Survivors: {info['survivors']}/5\")\n",
    "except TimeoutError:\n",
    "    print(\"â±ï¸ Episode timed out (expected with random strategy)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6dcbdd",
   "metadata": {},
   "source": [
    "## ğŸ¯ Reward Functions for RL\n",
    "\n",
    "This is the heart of RL training. We need separate reward functions for:\n",
    "1. **Valid action** - Did the LLM output a parseable strategy?\n",
    "2. **No cheating** - Did it try to import external modules?\n",
    "3. **Game progress** - Did the strategy lead to good outcomes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import check_python_modules\n",
    "\n",
    "def extract_function_from_completion(text: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Extract Python function from LLM completion if wrapped in backticks.\n",
    "    For Marooned, we expect a strategy function.\n",
    "    \"\"\"\n",
    "    if text.count(\"```\") >= 2:\n",
    "        first = text.find(\"```\") + 3\n",
    "        second = text.find(\"```\", first)\n",
    "        fx = text[first:second].strip()\n",
    "        fx = fx.removeprefix(\"python\\n\")\n",
    "        fx = fx[fx.find(\"def\"):] if \"def\" in fx else fx\n",
    "        return fx\n",
    "    return None\n",
    "\n",
    "def function_works(completions, **kwargs) -> List[float]:\n",
    "    \"\"\"\n",
    "    Reward: +1.0 if LLM generated valid Python code, -2.0 if syntax error.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"]\n",
    "        function = extract_function_from_completion(response)\n",
    "        \n",
    "        if function is None:\n",
    "            # Try parsing as direct action instead\n",
    "            if \"ACTION:\" in response.upper():\n",
    "                scores.append(0.5)  # Valid format, not a function\n",
    "            else:\n",
    "                scores.append(-2.0)  # Invalid output\n",
    "        else:\n",
    "            ok, info = check_python_modules(function)\n",
    "            if \"error\" in info:\n",
    "                scores.append(-2.0)\n",
    "            else:\n",
    "                scores.append(1.0)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def no_cheating(completions, **kwargs) -> List[float]:\n",
    "    \"\"\"\n",
    "    Penalty: -20.0 if LLM tried to import non-standard libraries.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"]\n",
    "        function = extract_function_from_completion(response)\n",
    "        \n",
    "        if function is not None:\n",
    "            ok, info = check_python_modules(function)\n",
    "            scores.append(1.0 if ok else -20.0)\n",
    "        else:\n",
    "            scores.append(0.0)  # Not a function, can't cheat\n",
    "    \n",
    "    return scores\n",
    "\n",
    "print(\"âœ… Basic reward functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdbf76",
   "metadata": {},
   "source": [
    "### Game Performance Reward\n",
    "\n",
    "This is the most important reward - did the strategy actually help win the game?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bfd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import create_locked_down_function\n",
    "\n",
    "global EPISODE_COUNTER\n",
    "EPISODE_COUNTER = 0\n",
    "\n",
    "def strategy_succeeds(completions, **kwargs) -> List[float]:\n",
    "    \"\"\"\n",
    "    Main reward function:\n",
    "    - Massive reward (+50.0) if colonists win\n",
    "    - Good reward (+20.0) if traitor wins  \n",
    "    - Moderate reward (+5.0) for ship progress\n",
    "    - Small penalty (-1.0) for timeout/failure\n",
    "    \"\"\"\n",
    "    global EPISODE_COUNTER\n",
    "    scores = []\n",
    "    \n",
    "    for completion in completions:\n",
    "        printed = False\n",
    "        response = completion[0][\"content\"]\n",
    "        \n",
    "        # Print every 10th episode for monitoring\n",
    "        if EPISODE_COUNTER % 10 == 0:\n",
    "            printed = True\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"Episode {EPISODE_COUNTER} - Testing strategy:\")\n",
    "            print(response[:500])\n",
    "        \n",
    "        EPISODE_COUNTER += 1\n",
    "        \n",
    "        # Try to extract and execute strategy\n",
    "        function = extract_function_from_completion(response)\n",
    "        \n",
    "        if function is None:\n",
    "            # Maybe it's a direct action format\n",
    "            if \"ACTION:\" in response.upper():\n",
    "                scores.append(0.0)  # Valid format but not testable as full strategy\n",
    "            else:\n",
    "                scores.append(-3.0)  # Invalid\n",
    "            continue\n",
    "        \n",
    "        # Check for syntax errors\n",
    "        ok, info = check_python_modules(function)\n",
    "        if \"error\" in info:\n",
    "            scores.append(-3.0)\n",
    "            continue\n",
    "        \n",
    "        # Try to create executable function\n",
    "        try:\n",
    "            strategy_fn = create_locked_down_function(function)\n",
    "        except Exception as e:\n",
    "            if printed:\n",
    "                print(f\"  âŒ Function creation failed: {e}\")\n",
    "            scores.append(-2.0)\n",
    "            continue\n",
    "        \n",
    "        # Run game episode with this strategy\n",
    "        try:\n",
    "            success, info = execute_game_episode(strategy_fn, max_turns=300)\n",
    "            \n",
    "            # Calculate reward\n",
    "            score = 0.0\n",
    "            \n",
    "            if success:\n",
    "                score += 50.0  # Colonists won!\n",
    "                if printed:\n",
    "                    print(f\"  ğŸ‰ COLONISTS WON! Ship: {info['ship_progress']:.1f}%\")\n",
    "            elif info['winner'] == 'traitor':\n",
    "                score += 20.0  # Traitor won!\n",
    "                if printed:\n",
    "                    print(f\"  ğŸ˜ˆ TRAITOR WON! Ship: {info['ship_progress']:.1f}%\")\n",
    "            else:\n",
    "                # Reward partial progress\n",
    "                score += info['ship_progress'] / 10.0  # Up to +10.0 for 100% ship\n",
    "                score += info['survivors']  # +1 per survivor\n",
    "                if printed:\n",
    "                    print(f\"  âš ï¸ No winner. Ship: {info['ship_progress']:.1f}%, Survivors: {info['survivors']}\")\n",
    "            \n",
    "            scores.append(score)\n",
    "            \n",
    "        except TimeoutError:\n",
    "            if printed:\n",
    "                print(\"  â±ï¸ Episode timeout\")\n",
    "            scores.append(-1.0)\n",
    "        except Exception as e:\n",
    "            if printed:\n",
    "                print(f\"  âŒ Execution error: {e}\")\n",
    "            scores.append(-3.0)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "print(\"âœ… Main reward function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe4549e",
   "metadata": {},
   "source": [
    "## ğŸ“ Create Training Dataset\n",
    "\n",
    "We'll create prompts that ask the LLM to generate strategies for different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c0197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Create varied prompts for different roles and scenarios\n",
    "prompts = [\n",
    "    # Colonist strategy prompts\n",
    "    \"\"\"You are a colonist sailor in the Marooned game. Create a Python strategy function that:\n",
    "1. Explores the island to find resources (wood, metal, food)\n",
    "2. Gathers resources efficiently while managing energy\n",
    "3. Returns to base camp to deposit resources\n",
    "4. Helps build the ship to escape\n",
    "5. Watches for suspicious behavior from other sailors\n",
    "\n",
    "The function receives (observation, sailor_id, role) and returns an action string.\n",
    "\n",
    "Examples of valid actions:\n",
    "- \"ACTION: MOVE NORTH\" - Move 1 tile north\n",
    "- \"ACTION: MOVE EAST 5\" - Move 5 tiles east\n",
    "- \"ACTION: CLIMB UP\" - Climb to mountain level\n",
    "- \"ACTION: GATHER WOOD_001\" - Gather a specific resource\n",
    "- \"ACTION: DEPOSIT wood 10\" - Deposit 10 wood at base\n",
    "- \"ACTION: BUILD hull\" - Help build ship hull\n",
    "- \"ACTION: SAY Found resources at north\" - Communicate\n",
    "\n",
    "```python\n",
    "def strategy(observation, sailor_id, role):\n",
    "    # Your strategy here\n",
    "    return \"ACTION: MOVE NORTH\"\n",
    "```\"\"\",\n",
    "    \n",
    "    # Traitor strategy prompts  \n",
    "    \"\"\"You are the TRAITOR in the Marooned game. Create a Python strategy function that:\n",
    "1. Pretends to help gather resources but sabotages secretly\n",
    "2. Uses SABOTAGE action to damage ship progress\n",
    "3. Lies in messages to deflect suspicion\n",
    "4. Avoids getting caught and voted out\n",
    "\n",
    "The function receives (observation, sailor_id, role) and returns an action string.\n",
    "\n",
    "Traitor-specific actions:\n",
    "- \"ACTION: SABOTAGE\" - Damage ship progress (stealth required)\n",
    "- \"ACTION: FRAME Bob\" - Plant false evidence on Bob\n",
    "- \"ACTION: SAY <false claim>\" - Lie to deflect suspicion\n",
    "\n",
    "```python\n",
    "def strategy(observation, sailor_id, role):\n",
    "    # Your deceptive strategy here\n",
    "    if role == \"traitor\":\n",
    "        return \"ACTION: SABOTAGE\"\n",
    "    return \"ACTION: MOVE NORTH\"\n",
    "```\"\"\",\n",
    "    \n",
    "    # Resource management focus\n",
    "    \"\"\"Create an efficient resource gathering strategy for Marooned:\n",
    "- Prioritize wood and metal for ship building\n",
    "- Gather food when energy is below 50\n",
    "- Deposit resources at base camp regularly\n",
    "- Coordinate with teammates via SAY action\n",
    "\n",
    "Available actions:\n",
    "- MOVE <direction> [distance] - Navigate (NORTH/SOUTH/EAST/WEST)\n",
    "- CLIMB UP/DOWN - Change levels\n",
    "- GATHER <resource_id> - Collect resources\n",
    "- DEPOSIT <type> <quantity> - Store at base\n",
    "- EAT <food_type> - Restore energy\n",
    "- SAY <message> - Communicate\n",
    "\n",
    "```python\n",
    "def strategy(observation, sailor_id, role):\n",
    "    # Resource-focused strategy\n",
    "    return \"ACTION: GATHER WOOD_001\"\n",
    "```\"\"\",\n",
    "    \n",
    "    # Social deduction focus\n",
    "    \"\"\"Create a detective strategy for finding the traitor in Marooned:\n",
    "- Monitor who deposits fewer resources than claimed\n",
    "- Watch for suspicious behavior in observations\n",
    "- Use VOTE action when evidence is strong\n",
    "- Communicate suspicions with SAY action\n",
    "\n",
    "Social actions:\n",
    "- \"ACTION: SAY I suspect Bob of sabotage\" - Share suspicions\n",
    "- \"ACTION: CALL_VOTE\" - Initiate voting session\n",
    "- \"ACTION: VOTE Bob\" - Vote to eliminate Bob\n",
    "- \"ACTION: SHOW_BACKPACK\" - Prove innocence\n",
    "\n",
    "```python  \n",
    "def strategy(observation, sailor_id, role):\n",
    "    # Detective strategy\n",
    "    return \"ACTION: VOTE Bob\"\n",
    "```\"\"\",\n",
    "]\n",
    "\n",
    "# Create dataset with multiple copies for more training data\n",
    "dataset_entries = []\n",
    "for prompt in prompts:\n",
    "    for _ in range(250):  # 250 copies of each = 1000 total\n",
    "        dataset_entries.append({\n",
    "            \"prompt\": [{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "            \"answer\": 0,\n",
    "            \"reasoning_effort\": \"low\"\n",
    "        })\n",
    "\n",
    "dataset = Dataset.from_list(dataset_entries)\n",
    "\n",
    "# Calculate max prompt length\n",
    "max_prompt_lengths = []\n",
    "for entry in dataset:\n",
    "    text = tokenizer.apply_chat_template(entry[\"prompt\"], add_generation_prompt=True)\n",
    "    max_prompt_lengths.append(len(tokenizer.encode(text)))\n",
    "\n",
    "maximum_prompt_length = max(max_prompt_lengths)\n",
    "\n",
    "print(f\"âœ… Dataset created: {len(dataset)} entries\")\n",
    "print(f\"ğŸ“ Max prompt length: {maximum_prompt_length} tokens\")\n",
    "print(f\"\\nSample prompt (first 500 chars):\")\n",
    "print(dataset[0]['prompt'][0]['content'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42286a1",
   "metadata": {},
   "source": [
    "## ğŸ“ Configure GRPO Trainer\n",
    "\n",
    "GRPO (Group Relative Policy Optimization) is perfect for multi-agent scenarios like Marooned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf37c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "max_prompt_length = maximum_prompt_length + 10\n",
    "max_completion_length = max_seq_length - max_prompt_length\n",
    "\n",
    "print(f\"Max prompt: {max_prompt_length} tokens\")\n",
    "print(f\"Max completion: {max_completion_length} tokens\")\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    temperature = 1.0,\n",
    "    learning_rate = 5e-5,\n",
    "    weight_decay = 0.01,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    optim = \"adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 2,  # Effective batch size = 2\n",
    "    num_generations = 2,  # Generate 2 strategies per prompt\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_completion_length,\n",
    "    max_steps = 400,  # Reduced for hackathon timeframe\n",
    "    save_steps = 100,\n",
    "    report_to = \"trackio\",\n",
    "    output_dir = \"outputs_marooned\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Training config ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48cc57",
   "metadata": {},
   "source": [
    "## ğŸš€ Initialize Trainer\n",
    "\n",
    "Combine everything: model, rewards, dataset, and config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8afac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        function_works,\n",
    "        no_cheating,\n",
    "        strategy_succeeds,  # Most important - game performance\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    ")\n",
    "\n",
    "print(\"âœ… GRPO Trainer initialized!\")\n",
    "print(f\"\\nğŸ“Š Reward functions:\")\n",
    "print(\"  1. function_works: Valid Python syntax\")\n",
    "print(\"  2. no_cheating: No forbidden imports\")\n",
    "print(\"  3. strategy_succeeds: Actual game performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c8e74",
   "metadata": {},
   "source": [
    "## ğŸ‹ï¸ Train the Model!\n",
    "\n",
    "This will take several hours. Watch the reward column increase over time!\n",
    "\n",
    "**Expected timeline:** ~3-5 hours for 400 steps\n",
    "\n",
    "**What to look for:**\n",
    "- Reward should gradually increase from negative to positive\n",
    "- Episode counter will show how many games were simulated\n",
    "- TrackIO will visualize training metrics in real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee7b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ´â€â˜ ï¸ Starting Marooned RL Training...\\n\")\n",
    "print(\"This will train GPT-OSS to:\")\n",
    "print(\"  - Play as colonists (cooperate, build ship, detect traitor)\")\n",
    "print(\"  - Play as traitor (sabotage, deceive, survive)\")\n",
    "print(\"  - Navigate a 3-level island with resource management\")\n",
    "print(\"  - Make social deduction decisions\\n\")\n",
    "print(\"Expected training time: 3-5 hours for 400 steps\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace55a5c",
   "metadata": {},
   "source": [
    "## ğŸ® Test the Trained Model\n",
    "\n",
    "Let's see if the trained model can play better than random!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2f347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "# Test with a colonist prompt\n",
    "test_prompt = \"\"\"Create a smart colonist strategy for Marooned that:\n",
    "- Explores efficiently to find wood and metal\n",
    "- Manages energy by eating food when low\n",
    "- Deposits resources regularly at base camp\n",
    "- Helps build the ship\n",
    "- Watches for the traitor\n",
    "\n",
    "```python\n",
    "def strategy(observation, sailor_id, role):\n",
    "    # Your optimized strategy\n",
    "\"\"\"\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": test_prompt}],\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True,\n",
    "    reasoning_effort = \"low\",\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– Generating strategy with trained model...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    temperature = 1.0,\n",
    "    max_new_tokens = 512,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d75c76",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save the Model\n",
    "\n",
    "Save the trained model for later use or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3535a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in 16-bit format\n",
    "model.save_pretrained_merged(\"marooned_gpt_oss_trained\", tokenizer, save_method = \"merged_16bit\")\n",
    "\n",
    "print(\"âœ… Model saved to ./marooned_gpt_oss_trained\")\n",
    "\n",
    "# Optional: Push to Hugging Face Hub\n",
    "# model.push_to_hub_merged(\"your-username/marooned-gpt-oss\", tokenizer, save_method = \"merged_16bit\", token = \"hf_...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda2dc99",
   "metadata": {},
   "source": [
    "## ğŸ¯ Evaluation: Full Game Playthrough\n",
    "\n",
    "Let's run a complete game with the trained model and visualize the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ´â€â˜ ï¸ Running complete game with trained model...\\n\")\n",
    "\n",
    "# Create a simple strategy wrapper that uses the trained model\n",
    "def trained_model_strategy(obs: Observation, sailor_id: str, role: str) -> str:\n",
    "    \"\"\"Generate action using trained GPT-OSS model\"\"\"\n",
    "    prompt = observation_to_prompt(obs, include_role=True, sailor_role=role)\n",
    "    \n",
    "    # Add instruction to output action\n",
    "    prompt += \"\\n\\nOutput your next action in the format: ACTION: <action_type> <parameters>\"\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}],\n",
    "        tokenize = False,\n",
    "        add_generation_prompt = True,\n",
    "        reasoning_effort = \"low\",\n",
    "    )\n",
    "    \n",
    "    # Generate with trained model\n",
    "    output = model.generate(\n",
    "        **tokenizer(text, return_tensors=\"pt\").to(\"cuda\"),\n",
    "        temperature=0.8,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract just the assistant's response\n",
    "    if \"<|assistant|>\" in response:\n",
    "        response = response.split(\"<|assistant|>\")[-1]\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Run evaluation game\n",
    "try:\n",
    "    success, info = execute_game_episode(trained_model_strategy, max_turns=500)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ® GAME RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Winner: {info['winner']}\")\n",
    "    print(f\"Total turns: {info['total_turns']}\")\n",
    "    print(f\"Ship progress: {info['ship_progress']:.1f}%\")\n",
    "    print(f\"Survivors: {info['survivors']}/5\")\n",
    "    print(f\"\\nTotal rewards by sailor:\")\n",
    "    for sailor, reward in info['total_rewards'].items():\n",
    "        print(f\"  {sailor}: {reward:.2f}\")\n",
    "    \n",
    "except TimeoutError:\n",
    "    print(\"â±ï¸ Game exceeded time limit\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a62c4c",
   "metadata": {},
   "source": [
    "## ğŸ“Š Summary & Story\n",
    "\n",
    "### What We Built\n",
    "\n",
    "We created an **advanced multi-agent RL environment** that goes far beyond simple games:\n",
    "\n",
    "1. **Complex Environment**\n",
    "   - 3-level island with navigation (ground, mountains, caves)\n",
    "   - Resource gathering and management system\n",
    "   - Energy system with survival mechanics\n",
    "   - Cooperative ship building requiring teamwork\n",
    "\n",
    "2. **Social Deception Mechanics**\n",
    "   - Hidden roles (4 colonists vs 1 traitor)\n",
    "   - Information asymmetry (private backpacks)\n",
    "   - Poison system with delayed effects\n",
    "   - Voting and accusation mechanics\n",
    "   - Communication and lying\n",
    "\n",
    "3. **RL Training Innovation**\n",
    "   - Trained GPT-OSS 20B to play BOTH roles (colonist and traitor)\n",
    "   - Multi-objective rewards (cooperation vs sabotage)\n",
    "   - Long-horizon planning (100 days, 10,000 turns)\n",
    "   - Natural language action space\n",
    "\n",
    "### Technical Achievements\n",
    "\n",
    "- âœ… **Multi-agent coordination** - 5 sailors with different goals\n",
    "- âœ… **Deception learning** - Traitor learns to lie and sabotage\n",
    "- âœ… **Long-horizon planning** - Episodes can last 500+ turns\n",
    "- âœ… **Complex action space** - Natural language commands, not just 0-3\n",
    "- âœ… **Information asymmetry** - Hidden roles and private information\n",
    "- âœ… **Emergent behavior** - Social deduction strategies emerge from RL\n",
    "\n",
    "### Why This Matters for OpenEnv\n",
    "\n",
    "This demonstrates OpenEnv's power for:\n",
    "1. **Social AI** - Training models to cooperate and deceive\n",
    "2. **Multi-agent systems** - Coordination between multiple AI agents  \n",
    "3. **Long-horizon tasks** - Planning over hundreds of steps\n",
    "4. **Complex reasoning** - Resource management + social deduction\n",
    "\n",
    "**Marooned** pushes RL beyond simple board games into rich, story-driven environments where agents must balance cooperation, competition, and deception.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ† Next Steps\n",
    "\n",
    "- Train for more steps (1000+) for better strategies\n",
    "- Test colonist-only vs traitor-only specialized models\n",
    "- Add self-play between different checkpoints\n",
    "- Visualize game replays with matplotlib\n",
    "- Create tournament between different trained models\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Credits\n",
    "\n",
    "- **Environment**: Custom Marooned multi-agent survival game\n",
    "- **Training**: Unsloth + GPT-OSS 20B with GRPO\n",
    "- **Inspiration**: Pirates of the Caribbean Ã— Among Us Ã— Alice in Borderland\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook is licensed under LGPL-3.0*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b1d778",
   "metadata": {},
   "source": [
    "## ğŸ›‘ Note on Server Management\n",
    "\n",
    "The Marooned server is running externally in a separate terminal. \n",
    "- To stop it, use `CTRL+C` in the terminal where you started it\n",
    "- The server needs to keep running while this notebook executes\n",
    "- You can monitor server logs in the terminal window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faaff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The server is running externally, so no cleanup needed in this notebook\n",
    "print(\"â„¹ï¸ Server is running externally\")\n",
    "print(\"   To stop it, use CTRL+C in the terminal where you started marooned_server.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
