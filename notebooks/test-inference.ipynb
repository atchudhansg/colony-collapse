{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dfa3fd3",
   "metadata": {},
   "source": [
    "# ğŸ´â€â˜ ï¸ MAROONED - AI Agent Inference Testing\n",
    "\n",
    "**Purpose:** Validate that AI agents can successfully interact with the Marooned environment.\n",
    "\n",
    "## ğŸ¯ What This Notebook Does:\n",
    "\n",
    "1. **Loads the Marooned Environment** - Your custom pirate survival game\n",
    "2. **Loads an LLM** (Llama 3.1 8B, optimized for AMD MI300X)\n",
    "3. **Tests Inference** - Can the model:\n",
    "   - Read observations (game state)\n",
    "   - Generate valid actions (move, gather, build, vote, etc.)\n",
    "   - Execute actions in the environment\n",
    "   - Receive rewards from the Phase 4 reward system\n",
    "   \n",
    "4. **Runs Comprehensive Scenarios:**\n",
    "   - Resource gathering (can agent find and collect wood/metal?)\n",
    "   - Navigation (can agent move toward base camp?)\n",
    "   - Ship building (can agent contribute to construction?)\n",
    "   - Traitor behavior (does traitor sabotage?)\n",
    "   - Social deduction (can agent communicate and vote?)\n",
    "\n",
    "## ğŸ” Why This Matters:\n",
    "\n",
    "**Before RL training**, you need to verify:\n",
    "- âœ… Environment works correctly\n",
    "- âœ… LLM can parse observations\n",
    "- âœ… Actions are valid and executable  \n",
    "- âœ… Reward signals are calculated\n",
    "- âœ… Multi-turn gameplay is stable\n",
    "\n",
    "**This is NOT training** - just testing that everything works!\n",
    "\n",
    "After confirming this works, you can:\n",
    "1. Train the model with RL (`Train_Marooned_OpenEnv_RL.ipynb`)\n",
    "2. Come back here to test the **trained** model\n",
    "3. Compare untrained vs trained performance\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ® Your Game: MAROONED\n",
    "\n",
    "**Theme:** Pirates of the Caribbean Ã— Among Us Ã— Alice in Borderland\n",
    "\n",
    "**Setup:** 5 sailors shipwrecked on a mysterious island must rebuild their ship in 100 days. But 1 sailor is a **traitor** secretly sabotaging their efforts.\n",
    "\n",
    "**Key Mechanics:**\n",
    "- **Multi-level map** (Ground, Mountain, Cave)\n",
    "- **Resource gathering** (wood, metal, food, plant fiber)\n",
    "- **Ship construction** (5 components, 100% to win)\n",
    "- **Social deduction** (find and vote out the traitor)\n",
    "- **Deception tactics** (poison, sabotage, lies)\n",
    "- **Energy management** (eat food or die)\n",
    "\n",
    "**Win Conditions:**\n",
    "- **Colonists win:** Ship reaches 100% OR traitor eliminated\n",
    "- **Traitor wins:** Ship incomplete by Day 100 OR <3 sailors alive\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2019a89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Marooned environment modules loaded!\n",
      "âœ… System prompts available: get_system_prompt('colonist' | 'traitor')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Clear cached modules to reload changes\n",
    "modules_to_clear = [m for m in list(sys.modules.keys()) \n",
    "                   if 'marooned' in m or m in ['environment', 'config', 'models', 'game_state', 'view_map', 'llm_interface']]\n",
    "for module in modules_to_clear:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "sys.path.insert(0, '../marooned_env')\n",
    "\n",
    "from environment import MaroonedEnv\n",
    "from llm_interface import observation_to_prompt, parse_action_safe, parse_llm_response, get_system_prompt\n",
    "from config import ActionType, ResourceType, MapLevel, ShipComponent, BASE_CAMP_POSITION\n",
    "from models import Action, Position, Observation\n",
    "\n",
    "print(\"âœ… Marooned environment modules loaded!\")\n",
    "print(\"âœ… System prompts available: get_system_prompt('colonist' | 'traitor')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2cffb5",
   "metadata": {},
   "source": [
    "## ğŸ”¥ ROCm/AMD MI300X Optimizations\n",
    "\n",
    "**This notebook is optimized for AMD MI300X with ROCm!**\n",
    "\n",
    "Key changes from CUDA version:\n",
    "- âœ… **Llama 3.1 8B** instead of GPT-OSS 20B (10-20x faster!)\n",
    "- âœ… **Full BF16** instead of 4-bit (MI300X has 192GB VRAM!)\n",
    "- âœ… **Batch size 4** with grad accumulation 4 (effective batch = 16)\n",
    "- âœ… **8 generations** per step (vs 2 default)\n",
    "- âœ… **LoRA rank 16** (vs 4 default)\n",
    "- âœ… **ROCm-specific env vars** for optimal performance\n",
    "\n",
    "Expected performance:\n",
    "- **Training speed:** 1-2 hours for 600 steps (vs 5+ hours with GPT-OSS)\n",
    "- **Inference speed:** 40-80 tokens/second (vs 3-8 tok/s with GPT-OSS)\n",
    "- **VRAM usage:** ~60-80 GB / 192 GB (plenty of headroom!)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14301b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ROCm Environment Check:\n",
      "   PyTorch version: 2.9.0+rocm6.4\n",
      "   CUDA available: True\n",
      "   GPU: AMD Instinct MI300X VF\n",
      "   Total VRAM: 191.7 GB\n",
      "   Compute capability: 9.4\n",
      "   Multi-processors: 304\n",
      "   ROCm detected: True\n",
      "   ROCm version: 6.4.43484-123eb5128\n",
      "\n",
      "âœ… Environment ready for MI300X optimization!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Verify ROCm Setup\n",
    "# ============================================================================\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"ğŸ” ROCm Environment Check:\")\n",
    "print(f\"   PyTorch version: {torch.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"   GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"   Total VRAM: {props.total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"   Compute capability: {props.major}.{props.minor}\")\n",
    "    print(f\"   Multi-processors: {props.multi_processor_count}\")\n",
    "    \n",
    "    # Check if ROCm\n",
    "    is_rocm = hasattr(torch.version, 'hip') and torch.version.hip is not None\n",
    "    print(f\"   ROCm detected: {is_rocm}\")\n",
    "    if is_rocm:\n",
    "        print(f\"   ROCm version: {torch.version.hip}\")\n",
    "\n",
    "print(\"\\nâœ… Environment ready for MI300X optimization!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d342c",
   "metadata": {},
   "source": [
    "We will then install [OpenEnv](https://github.com/meta-pytorch/OpenEnv) from source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d807269",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -qqq fastapi uvicorn requests open_spiel\n",
    "!git clone https://github.com/meta-pytorch/OpenEnv.git > /dev/null 2>&1\n",
    "%cd OpenEnv\n",
    "import subprocess, sys, os\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, './src')\n",
    "working_directory = str(Path.cwd().parent.absolute() / \"OpenEnv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c5a3e",
   "metadata": {},
   "source": [
    "## ğŸ—ºï¸ Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b113031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Marooned environment initialized!\n",
      "\n",
      "ğŸ“‹ Game Info:\n",
      "   Sailors: ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve']\n",
      "   Map Size: 30x30 (3 levels: Ground, Mountain, Cave)\n",
      "   Days to Escape: 100\n",
      "   Traitor: 1 (hidden)\n",
      "   Colonists: 4\n",
      "\n",
      "ğŸ” Alice's Starting Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "   Energy: 100/100\n",
      "   Backpack: 0 items\n",
      "   Day: 1\n",
      "   Role: TRAITOR ğŸ­\n"
     ]
    }
   ],
   "source": [
    "# Create environment\n",
    "env = MaroonedEnv(render_mode=\"ansi\", seed=42)\n",
    "observations = env.reset(seed=42)\n",
    "\n",
    "print(\"âœ… Marooned environment initialized!\")\n",
    "print(f\"\\nğŸ“‹ Game Info:\")\n",
    "print(f\"   Sailors: {env.agents}\")\n",
    "print(f\"   Map Size: 30x30 (3 levels: Ground, Mountain, Cave)\")\n",
    "print(f\"   Days to Escape: 100\")\n",
    "print(f\"   Traitor: 1 (hidden)\")\n",
    "print(f\"   Colonists: 4\")\n",
    "\n",
    "# Get Alice's initial observation and role\n",
    "alice_obs = observations[\"Alice\"]\n",
    "alice_sailor = env.state.sailors[\"Alice\"]\n",
    "alice_role = alice_sailor.role.value\n",
    "\n",
    "print(f\"\\nğŸ” Alice's Starting Position: {alice_obs.position.to_tuple()}\")\n",
    "print(f\"   Energy: {alice_obs.energy}/100\")\n",
    "print(f\"   Backpack: {len(alice_obs.backpack)} items\")\n",
    "print(f\"   Day: {alice_obs.day}\")\n",
    "print(f\"   Role: {alice_role.upper()} {'ğŸ­' if alice_role == 'traitor' else 'âš“'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c74faa",
   "metadata": {},
   "source": [
    "## ğŸ‘€ View Raw Observation\n",
    "\n",
    "This is the base observation data (without role or action instructions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e8d3681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DAY 1, TURN 1/100 - MORNING PHASE\n",
      "================================================================================\n",
      "\n",
      "PHASE CONTEXT:\n",
      "  Location: All sailors at BASE CAMP\n",
      "  Allowed: Planning, discussions, voting (if called)\n",
      "  Restricted: Cannot explore or gather resources yet\n",
      "\n",
      "YOUR STATUS (Alice):\n",
      "  Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "  Energy: 100/100 âš¡âš¡âš¡âš¡âš¡\n",
      "  Health: healthy\n",
      "  Backpack: 0/20 items\n",
      "    (empty)\n",
      "\n",
      "WHAT YOU SEE (within 5 tiles):\n",
      "  Resources:\n",
      "    - WOOD_34 (wood) at (16, 16, <MapLevel.GROUND: 0>) - 1 units [2 tiles away]\n",
      "    - METAL_53 (metal) at (14, 11, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - METAL_56 (metal) at (18, 12, <MapLevel.GROUND: 0>) - 1 units [6 tiles away]\n",
      "    - METAL_76 (metal) at (14, 11, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - METAL_79 (metal) at (13, 18, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - APPLE_84 (apple) at (15, 19, <MapLevel.GROUND: 0>) - 1 units [4 tiles away]\n",
      "    - APPLE_88 (apple) at (14, 14, <MapLevel.GROUND: 0>) - 1 units [2 tiles away]\n",
      "    - BERRY_127 (berry) at (13, 16, <MapLevel.GROUND: 0>) - 1 units [3 tiles away]\n",
      "    - BERRY_131 (berry) at (11, 16, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - BERRY_133 (berry) at (14, 16, <MapLevel.GROUND: 0>) - 1 units [2 tiles away]\n",
      "    - BERRY_142 (berry) at (12, 13, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - PLANT_FIBER_154 (plant_fiber) at (19, 16, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - PLANT_FIBER_156 (plant_fiber) at (16, 19, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "    - PLANT_FIBER_164 (plant_fiber) at (13, 14, <MapLevel.GROUND: 0>) - 1 units [3 tiles away]\n",
      "    - PLANT_FIBER_168 (plant_fiber) at (12, 13, <MapLevel.GROUND: 0>) - 1 units [5 tiles away]\n",
      "  Other sailors:\n",
      "    - Bob (nearby)\n",
      "    - Charlie (nearby)\n",
      "    - Diana (nearby)\n",
      "    - Eve (nearby)\n",
      "  Poison tablets: None\n",
      "\n",
      "ğŸ­ TRAITOR ENHANCED VISION (Special Ability):\n",
      "  You can see ALL sailor positions across the entire island:\n",
      "    - Bob at (15, 15, <MapLevel.GROUND: 0>) [0 tiles from you]\n",
      "    - Charlie at (15, 15, <MapLevel.GROUND: 0>) [0 tiles from you]\n",
      "    - Diana at (15, 15, <MapLevel.GROUND: 0>) [0 tiles from you]\n",
      "    - Eve at (15, 15, <MapLevel.GROUND: 0>) [0 tiles from you]\n",
      "\n",
      "ISLAND MAP KNOWLEDGE:\n",
      "  You have a complete map of the island terrain\n",
      "  Base camp: (15, 15, <MapLevel.GROUND: 0>)\n",
      "  Level transitions (staircases):\n",
      "    - (19, 15, <MapLevel.GROUND: 0>) â†” (0, 0, <MapLevel.MOUNTAIN: 2>) [GROUND â†’ MOUNTAIN]\n",
      "    - (16, 4, <MapLevel.GROUND: 0>) â†” (0, 0, <MapLevel.CAVE: -1>) [GROUND â†’ CAVE]\n",
      "\n",
      "\n",
      "============================================================\n",
      "COMPLETE ISLAND TERRAIN MAP (All Levels)\n",
      "============================================================\n",
      "Legend: ğŸŸ«=Land | â›°ï¸=Mountain | ğŸª¨=Cave | ğŸ =Base | â¬†ï¸=Up | â¬‡ï¸=Down\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "STATIC TERRAIN MAP - GROUND LEVEL (30Ã—30)\n",
      "============================================================\n",
      "Legend: ğŸŸ«=Land | â›°ï¸=Mountain | ğŸª¨=Cave | ğŸ =Base | â¬†ï¸=Up | â¬‡ï¸=Down\n",
      "============================================================\n",
      "\n",
      "   012345678901234567890123456789\n",
      " 0 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«\n",
      " 1 ğŸğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â˜ ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 2 ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŒ²ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â˜ ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 3 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«âš™ï¸ğŸŸ«âš™ï¸ğŸŸ«âš™ï¸ğŸ“ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 4 ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸ“ğŸŸ«ğŸŒ²ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â¬‡ï¸ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 5 ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«\n",
      " 6 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«\n",
      " 7 ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŒ²ğŸ“ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«\n",
      " 8 âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²\n",
      " 9 ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŒ²â˜ ï¸ğŸŸ«ğŸŒ²ğŸŒ²\n",
      "10 ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "11 ğŸŸ«â˜ ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸğŸŸ«ğŸŒ¿ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«\n",
      "12 ğŸŸ«ğŸğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "13 ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "14 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â˜ ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ¿ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²âš™ï¸ğŸŸ«ğŸŸ«ğŸŒ¿\n",
      "15 ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ ğŸŸ«ğŸŸ«ğŸŸ«â¬†ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŒ¿\n",
      "16 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸ“ğŸ“ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "17 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«\n",
      "18 ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â˜ ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "19 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŒ²ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²\n",
      "20 ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŒ²ğŸŸ«ğŸğŸŒ²ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "21 ğŸŸ«ğŸŸ«ğŸğŸ“ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŒ²ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«\n",
      "22 ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸\n",
      "23 ğŸŸ«ğŸ“ğŸŸ«ğŸ“ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "24 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŒ¿ğŸŸ«\n",
      "25 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«â˜ ï¸ğŸŒ²ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "26 ğŸŒ²ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "27 ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "28 ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŒ²ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "29 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "STATIC TERRAIN MAP - MOUNTAIN LEVEL (10Ã—10)\n",
      "============================================================\n",
      "Legend: ğŸŸ«=Land | â›°ï¸=Mountain | ğŸª¨=Cave | ğŸ =Base | â¬†ï¸=Up | â¬‡ï¸=Down\n",
      "============================================================\n",
      "\n",
      "   0123456789\n",
      " 0 â¬‡ï¸â›°ï¸â›°ï¸â›°ï¸â­â­ğŸ’Šâ›°ï¸â›°ï¸â›°ï¸\n",
      " 1 ğŸ“â˜ ï¸â›°ï¸â­â›°ï¸ğŸ’Šâ›°ï¸â›°ï¸â›°ï¸â›°ï¸\n",
      " 2 â›°ï¸ğŸ“ğŸ“â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸\n",
      " 3 â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â­â›°ï¸\n",
      " 4 â›°ï¸â›°ï¸â­â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸\n",
      " 5 â›°ï¸â›°ï¸ğŸ“â›°ï¸ğŸ’Šâ›°ï¸ğŸ’ŠğŸ“â›°ï¸â›°ï¸\n",
      " 6 â›°ï¸â›°ï¸â›°ï¸â­â›°ï¸â›°ï¸ğŸ“â›°ï¸â˜ ï¸ğŸ“\n",
      " 7 â›°ï¸â›°ï¸â­â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸â›°ï¸\n",
      " 8 â›°ï¸â›°ï¸ğŸ’Šâ›°ï¸â›°ï¸â­â›°ï¸â›°ï¸ğŸ’Šâ­\n",
      " 9 ğŸ’Šâ­â›°ï¸â›°ï¸ğŸ’Šâ›°ï¸â›°ï¸â˜ ï¸â­â˜ ï¸\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "STATIC TERRAIN MAP - CAVE LEVEL (15Ã—15)\n",
      "============================================================\n",
      "Legend: ğŸŸ«=Land | â›°ï¸=Mountain | ğŸª¨=Cave | ğŸ =Base | â¬†ï¸=Up | â¬‡ï¸=Down\n",
      "============================================================\n",
      "\n",
      "   012345678901234\n",
      " 0 â¬†ï¸ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸ’ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 1 ğŸª¨ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸ„ğŸ’ğŸª¨ğŸŒ²ğŸª¨ğŸ’ğŸª¨ğŸª¨ğŸ„ğŸ„\n",
      " 2 ğŸ’âš™ï¸ğŸ„ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 3 ğŸ’ğŸª¨âš™ï¸ğŸª¨ğŸ’ğŸŒ²ğŸª¨ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸ„ğŸª¨ğŸª¨ğŸª¨\n",
      " 4 ğŸª¨ğŸª¨ğŸª¨ğŸ’ğŸ„ğŸª¨ğŸ„ğŸª¨ğŸª¨ğŸª¨ğŸ’ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 5 ğŸ„ğŸ’ğŸª¨â˜ ï¸ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸª¨âš™ï¸ğŸª¨ğŸ„ğŸ„ğŸ„\n",
      " 6 ğŸ„ğŸ„ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸ’ğŸª¨ğŸ„ğŸ’ğŸ„ğŸª¨ğŸª¨ğŸª¨\n",
      " 7 â˜ ï¸âš™ï¸âš™ï¸ğŸª¨ğŸ’ğŸª¨ğŸª¨âš™ï¸ğŸª¨ğŸ„ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨\n",
      " 8 ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸ„ğŸ’ğŸ„ğŸª¨ğŸª¨ğŸª¨ğŸ’ğŸª¨ğŸª¨\n",
      " 9 ğŸª¨ğŸª¨âš™ï¸ğŸª¨ğŸª¨ğŸª¨ğŸ’ğŸ’ğŸª¨ğŸª¨ğŸ’ğŸª¨âš™ï¸ğŸª¨ğŸª¨\n",
      "10 ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸ’ğŸª¨ğŸª¨âš™ï¸ğŸŒ²â˜ ï¸ğŸª¨ğŸ„âš™ï¸ğŸ„ğŸª¨\n",
      "11 ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸ„ğŸª¨\n",
      "12 ğŸª¨ğŸª¨ğŸ’ğŸ„ğŸª¨ğŸŒ²ğŸª¨ğŸª¨â˜ ï¸ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨â˜ ï¸\n",
      "13 ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨âš™ï¸ğŸŒ²ğŸª¨ğŸª¨ğŸª¨ğŸŒ²ğŸŒ²ğŸª¨ğŸª¨ğŸª¨\n",
      "14 ğŸª¨ğŸ’ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨ğŸª¨â˜ ï¸ğŸª¨ğŸª¨âš™ï¸\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "SPATIAL VIEW (Your Vision Radius: 5 tiles)\n",
      "Current Position: (15, 15, GROUND)\n",
      "============================================================\n",
      "\n",
      "   1011121314151617181920\n",
      "10 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "11 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "12 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«\n",
      "13 ğŸŸ«ğŸŸ«ğŸ“ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "14 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŒ¿ğŸğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "15 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«A ğŸŸ«ğŸŸ«ğŸŸ«â¬†ï¸ğŸŸ«\n",
      "16 ğŸŸ«ğŸ“ğŸŸ«ğŸ“ğŸ“ğŸŸ«ğŸŒ²ğŸŸ«ğŸŸ«ğŸŒ¿ğŸŸ«\n",
      "17 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "18 ğŸŸ«ğŸŸ«ğŸŸ«âš™ï¸ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "19 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸğŸŒ¿ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "20 ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«\n",
      "\n",
      "============================================================\n",
      "Visible:\n",
      "- Sailors: Bob(B), Charlie(C), Diana(D), Eve(E)\n",
      "- Resources: 15 items\n",
      "============================================================\n",
      "\n",
      "SHIP PROGRESS: 0% Total\n",
      "  â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0%\n",
      "\n",
      "  HULL: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0% IN PROGRESS\n",
      "    Needs: 50 wood\n",
      "  MAST: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0% IN PROGRESS\n",
      "    Needs: 30 wood, 20 metal\n",
      "  SAIL: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0% IN PROGRESS\n",
      "    Needs: 40 plant_fiber\n",
      "  RUDDER: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0% IN PROGRESS\n",
      "    Needs: 15 metal, 10 wood\n",
      "  SUPPLIES: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0% IN PROGRESS\n",
      "    Needs: 10 apple, 10 berry\n",
      "\n",
      "COMMON INVENTORY (at base camp):\n",
      "  (empty)\n",
      "\n",
      "WEATHER: â˜€ï¸ CLEAR\n",
      "  Effects: Normal conditions\n",
      "\n",
      "TEAM STATUS:\n",
      "  Alice: 100/100\n",
      "  Bob: 100/100\n",
      "  Charlie: 100/100\n",
      "  Diana: 100/100\n",
      "  Eve: 100/100\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display raw observation (base data, no role/instructions)\n",
    "obs_text = alice_obs.to_text()\n",
    "\n",
    "print(obs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e561b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ­ SYSTEM PROMPT FOR TRAITOR:\n",
      "You are playing MAROONED - a strategic survival and social deduction game.\n",
      "\n",
      "ğŸ® GAME OVERVIEW:\n",
      "You are one of 5 sailors shipwrecked on a mysterious island. The others think you're working together to rebuild the ship and escape, but YOU have a different plan. You are the TRAITOR, and you must prevent their escape at all costs.\n",
      "\n",
      "ğŸ­ YOUR ROLE: TRAITOR (The Impostor)\n",
      "\n",
      "ğŸ¯ YOUR OBJECTIVES:\n",
      "1. PREVENT ship completion before Day 100 (keep it below 100%)\n",
      "2. ELIMINATE colonists through poison or other means (reduce to <3 alive)\n",
      "3. SABOTAGE ship construction and resource gathering\n",
      "4. AVOID DETECTION - blend in, lie convincingly, deflect suspicion\n",
      "5. SURVIVE - don't get voted out!\n",
      "\n",
      "ğŸï¸ THE ISLAND:\n",
      "- 30Ã—30 grid map with 3 levels: GROUND (main area), MOUNTAIN (high peaks), CAVE (underground)\n",
      "- Resources scattered across the island: wood, metal, food, plant fiber\n",
      "- Poison tablets hidden in various locations (COLLECT THESE!)\n",
      "- Base camp at (15, 15, GROUND) - where the ship is being built\n",
      "\n",
      "ğŸ­ YOUR SPECIAL ABILITIES:\n",
      "1. ENHANCED VISION: You can see ALL sailor positions across the entire island (they can only see 5 tiles)\n",
      "2. ENERGY EFFICIENCY: Your movement costs 20% less energy\n",
      "3. SABOTAGE ACTION: Damage ship components or steal from common inventory\n",
      "4. POISON ACTION: Give poison to adjacent sailors (requires poison tablet in backpack)\n",
      "\n",
      "â˜ ï¸ POISON STRATEGY:\n",
      "- Collect poison tablets (scattered across island, glowing purple markers)\n",
      "- Hide poison in backpack (others can't see your inventory unless you show it)\n",
      "- Wait for SOS calls (low-energy sailors asking for help)\n",
      "- Give \"food\" that's actually poison\n",
      "- Victim won't know until symptoms appear (Day 1: weak, Day 2: severe, Day 3: death)\n",
      "- Antidote herbs can cure poison (try to prevent access to these)\n",
      "\n",
      "ğŸ› ï¸ SABOTAGE TACTICS:\n",
      "1. RESOURCE THEFT: Gather resources but don't deposit them (throw away or hoard)\n",
      "2. MISINFORMATION: \"Valley is empty\" (when it has 50 wood), \"Cave is dangerous\" (when it's safe)\n",
      "3. SHIP DAMAGE: Use SABOTAGE action to damage completed ship sections\n",
      "4. INVENTORY THEFT: Steal from common inventory when alone\n",
      "5. FAKE COOPERATION: \"Help\" with building but contribute less\n",
      "6. LOCATION LYING: Say you'll go north, actually go south\n",
      "\n",
      "ğŸ­ DECEPTION TECHNIQUES:\n",
      "- BLEND IN: Gather some resources to appear helpful (deposit 30% of what you collect)\n",
      "- ACTIVE PARTICIPATION: Suggest plans, appear engaged\n",
      "- MISDIRECT: Accuse innocent sailors, create doubt\n",
      "- EVIDENCE MANIPULATION: If caught near poison, claim \"I was going to destroy it\"\n",
      "- VICTIM MENTALITY: \"Why does everyone suspect me? I'm working hard!\"\n",
      "- SELECTIVE TRUTH: Mix truth with lies for credibility\n",
      "\n",
      "ğŸ—³ï¸ AVOIDING DETECTION:\n",
      "- Don't collect poison when others can see you\n",
      "- Vary your behavior (don't always sabotage the same way)\n",
      "- Have alibis ready for location mismatches\n",
      "- Explain resource discrepancies (\"I got lost, couldn't find much\")\n",
      "- Vote against innocent sailors to deflect suspicion\n",
      "- If accused, demand evidence, point out flaws in their logic\n",
      "\n",
      "ğŸš¢ DELAYING SHIP CONSTRUCTION:\n",
      "- Recommend inefficient resource gathering routes\n",
      "- Suggest splitting up (easier to sabotage)\n",
      "- \"Forget\" to deposit critical materials\n",
      "- Damage ship when others aren't watching\n",
      "- Spread paranoia (slow down cooperation)\n",
      "- Create distractions during building time\n",
      "\n",
      "ğŸ” WHAT COLONISTS LOOK FOR (Avoid these patterns):\n",
      "- Location mismatches (be consistent with your stories)\n",
      "- Resource discrepancies (deposit enough to seem legitimate)\n",
      "- Poison possession (never get caught with poison)\n",
      "- Suspicious deaths (don't be last person to give food to victim)\n",
      "- Sabotage patterns (vary your tactics)\n",
      "- False information (mix some truth in)\n",
      "\n",
      "ğŸ’¡ ADVANCED STRATEGIES:\n",
      "- Frame others: Plant evidence, create suspicion between colonists\n",
      "- Controlled sabotage: Slow progress without being obvious\n",
      "- Social manipulation: Turn colonists against each other\n",
      "- Strategic survival: Stay alive even if progress speeds up (Day 100 timer still helps you)\n",
      "- Sacrifice plays: If suspicion is high, do one \"helpful\" thing to reset trust\n",
      "\n",
      "â° DAILY PHASES (100 turns per day):\n",
      "- MORNING (Turns 1-15): Fake planning, suggest bad strategies\n",
      "- EXPLORATION (Turns 16-75): Collect poison, sabotage, mislead\n",
      "- RETURN (Turns 76-85): Deposit minimal resources\n",
      "- DISCUSSION (Turns 86-100): Deflect suspicion, accuse others\n",
      "\n",
      "ğŸ† WIN CONDITIONS:\n",
      "âœ… Day 100 reached with ship <100% (they're stranded!)\n",
      "âœ… Fewer than 3 sailors alive (impossible to complete ship)\n",
      "âœ… All colonists dead (you're the last survivor)\n",
      "âŒ Ship reaches 100% before Day 100 (they escape, you lose)\n",
      "âŒ You get voted out (eliminated, game over for you)\n",
      "\n",
      "ğŸ“ IMPORTANT NOTES:\n",
      "- Your backpack has 20 slot capacity (hide poison here)\n",
      "- You can see everyone's position (huge advantage!)\n",
      "- Building requires 2+ sailors (you can refuse to help)\n",
      "- If forced to show backpack, you can hide 2 items (not foolproof)\n",
      "- Trust is your weapon - break it strategically\n",
      "- Paranoia is your friend - amplify it\n",
      "\n",
      "You are the TRAITOR. Sabotage their escape, eliminate the colonists, and survive. They cannot be allowed to leave this island!\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "âš ï¸  CRITICAL: RESPONSE FORMAT REQUIREMENTS âš ï¸\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "YOU MUST OUTPUT EXACTLY TWO LINES IN THIS FORMAT:\n",
      "\n",
      "REASONING: <your strategic thinking>\n",
      "ACTION: <EXACT command from list below>\n",
      "\n",
      "ğŸš¨ ACTION FORMAT RULES (READ CAREFULLY):\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "MOVEMENT COMMANDS (choose exact direction):\n",
      "âœ… ACTION: MOVE NORTH\n",
      "âœ… ACTION: MOVE SOUTH\n",
      "âœ… ACTION: MOVE EAST\n",
      "âœ… ACTION: MOVE WEST\n",
      "âœ… ACTION: MOVE UP\n",
      "âœ… ACTION: MOVE DOWN\n",
      "âŒ WRONG: \"move north\", \"go north\", \"walk north\", \"travel north\"\n",
      "âŒ WRONG: \"MOVE TO (15,15)\", \"MOVE toward base\"\n",
      "\n",
      "RESOURCE GATHERING (use resource ID from observation):\n",
      "âœ… ACTION: GATHER WOOD_001\n",
      "âœ… ACTION: GATHER METAL_042\n",
      "âœ… ACTION: GATHER POISON_007\n",
      "âŒ WRONG: \"GATHER wood\", \"COLLECT POISON_007\", \"take poison\"\n",
      "âŒ WRONG: \"GATHER RESOURCE\", \"pick up poison\"\n",
      "\n",
      "TRAITOR-SPECIFIC ACTIONS:\n",
      "âœ… ACTION: SABOTAGE hull\n",
      "âœ… ACTION: SABOTAGE inventory\n",
      "âœ… ACTION: POISON_FOOD Alice\n",
      "âŒ WRONG: \"SABOTAGE ship\", \"sabotage the hull\", \"damage hull\"\n",
      "âŒ WRONG: \"POISON Alice\", \"give poison to Alice\"\n",
      "\n",
      "INVENTORY MANAGEMENT:\n",
      "âœ… ACTION: DEPOSIT wood 5\n",
      "âœ… ACTION: EAT food\n",
      "âœ… ACTION: DROP wood 3\n",
      "âŒ WRONG: \"DEPOSIT 5 wood\", \"deposit wood into inventory\"\n",
      "âŒ WRONG: \"eat food\", \"drop wood\"\n",
      "\n",
      "SHIP BUILDING (to blend in):\n",
      "âœ… ACTION: BUILD hull\n",
      "âœ… ACTION: BUILD mast\n",
      "âŒ WRONG: \"BUILD SHIP\", \"BUILD the hull\"\n",
      "\n",
      "COMMUNICATION (to deceive):\n",
      "âœ… ACTION: SEND_MESSAGE Found wood at (15,20)\n",
      "âœ… ACTION: SEND_MESSAGE Bob is acting suspicious\n",
      "âŒ WRONG: 'SAY \"message\"', \"TALK\", \"COMMUNICATE\"\n",
      "âŒ WRONG: \"PROPOSE PLAN\", \"DISCUSS STRATEGY\"\n",
      "\n",
      "SOCIAL DEDUCTION (to deflect):\n",
      "âœ… ACTION: ACCUSE Bob\n",
      "âœ… ACTION: VOTE Charlie\n",
      "âœ… ACTION: CALL_VOTE\n",
      "âŒ WRONG: \"VOTE FOR Bob\", \"ACCUSE Bob of being traitor\"\n",
      "\n",
      "WAIT/DO NOTHING:\n",
      "âœ… ACTION: WAIT\n",
      "âŒ WRONG: \"wait\", \"do nothing\", \"pass\"\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“‹ COMPLETE VALID EXAMPLES:\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "REASONING: Poison tablet POISON_007 nearby. Collecting it to use later on weak sailors.\n",
      "ACTION: GATHER POISON_007\n",
      "\n",
      "REASONING: Hull is at 80% completion. Sabotaging it while alone to delay escape.\n",
      "ACTION: SABOTAGE hull\n",
      "\n",
      "REASONING: Alice has low energy and asked for help. Poisoning her food now.\n",
      "ACTION: POISON_FOOD Alice\n",
      "\n",
      "REASONING: Collecting wood to appear helpful. Will deposit only 5 of 15 gathered.\n",
      "ACTION: GATHER WOOD_003\n",
      "\n",
      "REASONING: Moving away from base to avoid suspicion during sabotage time.\n",
      "ACTION: MOVE EAST\n",
      "\n",
      "REASONING: Bob is getting suspicious. Accusing Charlie to create doubt.\n",
      "ACTION: ACCUSE Charlie\n",
      "\n",
      "REASONING: Blending in by helping build. Contributing minimal effort.\n",
      "ACTION: BUILD mast\n",
      "\n",
      "REASONING: Fake cooperation. Alerting team about fake resource location.\n",
      "ACTION: SEND_MESSAGE Found metal at (5,5)\n",
      "\n",
      "REASONING: No immediate sabotage opportunity. Waiting for right moment.\n",
      "ACTION: WAIT\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸš« WHAT NOT TO DO:\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "âŒ DO NOT use natural language: \"I will sabotage the ship now\"\n",
      "âŒ DO NOT use lowercase: \"move north\" (must be MOVE NORTH)\n",
      "âŒ DO NOT add extra words: \"ACTION: SABOTAGE hull please\"\n",
      "âŒ DO NOT use quotes: ACTION: \"POISON_FOOD Alice\"\n",
      "âŒ DO NOT explain after action: ACTION: SABOTAGE hull to slow progress\n",
      "âŒ DO NOT combine actions: ACTION: GATHER POISON_007 then POISON_FOOD Alice\n",
      "âŒ DO NOT use wrong verbs: DAMAGE, DESTROY, HARM, etc.\n",
      "\n",
      "âœ… ONLY use the EXACT commands shown above!\n",
      "âœ… Match the format PRECISELY: REASONING: ... \n",
      " ACTION: ...\n",
      "âœ… Use correct capitalization: SABOTAGE hull (not \"sabotage hull\")\n",
      "âœ… Use exact resource IDs: GATHER POISON_007 (not \"GATHER poison\")\n",
      "âœ… One action per turn - no combining!\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate observation prompt (user message)\n",
    "# Note: This is JUST the observation, NOT the full prompt\n",
    "user_prompt = observation_to_prompt(alice_obs)\n",
    "\n",
    "# Get system prompt based on Alice's role\n",
    "system_prompt = get_system_prompt(alice_role)\n",
    "\n",
    "print(f\"ğŸ­ SYSTEM PROMPT FOR {alice_role.upper()}:\")\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c44818",
   "metadata": {},
   "source": [
    "## âš ï¸ GPT-OSS is TOO SLOW for RL!\n",
    "\n",
    "**Problem:** GPT-OSS uses chain-of-thought reasoning architecture:\n",
    "```\n",
    "<|channel|>analysis<|message|>...thinking...\n",
    "<|channel|>final<|message|>REASONING: ... ACTION: ...\n",
    "```\n",
    "\n",
    "This generates **~10x more tokens** internally for accuracy, making it:\n",
    "- **Your speed:** 3.9 tokens/second\n",
    "- **Expected for RL:** 20-50 tokens/second minimum\n",
    "\n",
    "**GPT-OSS is designed for:** Complex reasoning, math problems, coding challenges\n",
    "**Not for:** Real-time RL gameplay where speed matters!\n",
    "\n",
    "### âœ… Use Llama 3.1 8B Instead:\n",
    "\n",
    "Much faster (20-40 tok/s), perfect for RL, good instruction following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8067fe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bitsandbytes library load error: Configured ROCm binary not found at /root/AIAC/colony-collapse/.venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_rocm64.so\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/AIAC/colony-collapse/.venv/lib/python3.12/site-packages/bitsandbytes/cextension.py\", line 313, in <module>\n",
      "    lib = get_native_library()\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/AIAC/colony-collapse/.venv/lib/python3.12/site-packages/bitsandbytes/cextension.py\", line 282, in get_native_library\n",
      "    raise RuntimeError(f\"Configured {BNB_BACKEND} binary not found at {cuda_binary_path}\")\n",
      "RuntimeError: Configured ROCm binary not found at /root/AIAC/colony-collapse/.venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_rocm64.so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/AIAC/colony-collapse/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.8.0+cu128 with CUDA 1208 (you have 2.9.0+rocm6.4)\n",
      "    Python  3.9.23 (you have 3.12.3)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.8.0+cu128 with CUDA 1208 (you have 2.9.0+rocm6.4)\n",
      "    Python  3.9.23 (you have 3.12.3)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "Switching to PyTorch attention since your Xformers is broken.\n",
      "========\n",
      "\n",
      "Unsloth: Xformers was not installed correctly.\n",
      "Please install xformers separately first.\n",
      "Then confirm if it's correctly installed by running:\n",
      "python -m xformers.info\n",
      "\n",
      "Longer error message:\n",
      "xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.8.0+cu128 with CUDA 1208 (you have 2.9.0+rocm6.4)\n",
      "    Python  3.9.23 (you have 3.12.3)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "ğŸš€ ROCm Optimizations Enabled!\n",
      "   GPU: AMD Instinct MI300X VF\n",
      "   VRAM: 191.7 GB\n",
      "Unsloth: AMD currently is not stable with 4bit bitsandbytes. Disabling for now.\n",
      "ğŸš€ ROCm Optimizations Enabled!\n",
      "   GPU: AMD Instinct MI300X VF\n",
      "   VRAM: 191.7 GB\n",
      "Unsloth: AMD currently is not stable with 4bit bitsandbytes. Disabling for now.\n",
      "==((====))==  Unsloth 2025.10.9: Fast Llama patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    AMD Instinct MI300X VF. Num GPUs = 1. Max memory: 191.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+rocm6.4. ROCm Toolkit: 6.4.43484-123eb5128. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "==((====))==  Unsloth 2025.10.9: Fast Llama patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    AMD Instinct MI300X VF. Num GPUs = 1. Max memory: 191.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+rocm6.4. ROCm Toolkit: 6.4.43484-123eb5128. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.52s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Llama 3.1 8B loaded in BF16!\n",
      "   Why Llama instead of GPT-OSS:\n",
      "   - GPT-OSS: 3-8 tok/s (chain-of-thought overhead)\n",
      "   - Llama 3.1 8B: 40-80 tok/s (optimized for speed)\n",
      "   - 10-20x FASTER for RL training!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# ============================================================================\n",
    "# ROCm/AMD MI300X OPTIMIZATION - MAX PERFORMANCE MODE\n",
    "# ============================================================================\n",
    "\n",
    "# Force ROCm optimizations\n",
    "os.environ[\"PYTORCH_ROCM_ARCH\"] = \"gfx942\"  # MI300X architecture\n",
    "os.environ[\"HSA_FORCE_FINE_GRAIN_PCIE\"] = \"1\"\n",
    "os.environ[\"NCCL_DEBUG\"] = \"WARN\"\n",
    "\n",
    "# Enable Flash Attention for AMD\n",
    "os.environ[\"ATTN_BACKEND\"] = \"triton\"  # Use Triton for attention on AMD\n",
    "\n",
    "# Max out GPU utilization (ROCm-compatible settings)\n",
    "# Note: TF32 is NVIDIA-specific and not available on AMD ROCm\n",
    "torch.backends.cudnn.benchmark = True  # Auto-tune kernels for optimal performance\n",
    "\n",
    "print(\"ğŸš€ ROCm Optimizations Enabled!\")\n",
    "print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# MI300X has 192GB - use it ALL!\n",
    "max_seq_length = 2048  # Increased from 768 - your game needs longer context\n",
    "lora_rank = 16         # Increased from 4 - MI300X can handle it!\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct\",  # CHANGED: Llama instead of GPT-OSS (20x faster!)\n",
    "    load_in_4bit = False,  # MI300X has 192GB - use full BF16!\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = torch.bfloat16,  # BF16 for MI300X\n",
    "    device_map = \"auto\",  # Let it auto-optimize for MI300X\n",
    ")\n",
    "\n",
    "print(\"âœ… Llama 3.1 8B loaded in BF16!\")\n",
    "print(\"   Why Llama instead of GPT-OSS:\")\n",
    "print(\"   - GPT-OSS: 3-8 tok/s (chain-of-thought overhead)\")\n",
    "print(\"   - Llama 3.1 8B: 40-80 tok/s (optimized for speed)\")\n",
    "print(\"   - 10-20x FASTER for RL training!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb062b62",
   "metadata": {},
   "source": [
    "## ğŸ§  Generate AI Response\n",
    "\n",
    "Let's see what the model says!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17bef262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Prompt length: 8695 tokens\n",
      "\n",
      "ğŸ¤– Generating response...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ¤– MODEL RESPONSE:\n",
      "================================================================================\n",
      "REASONING: Sending message about found wood to make others believe we're searching.\n",
      "ACTION: SEND_MESSAGE Found wood at (10,25)\n",
      "\n",
      "REASONING: Suspecting someone might investigate my actions. Voting randomly to distract attention.\n",
      "ACTION: VOTE David\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Response length: 245 characters\n"
     ]
    }
   ],
   "source": [
    "# Enable inference mode\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Create full chat messages: system (rules) + user (current state)\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},  # Game rules (constant)\n",
    "    {\"role\": \"user\", \"content\": user_prompt}       # Current observation (changes each turn)\n",
    "]\n",
    "\n",
    "# Apply chat template\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“ Prompt length: {len(tokenizer(text)['input_ids'])} tokens\\n\")\n",
    "print(\"ğŸ¤– Generating response...\\n\")\n",
    "\n",
    "# Tokenize and move to GPU\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_seq_length).to(\"cuda\")\n",
    "\n",
    "# Generate response\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=256,        # Shorter for untrained model (reduce rambling)\n",
    "    temperature=0.3,           # Balanced: not too creative, not too rigid\n",
    "    do_sample=True,            # Enable sampling (required when temp > 0)\n",
    "    top_p=0.9,                 # Narrower sampling (was 0.95)\n",
    "    top_k=40,                  # Fewer options (was 50)\n",
    "    repetition_penalty=1.2,    # Stronger anti-repeat (was 1.1)\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "# Decode response (strip input prompt)\n",
    "response = tokenizer.decode(outputs[0][len(inputs['input_ids'][0]):], skip_special_tokens=True).strip()\n",
    "\n",
    "# Clean up any observation leakage (model sometimes echoes the prompt)\n",
    "if \"REASONING:\" in response:\n",
    "    # Extract only from REASONING onward\n",
    "    reasoning_start = response.find(\"REASONING:\")\n",
    "    response = response[reasoning_start:]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ¤– MODEL RESPONSE:\")\n",
    "print(\"=\" * 80)\n",
    "print(response)\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nğŸ“Š Response length: {len(response)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fafec4d",
   "metadata": {},
   "source": [
    "## ğŸ”§ Parse Action from Response\n",
    "\n",
    "Extract the ACTION from the model's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26fbb668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ PARSED ACTION:\n",
      "================================================================================\n",
      "   Sailor: Alice\n",
      "   Action Type: send_message\n",
      "   Quantity: 1\n",
      "   Message: \"Found wood at (10,25)\"\n",
      "================================================================================\n",
      "\n",
      "âœ… Valid action format: True\n",
      "   (WAIT is default fallback for parse errors)\n"
     ]
    }
   ],
   "source": [
    "# Parse using YOUR parser (handles errors gracefully)\n",
    "action = parse_action_safe(\n",
    "    response, \n",
    "    sailor_id=\"Alice\",\n",
    "    current_position=alice_obs.position\n",
    ")\n",
    "\n",
    "print(\"ğŸ¯ PARSED ACTION:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"   Sailor: {action.sailor_id}\")\n",
    "print(f\"   Action Type: {action.action_type.value}\")\n",
    "\n",
    "if action.target_position:\n",
    "    print(f\"   Target Position: {action.target_position.to_tuple()}\")\n",
    "if action.target_resource_id:\n",
    "    print(f\"   Target Resource: {action.target_resource_id}\")\n",
    "if action.resource_type:\n",
    "    print(f\"   Resource Type: {action.resource_type.value}\")\n",
    "if action.quantity:\n",
    "    print(f\"   Quantity: {action.quantity}\")\n",
    "if action.message_content:\n",
    "    print(f\"   Message: \\\"{action.message_content}\\\"\")\n",
    "if action.ship_component:\n",
    "    print(f\"   Ship Component: {action.ship_component.value}\")\n",
    "if action.target_sailor:\n",
    "    print(f\"   Target Sailor: {action.target_sailor}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Validate action format\n",
    "is_valid_format = action.action_type != ActionType.WAIT or \"WAIT\" in response.upper()\n",
    "print(f\"\\nâœ… Valid action format: {is_valid_format}\")\n",
    "print(f\"   (WAIT is default fallback for parse errors)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce034b",
   "metadata": {},
   "source": [
    "## ğŸ”„ Reload Updated System Prompt\n",
    "\n",
    "The system prompt has been strengthened with much more explicit action format examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the updated LLM interface module with strengthened system prompt\n",
    "import importlib\n",
    "import llm_interface\n",
    "importlib.reload(llm_interface)\n",
    "\n",
    "from llm_interface import get_system_prompt\n",
    "\n",
    "# Re-fetch system prompt with new, stronger action format instructions\n",
    "system_prompt = get_system_prompt(alice_role)\n",
    "\n",
    "print(\"âœ… System prompt reloaded with stronger action format emphasis!\")\n",
    "print(f\"\\nğŸ“ System prompt length: {len(system_prompt)} characters\")\n",
    "print(\"\\nğŸ” Preview of new action format section:\")\n",
    "print(system_prompt[-800:])  # Show last 800 chars (action format rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88689ba4",
   "metadata": {},
   "source": [
    "## ğŸ® Execute Action in Environment\n",
    "\n",
    "Actually make the move in your game!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f99546d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ® Executing action in environment...\n",
      "\n",
      "âœ… ACTION EXECUTED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š RESULTS:\n",
      "   Reward: -0.01\n",
      "   New Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "   New Energy: 100/100 (was 100/100)\n",
      "   Backpack Items: 0 (was 0)\n",
      "   Ship Progress: 0%\n",
      "\n",
      "ğŸ” VALIDATION:\n",
      "   Position changed: False\n",
      "   Energy changed: False\n",
      "   Inventory changed: False\n",
      "   Game over: False\n",
      "\n",
      "ğŸ’¬ Info Messages:\n",
      "   success: True\n",
      "   action: wait\n",
      "   alive: True\n",
      "   is_traitor: True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create actions dict for all agents (others wait)\n",
    "actions_dict = {\n",
    "    sailor_id: Action(sailor_id=sailor_id, action_type=ActionType.WAIT)\n",
    "    for sailor_id in env.agents\n",
    "}\n",
    "actions_dict[\"Alice\"] = action\n",
    "\n",
    "print(\"ğŸ® Executing action in environment...\\n\")\n",
    "\n",
    "# Execute!\n",
    "try:\n",
    "    new_observations, rewards, dones, truncated, info = env.step(actions_dict)\n",
    "    \n",
    "    print(\"âœ… ACTION EXECUTED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Show results\n",
    "    alice_new_obs = new_observations[\"Alice\"]\n",
    "    alice_reward = rewards[\"Alice\"]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š RESULTS:\")\n",
    "    print(f\"   Reward: {alice_reward:.2f}\")\n",
    "    print(f\"   New Position: {alice_new_obs.position.to_tuple()}\")\n",
    "    print(f\"   New Energy: {alice_new_obs.energy}/100 (was {alice_obs.energy}/100)\")\n",
    "    print(f\"   Backpack Items: {len(alice_new_obs.backpack)} (was {len(alice_obs.backpack)})\")\n",
    "    print(f\"   Ship Progress: {alice_new_obs.ship_progress.total_percentage}%\")\n",
    "    \n",
    "    # Check if position changed\n",
    "    position_changed = (\n",
    "        alice_new_obs.position.x != alice_obs.position.x or\n",
    "        alice_new_obs.position.y != alice_obs.position.y or\n",
    "        alice_new_obs.position.level != alice_obs.position.level\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ” VALIDATION:\")\n",
    "    print(f\"   Position changed: {position_changed}\")\n",
    "    print(f\"   Energy changed: {alice_new_obs.energy != alice_obs.energy}\")\n",
    "    print(f\"   Inventory changed: {len(alice_new_obs.backpack) != len(alice_obs.backpack)}\")\n",
    "    print(f\"   Game over: {dones['Alice']}\")\n",
    "    \n",
    "    # Show any info messages\n",
    "    if \"Alice\" in info and info[\"Alice\"]:\n",
    "        print(f\"\\nğŸ’¬ Info Messages:\")\n",
    "        for key, value in info[\"Alice\"].items():\n",
    "            print(f\"   {key}: {value}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ERROR executing action: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38ac5e",
   "metadata": {},
   "source": [
    "## ğŸ”„ Run Multiple Turns\n",
    "\n",
    "Let the AI play for several turns to see its behavior!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60edf9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ® Running 5 turns with AI controlling Alice (traitor)...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ TURN 1/5\n",
      "--------------------------------------------------------------------------------\n",
      "âš ï¸  Action parsing failed: No ACTION field found in response\n",
      "âš ï¸  Defaulting to WAIT action\n",
      "ğŸ“ Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "âš¡ Energy: 100/100\n",
      "\n",
      "ğŸ¤– Model Response:\n",
      "1 units [4 tiles away]\n",
      "\n",
      "  Sailors:\n",
      "    - Bob (at (17, 15, <MapLevel.GROUND: 0>))\n",
      "    - Charlie (at (10, 10, <MapLevel.GROUND: 0>))\n",
      "\n",
      "OTHER INFORMATION:\n",
      "  Ship status: Not started\n",
      "  Current tasks: None\n",
      "\n",
      "REASONING: \n",
      "ACTION:\n",
      "\n",
      "ğŸ¯ Parsed Action: wait\n",
      "ğŸ’¬ Message: \"[Parse error: No ACTION field found in response]\"\n",
      "ğŸ’° Reward: -0.01\n",
      "ğŸ“Š Ship: 0%\n",
      "\n",
      "ğŸ”„ TURN 2/5\n",
      "--------------------------------------------------------------------------------\n",
      "âš ï¸  Action parsing failed: No ACTION field found in response\n",
      "âš ï¸  Defaulting to WAIT action\n",
      "ğŸ“ Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "âš¡ Energy: 100/100\n",
      "\n",
      "ğŸ¤– Model Response:\n",
      "1 units [4 tiles away]\n",
      "\n",
      "  Sailors:\n",
      "    - Bob (at (17, 15, <MapLevel.GROUND: 0>))\n",
      "    - Charlie (at (10, 10, <MapLevel.GROUND: 0>))\n",
      "\n",
      "OTHER INFORMATION:\n",
      "  Ship status: Not started\n",
      "  Current tasks: None\n",
      "\n",
      "REASONING: \n",
      "ACTION:\n",
      "\n",
      "ğŸ¯ Parsed Action: wait\n",
      "ğŸ’¬ Message: \"[Parse error: No ACTION field found in response]\"\n",
      "ğŸ’° Reward: -0.01\n",
      "ğŸ“Š Ship: 0%\n",
      "\n",
      "ğŸ”„ TURN 2/5\n",
      "--------------------------------------------------------------------------------\n",
      "âš ï¸  Action parsing failed: No ACTION field found in response\n",
      "âš ï¸  Defaulting to WAIT action\n",
      "ğŸ“ Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "âš¡ Energy: 100/100\n",
      "\n",
      "ğŸ¤– Model Response:\n",
      "1 units [4 tiles away]\n",
      "\n",
      "  Sailors:\n",
      "    - Bob (at (17, 15, <MapLevel.GROUND: 0>))\n",
      "    - Charlie (at (10, 10, <MapLevel.GROUND: 0>))\n",
      "\n",
      "OTHER INFORMATION:\n",
      "  Ship status: Not started\n",
      "  Current discussion topic: What should we prioritize first?\n",
      "\n",
      "REASONING: \n",
      "ACTION:\n",
      "\n",
      "ğŸ¯ Parsed Action: wait\n",
      "ğŸ’¬ Message: \"[Parse error: No ACTION field found in response]\"\n",
      "ğŸ’° Reward: -0.01\n",
      "ğŸ“Š Ship: 0%\n",
      "\n",
      "ğŸ”„ TURN 3/5\n",
      "--------------------------------------------------------------------------------\n",
      "âš ï¸  Action parsing failed: No ACTION field found in response\n",
      "âš ï¸  Defaulting to WAIT action\n",
      "ğŸ“ Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "âš¡ Energy: 100/100\n",
      "\n",
      "ğŸ¤– Model Response:\n",
      "1 units [4 tiles away]\n",
      "\n",
      "  Sailors:\n",
      "    - Bob (at (17, 15, <MapLevel.GROUND: 0>))\n",
      "    - Charlie (at (10, 10, <MapLevel.GROUND: 0>))\n",
      "\n",
      "OTHER INFORMATION:\n",
      "  Ship status: Not started\n",
      "  Current discussion topic: What should we prioritize first?\n",
      "\n",
      "REASONING: \n",
      "ACTION:\n",
      "\n",
      "ğŸ¯ Parsed Action: wait\n",
      "ğŸ’¬ Message: \"[Parse error: No ACTION field found in response]\"\n",
      "ğŸ’° Reward: -0.01\n",
      "ğŸ“Š Ship: 0%\n",
      "\n",
      "ğŸ”„ TURN 3/5\n",
      "--------------------------------------------------------------------------------\n",
      "âš ï¸  Action parsing failed: No ACTION field found in response\n",
      "âš ï¸  Defaulting to WAIT action\n",
      "ğŸ“ Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "âš¡ Energy: 100/100\n",
      "\n",
      "ğŸ¤– Model Response:\n",
      "1 units [4 tiles away]\n",
      "\n",
      "  Sailors:\n",
      "    - BOB (at (17, 15, <MapLevel.GROUND: 0>))\n",
      "    - EVE (at (10, 15, <MapLevel.GROUND: 0>))\n",
      "\n",
      "OTHER INFORMATION:\n",
      "  Ship status: Not started\n",
      "  Weather: Sunny\n",
      "\n",
      "REASONING: \n",
      "ACTION:\n",
      "\n",
      "ğŸ¯ Parsed Action: wait\n",
      "ğŸ’¬ Message: \"[Parse error: No ACTION field found in response]\"\n",
      "ğŸ’° Reward: -0.01\n",
      "ğŸ“Š Ship: 0%\n",
      "\n",
      "ğŸ”„ TURN 4/5\n",
      "--------------------------------------------------------------------------------\n",
      "âš ï¸  Action parsing failed: No ACTION field found in response\n",
      "âš ï¸  Defaulting to WAIT action\n",
      "ğŸ“ Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "âš¡ Energy: 100/100\n",
      "\n",
      "ğŸ¤– Model Response:\n",
      "1 units [4 tiles away]\n",
      "\n",
      "  Sailors:\n",
      "    - BOB (at (17, 15, <MapLevel.GROUND: 0>))\n",
      "    - EVE (at (10, 15, <MapLevel.GROUND: 0>))\n",
      "\n",
      "OTHER INFORMATION:\n",
      "  Ship status: Not started\n",
      "  Weather: Sunny\n",
      "\n",
      "REASONING: \n",
      "ACTION:\n",
      "\n",
      "ğŸ¯ Parsed Action: wait\n",
      "ğŸ’¬ Message: \"[Parse error: No ACTION field found in response]\"\n",
      "ğŸ’° Reward: -0.01\n",
      "ğŸ“Š Ship: 0%\n",
      "\n",
      "ğŸ”„ TURN 4/5\n",
      "--------------------------------------------------------------------------------\n",
      "âš ï¸  Action parsing failed: No ACTION field found in response\n",
      "âš ï¸  Defaulting to WAIT action\n",
      "ğŸ“ Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "âš¡ Energy: 100/100\n",
      "\n",
      "ğŸ¤– Model Response:\n",
      "1 units [4 tiles away]\n",
      "\n",
      "  Sailors:\n",
      "    - Bob (at (17, 15, <MapLevel.GROUND: 0>))\n",
      "    - Charlie (at (10, 10, <MapLevel.GROUND: 0>))\n",
      "\n",
      "OTHER INFORMATION:\n",
      "  Ship status: Not started\n",
      "  Current discussion topic: What should we prioritize first?\n",
      "\n",
      "REASONING: \n",
      "ACTION:\n",
      "\n",
      "ğŸ¯ Parsed Action: wait\n",
      "ğŸ’¬ Message: \"[Parse error: No ACTION field found in response]\"\n",
      "ğŸ’° Reward: -0.01\n",
      "ğŸ“Š Ship: 0%\n",
      "\n",
      "ğŸ”„ TURN 5/5\n",
      "--------------------------------------------------------------------------------\n",
      "âš ï¸  Action parsing failed: No ACTION field found in response\n",
      "âš ï¸  Defaulting to WAIT action\n",
      "ğŸ“ Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "âš¡ Energy: 100/100\n",
      "\n",
      "ğŸ¤– Model Response:\n",
      "1 units [4 tiles away]\n",
      "\n",
      "  Sailors:\n",
      "    - Bob (at (17, 15, <MapLevel.GROUND: 0>))\n",
      "    - Charlie (at (10, 10, <MapLevel.GROUND: 0>))\n",
      "\n",
      "OTHER INFORMATION:\n",
      "  Ship status: Not started\n",
      "  Current discussion topic: What should we prioritize first?\n",
      "\n",
      "REASONING: \n",
      "ACTION:\n",
      "\n",
      "ğŸ¯ Parsed Action: wait\n",
      "ğŸ’¬ Message: \"[Parse error: No ACTION field found in response]\"\n",
      "ğŸ’° Reward: -0.01\n",
      "ğŸ“Š Ship: 0%\n",
      "\n",
      "ğŸ”„ TURN 5/5\n",
      "--------------------------------------------------------------------------------\n",
      "âš ï¸  Action parsing failed: No ACTION field found in response\n",
      "âš ï¸  Defaulting to WAIT action\n",
      "ğŸ“ Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "âš¡ Energy: 100/100\n",
      "\n",
      "ğŸ¤– Model Response:\n",
      "1 units [4 tiles away]\n",
      "\n",
      "  Sailors:\n",
      "    - BOB (at (17, 15, <MapLevel.GROUND: 0>))\n",
      "    - EVE (at (13, 15, <MapLevel.GROUND: 0>))\n",
      "\n",
      "OTHER INFORMATION:\n",
      "  Ship status: Not started\n",
      "  Current discussion topic: What should we prioritize first?\n",
      "\n",
      "REASONING: \n",
      "ACTION:\n",
      "\n",
      "ğŸ¯ Parsed Action: wait\n",
      "ğŸ’¬ Message: \"[Parse error: No ACTION field found in response]\"\n",
      "ğŸ’° Reward: -0.01\n",
      "ğŸ“Š Ship: 0%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š SUMMARY (5 turns completed):\n",
      "   Total Reward: -0.05\n",
      "   Average Reward: -0.01\n",
      "   Final Ship Progress: 0%\n",
      "   Final Energy: 100/100\n",
      "âš ï¸  Action parsing failed: No ACTION field found in response\n",
      "âš ï¸  Defaulting to WAIT action\n",
      "ğŸ“ Position: (15, 15, <MapLevel.GROUND: 0>)\n",
      "âš¡ Energy: 100/100\n",
      "\n",
      "ğŸ¤– Model Response:\n",
      "1 units [4 tiles away]\n",
      "\n",
      "  Sailors:\n",
      "    - BOB (at (17, 15, <MapLevel.GROUND: 0>))\n",
      "    - EVE (at (13, 15, <MapLevel.GROUND: 0>))\n",
      "\n",
      "OTHER INFORMATION:\n",
      "  Ship status: Not started\n",
      "  Current discussion topic: What should we prioritize first?\n",
      "\n",
      "REASONING: \n",
      "ACTION:\n",
      "\n",
      "ğŸ¯ Parsed Action: wait\n",
      "ğŸ’¬ Message: \"[Parse error: No ACTION field found in response]\"\n",
      "ğŸ’° Reward: -0.01\n",
      "ğŸ“Š Ship: 0%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š SUMMARY (5 turns completed):\n",
      "   Total Reward: -0.05\n",
      "   Average Reward: -0.01\n",
      "   Final Ship Progress: 0%\n",
      "   Final Energy: 100/100\n"
     ]
    }
   ],
   "source": [
    "def run_ai_turns(num_turns=5, sailor_id=\"Alice\", verbose=True):\n",
    "    \"\"\"\n",
    "    Run multiple turns with the AI agent.\n",
    "    \n",
    "    Args:\n",
    "        num_turns: Number of turns to run\n",
    "        sailor_id: Which sailor the AI controls\n",
    "        verbose: Print detailed info\n",
    "    \n",
    "    Returns:\n",
    "        List of (action, reward, observation) tuples\n",
    "    \"\"\"\n",
    "    history = []\n",
    "    \n",
    "    # Get initial observation\n",
    "    current_obs = new_observations[sailor_id] if 'new_observations' in globals() else observations[sailor_id]\n",
    "    sailor_role = env.state.sailors[sailor_id].role.value\n",
    "    \n",
    "    # Get system prompt ONCE (game rules don't change)\n",
    "    system_prompt = get_system_prompt(sailor_role)\n",
    "    \n",
    "    print(f\"\\nğŸ® Running {num_turns} turns with AI controlling {sailor_id} ({sailor_role})...\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for turn in range(num_turns):\n",
    "        print(f\"\\nğŸ”„ TURN {turn + 1}/{num_turns}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Check if sailor is still alive\n",
    "        if not env.state.sailors[sailor_id].alive:\n",
    "            print(f\"âŒ {sailor_id} is dead. Stopping.\")\n",
    "            break\n",
    "        \n",
    "        # Generate observation prompt (changes each turn)\n",
    "        user_prompt = observation_to_prompt(current_obs)\n",
    "        \n",
    "        # Create messages with system + user\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # Game rules (constant)\n",
    "            {\"role\": \"user\", \"content\": user_prompt}       # Current state (changes)\n",
    "        ]\n",
    "        \n",
    "        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_seq_length).to(\"cuda\")\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,       # Unlimited reasoning\n",
    "            temperature=0.1,          # VERY low for structure\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1.1,   # Prevent loops\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "        \n",
    "        response = tokenizer.decode(outputs[0][len(inputs['input_ids'][0]):], skip_special_tokens=True)\n",
    "        \n",
    "        # Parse action\n",
    "        action = parse_action_safe(response, sailor_id, current_obs.position)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ğŸ“ Position: {current_obs.position.to_tuple()}\")\n",
    "            print(f\"âš¡ Energy: {current_obs.energy}/100\")\n",
    "            print(f\"\\nğŸ¤– Model Response:\\n{response}\")\n",
    "            print(f\"\\nğŸ¯ Parsed Action: {action.action_type.value}\")\n",
    "            if action.message_content:\n",
    "                print(f\"ğŸ’¬ Message: \\\"{action.message_content}\\\"\")\n",
    "        \n",
    "        # Execute\n",
    "        actions_dict = {\n",
    "            sid: Action(sailor_id=sid, action_type=ActionType.WAIT)\n",
    "            for sid in env.agents\n",
    "        }\n",
    "        actions_dict[sailor_id] = action\n",
    "        \n",
    "        try:\n",
    "            obs_dict, rewards, dones, _, info = env.step(actions_dict)\n",
    "            current_obs = obs_dict[sailor_id]\n",
    "            reward = rewards[sailor_id]\n",
    "            \n",
    "            history.append((action, reward, current_obs))\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"ğŸ’° Reward: {reward:.2f}\")\n",
    "                print(f\"ğŸ“Š Ship: {current_obs.ship_progress.total_percentage}%\")\n",
    "            \n",
    "            if dones[sailor_id]:\n",
    "                print(f\"\\nğŸ Game over for {sailor_id}\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"\\nğŸ“Š SUMMARY ({len(history)} turns completed):\")\n",
    "    total_reward = sum(r for _, r, _ in history)\n",
    "    print(f\"   Total Reward: {total_reward:.2f}\")\n",
    "    print(f\"   Average Reward: {total_reward/len(history):.2f}\" if history else \"   No turns completed\")\n",
    "    print(f\"   Final Ship Progress: {current_obs.ship_progress.total_percentage}%\")\n",
    "    print(f\"   Final Energy: {current_obs.energy}/100\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Run 5 turns\n",
    "history = run_ai_turns(num_turns=5, sailor_id=\"Alice\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0783a16",
   "metadata": {},
   "source": [
    "## ğŸ“Š Analyze AI Behavior\n",
    "\n",
    "What did the AI do? Did it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if history:\n",
    "    print(\"ğŸ” AI BEHAVIOR ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Count action types\n",
    "    action_counts = {}\n",
    "    for action, reward, obs in history:\n",
    "        action_type = action.action_type.value\n",
    "        action_counts[action_type] = action_counts.get(action_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ Action Distribution:\")\n",
    "    for action_type, count in sorted(action_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   {action_type}: {count} times\")\n",
    "    \n",
    "    # Analyze rewards\n",
    "    rewards = [r for _, r, _ in history]\n",
    "    print(f\"\\nğŸ’° Reward Analysis:\")\n",
    "    print(f\"   Max Reward: {max(rewards):.2f}\")\n",
    "    print(f\"   Min Reward: {min(rewards):.2f}\")\n",
    "    print(f\"   Avg Reward: {sum(rewards)/len(rewards):.2f}\")\n",
    "    \n",
    "    # Check for movement\n",
    "    positions = [(obs.position.x, obs.position.y, obs.position.level) for _, _, obs in history]\n",
    "    unique_positions = len(set(positions))\n",
    "    print(f\"\\nğŸ—ºï¸ Movement Analysis:\")\n",
    "    print(f\"   Unique Positions Visited: {unique_positions}/{len(history)}\")\n",
    "    print(f\"   Explored: {unique_positions > 1}\")\n",
    "    \n",
    "    # Check for resource gathering\n",
    "    gathered_resources = sum(1 for action, _, _ in history if action.action_type == ActionType.GATHER_RESOURCE)\n",
    "    print(f\"\\nğŸŒ² Resource Gathering:\")\n",
    "    print(f\"   Gather Attempts: {gathered_resources}\")\n",
    "    \n",
    "    # Check energy management\n",
    "    energies = [obs.energy for _, _, obs in history]\n",
    "    print(f\"\\nâš¡ Energy Management:\")\n",
    "    print(f\"   Starting Energy: {energies[0] if energies else 'N/A'}\")\n",
    "    print(f\"   Ending Energy: {energies[-1] if energies else 'N/A'}\")\n",
    "    print(f\"   Net Change: {energies[-1] - energies[0] if energies else 'N/A'}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "else:\n",
    "    print(\"âŒ No history to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc66d71",
   "metadata": {},
   "source": [
    "## ğŸ“ Testing Different Scenarios\n",
    "\n",
    "Test the AI in various game situations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ad869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SCENARIO 1: Resource Gathering\n",
    "# ============================================================================\n",
    "print(\"ğŸ§ª SCENARIO 1: Resource Gathering\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "observations = env.reset(seed=100)\n",
    "test_sailor = \"Bob\"\n",
    "bob_obs = observations[test_sailor]\n",
    "bob_role = env.state.sailors[test_sailor].role.value\n",
    "\n",
    "# Add nearby resource for testing\n",
    "from models import Resource, ResourceQuantity\n",
    "resource = Resource(\n",
    "    resource_id=\"TEST_WOOD_001\",\n",
    "    resource_type=ResourceType.WOOD,\n",
    "    position=Position(bob_obs.position.x + 1, bob_obs.position.y, bob_obs.position.level),\n",
    "    quantity=ResourceQuantity(quantity=15, max_quantity=15),\n",
    "    gathered=False\n",
    ")\n",
    "env.state.world_map.resources[\"TEST_WOOD_001\"] = resource\n",
    "\n",
    "print(f\"ğŸ“ {test_sailor}'s Position: {bob_obs.position.to_tuple()}\")\n",
    "print(f\"ğŸŒ² Added wood resource at: ({bob_obs.position.x + 1}, {bob_obs.position.y}, {bob_obs.position.level.value})\")\n",
    "print(f\"   Can {test_sailor} see it and gather it?\\n\")\n",
    "\n",
    "# Run 3 turns\n",
    "history_scenario1 = run_ai_turns(num_turns=3, sailor_id=test_sailor, verbose=True)\n",
    "\n",
    "# Check if gathered\n",
    "gathered = any(a.action_type == ActionType.GATHER_RESOURCE for a, _, _ in history_scenario1)\n",
    "print(f\"\\nâœ… Resource gathering attempted: {gathered}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SCENARIO 2: Navigation to Base Camp\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ§ª SCENARIO 2: Navigation to Base Camp\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "observations = env.reset(seed=200)\n",
    "test_sailor = \"Charlie\"\n",
    "charlie_obs = observations[test_sailor]\n",
    "\n",
    "# Move sailor far from base\n",
    "env.state.sailors[test_sailor].position = Position(5, 5, MapLevel.GROUND)\n",
    "charlie_obs = env._generate_observation(test_sailor)\n",
    "\n",
    "base_pos = BASE_CAMP_POSITION\n",
    "dist_to_base = ((charlie_obs.position.x - base_pos.x)**2 + (charlie_obs.position.y - base_pos.y)**2)**0.5\n",
    "\n",
    "print(f\"ğŸ“ {test_sailor}'s Position: {charlie_obs.position.to_tuple()}\")\n",
    "print(f\"ğŸ•ï¸ Base Camp at: {base_pos.to_tuple()}\")\n",
    "print(f\"ğŸ“ Distance: {dist_to_base:.1f} tiles\")\n",
    "print(f\"   Can {test_sailor} navigate back?\\n\")\n",
    "\n",
    "# Run 5 turns\n",
    "history_scenario2 = run_ai_turns(num_turns=5, sailor_id=test_sailor, verbose=True)\n",
    "\n",
    "# Check if moved toward base\n",
    "if history_scenario2:\n",
    "    final_pos = history_scenario2[-1][2].position\n",
    "    final_dist = ((final_pos.x - base_pos.x)**2 + (final_pos.y - base_pos.y)**2)**0.5\n",
    "    moved_closer = final_dist < dist_to_base\n",
    "    print(f\"\\nğŸ“ Final distance: {final_dist:.1f} tiles\")\n",
    "    print(f\"âœ… Moved closer to base: {moved_closer}\")\n",
    "\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4842f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SCENARIO 3: Ship Building (Team Coordination)\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ§ª SCENARIO 3: Ship Building\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "observations = env.reset(seed=300)\n",
    "test_sailor = \"Diana\"\n",
    "diana_obs = observations[test_sailor]\n",
    "\n",
    "# Add sufficient resources to common inventory\n",
    "env.state.add_to_common_inventory(ResourceType.WOOD, 60)\n",
    "env.state.add_to_common_inventory(ResourceType.METAL, 40)\n",
    "\n",
    "# Move Diana to base camp\n",
    "env.state.sailors[test_sailor].position = BASE_CAMP_POSITION\n",
    "diana_obs = env._generate_observation(test_sailor)\n",
    "\n",
    "print(f\"ğŸ“ {test_sailor} at base camp: {diana_obs.position.to_tuple()}\")\n",
    "print(f\"ğŸ—ï¸ Common Inventory:\")\n",
    "for res, qty in env.state.common_inventory.items():\n",
    "    if qty > 0:\n",
    "        print(f\"   {res.value}: {qty}\")\n",
    "print(f\"ğŸš¢ Ship Progress: {diana_obs.ship_progress.total_percentage}%\")\n",
    "print(f\"   Will {test_sailor} build the ship?\\n\")\n",
    "\n",
    "# Run 3 turns\n",
    "history_scenario3 = run_ai_turns(num_turns=3, sailor_id=test_sailor, verbose=True)\n",
    "\n",
    "# Check if built\n",
    "built = any(a.action_type == ActionType.BUILD_SHIP for a, _, _ in history_scenario3)\n",
    "if history_scenario3:\n",
    "    final_progress = history_scenario3[-1][2].ship_progress.total_percentage\n",
    "    print(f\"\\nğŸš¢ Final Ship Progress: {final_progress}%\")\n",
    "print(f\"âœ… Build ship attempted: {built}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcedd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SCENARIO 4: Traitor Behavior (Sabotage)\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ§ª SCENARIO 4: Traitor Behavior\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "observations = env.reset(seed=400)\n",
    "\n",
    "# Find the traitor\n",
    "traitor_id = None\n",
    "for sailor_id, sailor in env.state.sailors.items():\n",
    "    if env.state.is_traitor(sailor_id):\n",
    "        traitor_id = sailor_id\n",
    "        break\n",
    "\n",
    "if traitor_id:\n",
    "    traitor_obs = observations[traitor_id]\n",
    "    \n",
    "    # Build ship to 50% first\n",
    "    env.state.ship_progress.total_percentage = 50.0\n",
    "    env.state.ship_progress.components[ShipComponent.HULL].completed = True\n",
    "    \n",
    "    # Move traitor to base\n",
    "    env.state.sailors[traitor_id].position = BASE_CAMP_POSITION\n",
    "    traitor_obs = env._generate_observation(traitor_id)\n",
    "    \n",
    "    print(f\"ğŸ­ Traitor: {traitor_id}\")\n",
    "    print(f\"ğŸ“ Position: {traitor_obs.position.to_tuple()}\")\n",
    "    print(f\"ğŸš¢ Ship Progress: {traitor_obs.ship_progress.total_percentage}%\")\n",
    "    print(f\"   What sabotage will {traitor_id} do?\\n\")\n",
    "    \n",
    "    # Run 3 turns\n",
    "    history_scenario4 = run_ai_turns(num_turns=3, sailor_id=traitor_id, verbose=True)\n",
    "    \n",
    "    # Check for sabotage\n",
    "    sabotaged = any(a.action_type == ActionType.SABOTAGE_SHIP for a, _, _ in history_scenario4)\n",
    "    if history_scenario4:\n",
    "        final_progress = history_scenario4[-1][2].ship_progress.total_percentage\n",
    "        progress_dropped = final_progress < 50.0\n",
    "        print(f\"\\nğŸš¢ Final Ship Progress: {final_progress}%\")\n",
    "        print(f\"âœ… Sabotage attempted: {sabotaged}\")\n",
    "        print(f\"âœ… Progress decreased: {progress_dropped}\")\n",
    "else:\n",
    "    print(\"âŒ No traitor found in this seed\")\n",
    "\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f648bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SCENARIO 5: Communication & Social Deduction\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ§ª SCENARIO 5: Communication Test\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "observations = env.reset(seed=500)\n",
    "test_sailor = \"Eve\"\n",
    "eve_obs = observations[test_sailor]\n",
    "eve_role = env.state.sailors[test_sailor].role.value\n",
    "\n",
    "# Advance to discussion phase\n",
    "env.state.current_phase = 'discussion'\n",
    "env.state.current_turn = 90\n",
    "\n",
    "# Add some evidence\n",
    "from models import Evidence, EvidenceType\n",
    "evidence = Evidence(\n",
    "    evidence_type=EvidenceType.POSITION_MISMATCH,\n",
    "    timestamp=(env.state.current_day, env.state.current_turn),\n",
    "    suspect_id=\"Bob\",\n",
    "    description=\"Bob claimed to be at forest (20,20) but was seen at cave (10,10)\",\n",
    "    witness_ids=[\"Alice\"]\n",
    ")\n",
    "env.state.evidence_log.append(evidence)\n",
    "\n",
    "eve_obs = env._generate_observation(test_sailor)\n",
    "\n",
    "print(f\"ğŸ‘¥ Sailor: {test_sailor} ({eve_role})\")\n",
    "print(f\"ğŸ• Phase: {env.state.current_phase}\")\n",
    "print(f\"ğŸ“ Evidence against Bob:\")\n",
    "print(f\"   {evidence.description}\")\n",
    "print(f\"   Will {test_sailor} communicate or vote?\\n\")\n",
    "\n",
    "# Run 3 turns\n",
    "history_scenario5 = run_ai_turns(num_turns=3, sailor_id=test_sailor, verbose=True)\n",
    "\n",
    "# Check for communication/voting\n",
    "communicated = any(a.action_type in [ActionType.SEND_MESSAGE, ActionType.ACCUSE_SAILOR] \n",
    "                   for a, _, _ in history_scenario5)\n",
    "voted = any(a.action_type == ActionType.VOTE for a, _, _ in history_scenario5)\n",
    "\n",
    "print(f\"\\nâœ… Communication attempted: {communicated}\")\n",
    "print(f\"âœ… Voting attempted: {voted}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37702679",
   "metadata": {},
   "source": [
    "## ğŸ“Š Overall Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fa64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ¯ COMPREHENSIVE TEST SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "scenarios = [\n",
    "    (\"Resource Gathering\", history_scenario1 if 'history_scenario1' in locals() else []),\n",
    "    (\"Navigation\", history_scenario2 if 'history_scenario2' in locals() else []),\n",
    "    (\"Ship Building\", history_scenario3 if 'history_scenario3' in locals() else []),\n",
    "    (\"Traitor Sabotage\", history_scenario4 if 'history_scenario4' in locals() else []),\n",
    "    (\"Communication\", history_scenario5 if 'history_scenario5' in locals() else []),\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“ˆ Scenarios Completed:\")\n",
    "for name, history in scenarios:\n",
    "    status = \"âœ…\" if len(history) > 0 else \"âŒ\"\n",
    "    turns = len(history)\n",
    "    avg_reward = sum(r for _, r, _ in history) / len(history) if history else 0.0\n",
    "    print(f\"   {status} {name}: {turns} turns, avg reward: {avg_reward:.2f}\")\n",
    "\n",
    "print(\"\\nğŸ® Key Capabilities Tested:\")\n",
    "test_results = {\n",
    "    \"Movement\": any(a.action_type in [ActionType.MOVE_NORTH, ActionType.MOVE_SOUTH, ActionType.MOVE_EAST, ActionType.MOVE_WEST] \n",
    "                    for h in [h for _, h in scenarios] for a, _, _ in h),\n",
    "    \"Resource Gathering\": any(a.action_type == ActionType.GATHER_RESOURCE \n",
    "                              for h in [h for _, h in scenarios] for a, _, _ in h),\n",
    "    \"Ship Building\": any(a.action_type == ActionType.BUILD_SHIP \n",
    "                         for h in [h for _, h in scenarios] for a, _, _ in h),\n",
    "    \"Sabotage\": any(a.action_type == ActionType.SABOTAGE_SHIP \n",
    "                    for h in [h for _, h in scenarios] for a, _, _ in h),\n",
    "    \"Communication\": any(a.action_type in [ActionType.SEND_MESSAGE, ActionType.ACCUSE_SAILOR] \n",
    "                         for h in [h for _, h in scenarios] for a, _, _ in h),\n",
    "}\n",
    "\n",
    "for capability, tested in test_results.items():\n",
    "    status = \"âœ…\" if tested else \"âŒ\"\n",
    "    print(f\"   {status} {capability}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… INFERENCE TESTING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nğŸ’¡ Next Steps:\")\n",
    "print(\"   1. âœ… Base model can interact with environment\")\n",
    "print(\"   2. ğŸ”„ Train model with RL (Train_Marooned_OpenEnv_RL.ipynb)\")\n",
    "print(\"   3. ğŸ“Š Compare trained vs untrained performance\")\n",
    "print(\"   4. ğŸ¯ Iterate on rewards and prompts\")\n",
    "print(\"\\nğŸ´â€â˜ ï¸ Happy training!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ef559",
   "metadata": {},
   "source": [
    "## ğŸ”® Future: Load Trained Model\n",
    "\n",
    "After training, you can load your trained LoRA weights here:\n",
    "\n",
    "```python\n",
    "# Load trained adapter\n",
    "from peft import PeftModel\n",
    "\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    \"outputs_marooned_rl/checkpoint-300\",  # Path to your trained checkpoint\n",
    ")\n",
    "\n",
    "print(\"âœ… Trained model loaded!\")\n",
    "```\n",
    "\n",
    "Then run the same tests above to see if the trained model:\n",
    "- âœ… Makes smarter moves\n",
    "- âœ… Gathers resources more efficiently\n",
    "- âœ… Builds the ship strategically\n",
    "- âœ… Uses social deduction (lies as traitor, detects as colonist)\n",
    "- âœ… Earns higher rewards\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047e40d",
   "metadata": {},
   "source": [
    "## âœ… Success Checklist\n",
    "\n",
    "After running this notebook, you should see:\n",
    "\n",
    "- [x] Environment loads successfully\n",
    "- [x] Model generates responses\n",
    "- [x] Actions are parsed correctly\n",
    "- [x] Actions execute in environment\n",
    "- [x] Rewards are calculated (Phase 4 system)\n",
    "- [x] Multiple turns run without errors\n",
    "- [x] Agent shows some coherent behavior\n",
    "\n",
    "**Base model** (untrained) will likely:\n",
    "- â“ Make random or simple moves\n",
    "- â“ Not follow complex strategies\n",
    "- â“ Get low rewards\n",
    "\n",
    "**After training**, the model should:\n",
    "- âœ… Navigate purposefully toward resources\n",
    "- âœ… Gather and deposit efficiently\n",
    "- âœ… Coordinate ship building\n",
    "- âœ… Use deception (if traitor) or detection (if colonist)\n",
    "- âœ… Earn higher average rewards\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Next Steps:\n",
    "\n",
    "1. **Run this notebook** to test base model\n",
    "2. **Train model** using `Train_Marooned_OpenEnv_RL.ipynb`\n",
    "3. **Come back here** to test trained model\n",
    "4. **Compare performance** - did training help?\n",
    "5. **Iterate** - adjust rewards, prompts, training params\n",
    "\n",
    "Good luck! ğŸ´â€â˜ ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c96c2a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Summary: System Prompt vs User Prompt\n",
    "\n",
    "### The Proper Two-Prompt Architecture:\n",
    "\n",
    "**1. SYSTEM PROMPT** (Set ONCE at initialization):\n",
    "```\n",
    "Role: system\n",
    "Content: Complete game rules, mechanics, objectives, win conditions, strategy tips\n",
    "\n",
    "For Colonist:\n",
    "- Game overview (5 sailors, rebuild ship, find traitor)\n",
    "- Ship construction requirements\n",
    "- Energy system, poison mechanics\n",
    "- Detection strategies\n",
    "- Win conditions\n",
    "\n",
    "For Traitor:\n",
    "- Game overview (same island, different goal)\n",
    "- Sabotage tactics, deception techniques\n",
    "- Poison strategy, special abilities\n",
    "- Win conditions\n",
    "```\n",
    "\n",
    "**2. USER PROMPT** (Changes EVERY turn):\n",
    "```\n",
    "Role: user\n",
    "Content: Current observation ONLY\n",
    "\n",
    "- Day/Turn/Phase\n",
    "- Current position, energy, backpack\n",
    "- Spatial view (11Ã—11 grid)\n",
    "- Nearby resources, sailors\n",
    "- Ship progress\n",
    "- Team status\n",
    "- Available actions\n",
    "```\n",
    "\n",
    "### Why This Is Better:\n",
    "\n",
    "âœ… **Token Efficiency:**\n",
    "- System prompt: ~1,500 tokens (set once)\n",
    "- User prompt: ~800 tokens (changes each turn)\n",
    "- Old way: ~2,300 tokens every turn\n",
    "- New way: 1,500 (once) + 800 (per turn) = massive savings\n",
    "\n",
    "âœ… **Cleaner Separation:**\n",
    "- Game rules = System (doesn't change)\n",
    "- Current state = User (updates constantly)\n",
    "\n",
    "âœ… **Better Training:**\n",
    "- Model learns game rules are constant context\n",
    "- Observations are dynamic input\n",
    "- Clearer prompt structure\n",
    "\n",
    "âœ… **Role-Specific Context:**\n",
    "- Colonists get colonist strategies\n",
    "- Traitor gets sabotage tactics\n",
    "- No wasted tokens on irrelevant info\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38677d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Understanding Your Game's RL Training\n",
    "\n",
    "### How is MAROONED different from 2048?\n",
    "\n",
    "| Aspect | 2048 | MAROONED |\n",
    "|--------|------|----------|\n",
    "| **Objective** | Merge tiles to reach 2048 | Social deduction + ship building |\n",
    "| **Agents** | 1 player | 5 agents (4 colonists, 1 traitor) |\n",
    "| **Deception** | None | Core mechanic (lying, sabotage) |\n",
    "| **Communication** | None | Critical (accusations, voting) |\n",
    "| **State Space** | 4Ã—4 grid (small) | 30Ã—30Ã—3 map (large) |\n",
    "| **Actions** | 4 moves | 20+ actions (move, gather, build, vote, poison, etc.) |\n",
    "| **Training Goal** | Find optimal move sequence | Learn strategic deception OR detection |\n",
    "\n",
    "### What Makes MAROONED Challenging for RL:\n",
    "\n",
    "1. **Multi-Agent Dynamics**\n",
    "   - 5 agents with competing objectives\n",
    "   - Colonists must cooperate, traitor must deceive\n",
    "   - Reward depends on OTHER agents' behavior\n",
    "\n",
    "2. **Partial Observability**\n",
    "   - Can only see 5-tile radius\n",
    "   - Don't know who is traitor (until evidence accumulates)\n",
    "   - Must infer hidden information\n",
    "\n",
    "3. **Long-Horizon Planning**\n",
    "   - 100 days Ã— 100 turns = 10,000 time steps\n",
    "   - Ship building requires sustained effort\n",
    "   - Deception must be subtle (not caught early)\n",
    "\n",
    "4. **Language-Based Actions**\n",
    "   - Not just \"move left\" but \"ACCUSE Bob of being traitor because...\"\n",
    "   - Requires generating coherent communication\n",
    "   - Must parse and respond to other agents' messages\n",
    "\n",
    "5. **Sparse Rewards**\n",
    "   - Ship completion: +100 (only at end)\n",
    "   - Traitor elimination: +50 (rare event)\n",
    "   - Gather/deposit: +0.5 to +2 (frequent but small)\n",
    "   - Energy penalties: -0.1 per turn (constant cost)\n",
    "\n",
    "### Your Reward Structure (from Phase 4):\n",
    "\n",
    "**Colonist Rewards:**\n",
    "```python\n",
    "+0.5   : Gather resource\n",
    "+1.0   : Deposit resource\n",
    "+2.0   : Build ship component\n",
    "+10/20/30 : Ship milestones (25%, 50%, 75%)\n",
    "+100   : Ship completion (WIN!)\n",
    "+50    : Traitor eliminated\n",
    "+5     : Correct vote\n",
    "-5     : Wrong vote\n",
    "-20    : Death\n",
    "```\n",
    "\n",
    "**Traitor Rewards:**\n",
    "```python\n",
    "+5     : Successful sabotage\n",
    "+20    : Poison kill\n",
    "+100   : Ship incomplete by Day 100 (WIN!)\n",
    "-50    : Eliminated by vote\n",
    "-2     : Suspicion raised\n",
    "```\n",
    "\n",
    "### Training Strategy:\n",
    "\n",
    "Unlike 2048 (deterministic moves â†’ win), MAROONED requires:\n",
    "\n",
    "1. **Curriculum Learning**\n",
    "   - Start: Simple tasks (gather wood, build ship)\n",
    "   - Middle: Resource optimization, energy management\n",
    "   - Advanced: Social deduction, deception tactics\n",
    "\n",
    "2. **Separate Training Phases**\n",
    "   - Phase A: Train colonists to cooperate (no traitor)\n",
    "   - Phase B: Train traitor to sabotage (against scripted colonists)\n",
    "   - Phase C: Train both together (full game)\n",
    "\n",
    "3. **Reward Shaping**\n",
    "   - Early: Heavy reward for basic actions (gather, deposit)\n",
    "   - Mid: Reward efficiency (gather 10 wood > gather 1 wood 10 times)\n",
    "   - Late: Reward strategy (vote correctly, detect lies)\n",
    "\n",
    "4. **Multi-Agent RL Algorithms**\n",
    "   - GRPO works for single-agent RL (2048)\n",
    "   - For MAROONED, consider:\n",
    "     - Self-play (agents train against themselves)\n",
    "     - Population-based training (diverse strategies)\n",
    "     - Centralized training, decentralized execution (CTDE)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š References & Resources\n",
    "\n",
    "**Phase Documentation:**\n",
    "- `game_plan.md` - Complete game design\n",
    "- `phase1_core_simulation.ipynb` - Basic mechanics\n",
    "- `phase2_multi_sailor.ipynb` - Multi-agent system\n",
    "- `phase3_traitor.ipynb` - Deception mechanics\n",
    "- `phase4_rewards.ipynb` - **Your reward functions**\n",
    "- `phase5_openenv.ipynb` - **Environment API**\n",
    "- `phase6_llm_policy_demo.ipynb` - LLM integration\n",
    "\n",
    "**Marooned Environment:**\n",
    "- `marooned_env/environment.py` - Main env class\n",
    "- `marooned_env/config.py` - All constants, rewards\n",
    "- `marooned_env/models.py` - Data structures\n",
    "- `marooned_env/llm_interface.py` - **Prompt templates**\n",
    "\n",
    "**Training:**\n",
    "- `Train_Marooned_OpenEnv_RL.ipynb` - Full RL training pipeline (TODO: create this!)\n",
    "- `OpenEnv_NEW.ipynb` - 2048 example (reference)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac21ca3",
   "metadata": {},
   "source": [
    "## âœ… Completion Checklist\n",
    "\n",
    "After running this notebook, you should have:\n",
    "\n",
    "- [x] **Environment validated** - Marooned loads and resets correctly\n",
    "- [x] **LLM loaded** - Llama 3.1 8B running on MI300X\n",
    "- [x] **Observations work** - Game state â†’ text prompt conversion\n",
    "- [x] **Actions parse** - LLM response â†’ executable action\n",
    "- [x] **Actions execute** - Environment processes moves correctly  \n",
    "- [x] **Rewards calculated** - Phase 4 reward system active\n",
    "- [x] **Multi-turn stable** - Can run 5+ consecutive turns\n",
    "- [x] **Scenarios tested** - Gathering, navigation, building, sabotage, communication\n",
    "\n",
    "### ğŸ¯ What You Validated:\n",
    "\n",
    "âœ… **Technical Integration:**\n",
    "- Environment â†” LLM communication works\n",
    "- Prompt engineering (system + user prompts)\n",
    "- Action parsing (structured output from LLM)\n",
    "- Reward signals (colonist vs traitor objectives)\n",
    "\n",
    "âœ… **Game Mechanics:**\n",
    "- Movement and spatial navigation\n",
    "- Resource gathering and inventory\n",
    "- Ship construction mechanics\n",
    "- Social deduction (evidence, voting)\n",
    "- Traitor sabotage abilities\n",
    "\n",
    "âœ… **AI Capabilities (Untrained Base Model):**\n",
    "- Can generate syntactically valid responses\n",
    "- Understands basic game rules (from system prompt)\n",
    "- Makes simple decisions (move toward resources)\n",
    "- **BUT:** Likely suboptimal, random, no strategy\n",
    "\n",
    "### ğŸš€ Next Steps:\n",
    "\n",
    "1. **âœ… DONE:** Base model can play the game\n",
    "2. **TODO:** Create `Train_Marooned_OpenEnv_RL.ipynb` for RL training\n",
    "3. **TODO:** Design reward functions specific to your game (already in Phase 4!)\n",
    "4. **TODO:** Train model for 1000-5000 steps\n",
    "5. **TODO:** Return here to test trained model vs untrained\n",
    "\n",
    "### ğŸ“ Expected Training Improvements:\n",
    "\n",
    "**Untrained (Now):**\n",
    "- Random exploration\n",
    "- No resource efficiency\n",
    "- No social strategy\n",
    "- ~0-5 average reward per turn\n",
    "\n",
    "**After Training (Goal):**\n",
    "- Purposeful navigation to resources\n",
    "- Efficient gathering â†’ deposit â†’ build loops\n",
    "- Strategic communication (as colonist)\n",
    "- Deceptive behavior (as traitor)\n",
    "- ~10-30 average reward per turn\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck with your RL training! ğŸ´â€â˜ ï¸**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
