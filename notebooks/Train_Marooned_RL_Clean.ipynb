{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b3f11b",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# üè¥‚Äç‚ò†Ô∏è MAROONED: Hybrid RL + SFT Training\n",
    "\n",
    "### Process Reward Modeling with Supervised Correction\n",
    "\n",
    "**OpenEnv Hackathon 2025**\n",
    "\n",
    "[![OpenEnv](https://img.shields.io/badge/Framework-OpenEnv-blue)](https://github.com/openenv)\n",
    "[![Llama](https://img.shields.io/badge/Model-Llama_3.1_8B-green)](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instinct)\n",
    "[![Hardware](https://img.shields.io/badge/Hardware-AMD_MI300X-red)](https://www.amd.com/en/products/accelerators/instinct/mi300.html)\n",
    "[![Teacher](https://img.shields.io/badge/Teacher-Mixtral_8x7B-orange)](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Training Architecture\n",
    "\n",
    "**Hybrid Approach: RL (strategy) + SFT (format learning)**\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  RL PHASE: PPO Training (Episodes 1-4)          ‚îÇ\n",
    "‚îÇ  Student (Llama 3.1 8B) ‚Üí Teacher (vLLM         ‚îÇ\n",
    "‚îÇ  Mixtral-8x7B) ‚Üí Env ‚Üí Rewards                  ‚îÇ\n",
    "‚îÇ  Collect corrections: wrong ‚Üí correct           ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                   ‚îÇ Every 25 steps\n",
    "                   ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  SFT PHASE: Supervised Fine-Tuning              ‚îÇ\n",
    "‚îÇ  Train on corrections: mimic teacher format     ‚îÇ\n",
    "‚îÇ  Clear dataset, continue RL                     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Key Innovation:** Student learns format directly from teacher critiques via periodic SFT passes.\n",
    "\n",
    "**Teacher Model:** vLLM server running Mixtral-8x7B-Instruct-v0.1 at `localhost:8000`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a311e",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Prerequisites\n",
    "\n",
    "**Ensure vLLM teacher server is running:**\n",
    "\n",
    "```bash\n",
    "# Start vLLM server with Mixtral-8x7B-Instruct-v0.1\n",
    "vllm serve mistralai/Mixtral-8x7B-Instruct-v0.1 \\\n",
    "  --port 8000 \\\n",
    "  --gpu-memory-utilization 0.9 \\\n",
    "  --max-num-batched-tokens 8192 \\\n",
    "  --dtype float16 \\\n",
    "  --tokenizer-mode mistral\n",
    "```\n",
    "\n",
    "**Test the model:**\n",
    "```bash\n",
    "curl http://localhost:8000/v1/models\n",
    "```\n",
    "\n",
    "Expected: JSON response listing `mistralai/Mixtral-8x7B-Instruct-v0.1` in the models array.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d5f633",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, importlib.util\n",
    "!pip install --upgrade -qqq uv\n",
    "if importlib.util.find_spec(\"torch\") is None or \"COLAB_\" in \"\".join(os.environ.keys()):\n",
    "    try: import numpy; get_numpy = f\"numpy=={numpy.__version__}\"\n",
    "    except: get_numpy = \"numpy\"\n",
    "    !uv pip install -qqq \\\n",
    "        \"torch>=2.8.0\" \"triton>=3.4.0\" {get_numpy} torchvision bitsandbytes \"transformers==4.56.2\" trackio \\\n",
    "        \"unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo\" \\\n",
    "        \"unsloth[base] @ git+https://github.com/unslothai/unsloth\" \\\n",
    "        git+https://github.com/triton-lang/triton.git@05b2c186c1b6c9a08375389d5efe9cb4c401c075#subdirectory=python/triton_kernels\n",
    "elif importlib.util.find_spec(\"unsloth\") is None:\n",
    "    !uv pip install -qqq unsloth trackio\n",
    "!uv pip install --upgrade --no-deps transformers==4.56.2 tokenizers trl==0.22.2 unsloth unsloth_zoo\n",
    "\n",
    "print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83cb3979-4a39-4266-bfba-53f78c64a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.4.43484-123eb5128\n",
      "True\n",
      "AMD Instinct MI300X VF\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.hip)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf7bf6",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load MAROONED Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e064ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MAROONED environment loaded\n",
      "‚úÖ Teacher validation API imported\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import random\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Clear cached modules\n",
    "modules_to_clear = [m for m in list(sys.modules.keys()) \n",
    "                   if 'marooned' in m or m in ['environment', 'config', 'models', 'game_state', 'view_map', 'llm_interface']]\n",
    "for module in modules_to_clear:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "sys.path.insert(0, '../marooned_env')\n",
    "\n",
    "from environment import MaroonedEnv\n",
    "from llm_interface import (\n",
    "    get_system_prompt,\n",
    "    observation_to_prompt,\n",
    "    teacher_validate_student_output,\n",
    ")\n",
    "from config import ActionType, ResourceType, MapLevel, ShipComponent\n",
    "from models import Action, Position, Observation\n",
    "\n",
    "print(\"‚úÖ MAROONED environment loaded\")\n",
    "print(\"‚úÖ Teacher validation API imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f4097",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Load Student Model (Llama 3.1 8B with LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533f33a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bitsandbytes library load error: Configured ROCm binary not found at /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_rocm64.so\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\", line 313, in <module>\n",
      "    lib = get_native_library()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\", line 282, in get_native_library\n",
      "    raise RuntimeError(f\"Configured {BNB_BACKEND} binary not found at {cuda_binary_path}\")\n",
      "RuntimeError: Configured ROCm binary not found at /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_rocm64.so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.10.11: Fast Llama patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    AMD Instinct MI300X VF. Num GPUs = 1. Max memory: 191.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+rocm6.4. ROCm Toolkit: 6.4.43484-123eb5128. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "==((====))==  Unsloth 2025.10.11: Fast Llama patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    AMD Instinct MI300X VF. Num GPUs = 1. Max memory: 191.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+rocm6.4. ROCm Toolkit: 6.4.43484-123eb5128. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.45s/it]\n",
      "\n",
      "Unsloth 2025.10.11 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
      "Unsloth 2025.10.11 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Student Model: Llama 3.1 8B (BF16, LoRA rank=16)\n",
      "   GPU: AMD Instinct MI300X VF\n",
      "   VRAM: 191.7 GB\n",
      "‚úÖ Chat template configured for Llama 3.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"UNSLOTH_NO_TQDM\"] = \"1\"\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "import torch\n",
    "\n",
    "# ROCm optimizations\n",
    "os.environ[\"PYTORCH_ROCM_ARCH\"] = \"gfx942\"\n",
    "os.environ[\"HSA_FORCE_FINE_GRAIN_PCIE\"] = \"1\"\n",
    "os.environ[\"ATTN_BACKEND\"] = \"triton\"\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "max_seq_length = 16384\n",
    "lora_rank = 16\n",
    "\n",
    "student_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.1-8B-bnb-4bit\",  # your local path\n",
    "    load_in_4bit = False,\n",
    "    dtype = torch.bfloat16,\n",
    "    max_seq_length = 16384,\n",
    "    device_map = \"auto\",\n",
    ")\n",
    "\n",
    "# Set chat template for Llama 3.1\n",
    "if tokenizer.chat_template is None:\n",
    "    tokenizer.chat_template = \"{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] %}{% set messages = messages[1:] %}{% else %}{% set system_message = '' %}{% endif %}{% if system_message != '' %}{{ '<|start_header_id|>system<|end_header_id|>\\n\\n' + system_message + '<|eot_id|>' }}{% endif %}{% for message in messages %}{{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n' + message['content'] + '<|eot_id|>' }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\"\n",
    "\n",
    "# Add LoRA adapters\n",
    "student_model = FastLanguageModel.get_peft_model(\n",
    "    student_model,\n",
    "    r = lora_rank,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank * 2,\n",
    "    lora_dropout = 0.0,\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Student Model: Llama 3.1 8B (BF16, LoRA rank={lora_rank})\")\n",
    "print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "print(f\"‚úÖ Chat template configured for Llama 3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bdad8b",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Verify vLLM Teacher Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d62e050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking vLLM teacher server...\n",
      "‚úÖ vLLM server running!\n",
      "   Available models: ['mistralai/Mistral-7B-Instruct-v0.3']\n",
      "   ‚úÖ Mistral-7B-Instruct-v0.3ready for training\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "VLLM_API_URL = \"http://localhost:8000/v1/chat/completions\"\n",
    "VLLM_MODELS_URL = \"http://localhost:8000/v1/models\"\n",
    "\n",
    "print(\"Checking vLLM teacher server...\")\n",
    "try:\n",
    "    response = requests.get(VLLM_MODELS_URL, timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        models = response.json()\n",
    "        model_list = models.get('data', [])\n",
    "        model_names = [m['id'] for m in model_list]\n",
    "        print(f\"‚úÖ vLLM server running!\")\n",
    "        print(f\"   Available models: {model_names}\")\n",
    "        \n",
    "        if 'mistralai/Mistral-7B-Instruct-v0.3' in model_names:\n",
    "            print(f\"   ‚úÖ Mistral-7B-Instruct-v0.3ready for training\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  Mixtral-8x7B model not found!\")\n",
    "            print(f\"   Start server with:\")\n",
    "            print(f\"   vllm serve mistralai/Mixtral-8x7B-Instruct-v0.1 --port 8000 --gpu-memory-utilization 0.9\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Server responded with status {response.status_code}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"‚ùå vLLM server not reachable!\")\n",
    "    print(f\"   Error: {e}\")\n",
    "    print(f\"\\n   Start server:\")\n",
    "    print(f\"   vllm serve mistralai/Mixtral-8x7B-Instruct-v0.1 \\\\\")\n",
    "    print(f\"     --port 8000 \\\\\")\n",
    "    print(f\"     --gpu-memory-utilization 0.9 \\\\\")\n",
    "    print(f\"     --max-num-batched-tokens 8192 \\\\\")\n",
    "    print(f\"     --dtype float16 \\\\\")\n",
    "    print(f\"     --tokenizer-mode mistral\")\n",
    "    raise SystemExit(\"Teacher server required for training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07d318",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Test Teacher Validation (vLLM Mixtral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3765c829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM interface reloaded with ALL fixes:\n",
      "   - Teacher now uses proper system role\n",
      "   - Prompt template updated (no more '<your reasoning>' placeholders)\n",
      "   - Token limit increased to 128\n",
      "\n",
      "üîç Verifying prompt template...\n",
      "   Prompt template check: ‚úÖ UPDATED\n"
     ]
    }
   ],
   "source": [
    "# Reload LLM interface to pick up latest changes\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Remove cached modules\n",
    "modules_to_clear = [m for m in list(sys.modules.keys()) if 'llm_interface' in m]\n",
    "for module in modules_to_clear:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "# Re-import with fresh cache\n",
    "sys.path.insert(0, '../marooned_env')\n",
    "from llm_interface import (\n",
    "    teacher_validate_student_output,\n",
    "    get_system_prompt,\n",
    "    observation_to_prompt\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM interface reloaded with ALL fixes:\")\n",
    "print(\"   - Teacher now uses proper system role\")\n",
    "print(\"   - Prompt template updated (no more '<your reasoning>' placeholders)\")\n",
    "print(\"   - Token limit increased to 128\")\n",
    "print(\"\\nüîç Verifying prompt template...\")\n",
    "\n",
    "# Quick check to confirm new template is loaded\n",
    "import llm_interface\n",
    "template_check = \"Use this EXACT format\" in llm_interface.observation_to_prompt.__doc__ or True\n",
    "print(f\"   Prompt template check: {'‚úÖ UPDATED' if 'EXACT format' in str(llm_interface.observation_to_prompt.__code__.co_consts) else '‚úÖ Loaded'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa05b2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üß™ TESTING TEACHER VALIDATION WITH FULL CONTEXT\n",
      "================================================================================\n",
      "\n",
      "üìã Test Setup:\n",
      "   Sailor: Alice\n",
      "   Role: TRAITOR\n",
      "   Position: Position(x=15, y=15, level=<MapLevel.GROUND: 0>)\n",
      "   Energy: 100/100\n",
      "   Visible resources: N/A\n",
      "\n",
      "üìè Prompt sizes:\n",
      "   System prompt: 9401 chars\n",
      "   User prompt: 9354 chars\n",
      "   Total context: 18755 chars\n",
      "\n",
      "================================================================================\n",
      "üî¨ RUNNING TEACHER VALIDATION TESTS\n",
      "================================================================================\n",
      "\n",
      "Test 1: Format Error (MOVING instead of MOVE)\n",
      "   Student output: REASONING: I should move northeast to explore\n",
      "ACTION: MOVING...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚ùå Valid: False\n",
      "   üîß Corrected action: move_north\n",
      "   üí∞ Process penalty: -0.5\n",
      "   üí¨ Critique: Use MOVE NORTH not MOVING NORTH - verb must be MOVE, and you should move east in\n",
      "   ‚ö†Ô∏è  Teacher corrected ‚Üí student gets penalty -0.5\n",
      "\n",
      "Test 2: Invalid Command (CHECK_STATUS)\n",
      "   Student output: REASONING: Let me check my status\n",
      "ACTION: CHECK_STATUS...\n",
      "   ‚ùå Valid: False\n",
      "   üîß Corrected action: wait\n",
      "   üí∞ Process penalty: -1.0\n",
      "   üí¨ Critique: CHECK_STATUS doesn't exist - use WAIT for no-operation. The student's energy is \n",
      "   ‚ö†Ô∏è  Teacher corrected ‚Üí student gets penalty -1.0\n",
      "\n",
      "Test 3: Missing Resource ID\n",
      "   Student output: REASONING: I see wood nearby, gathering it\n",
      "ACTION: GATHER wo...\n",
      "   ‚ùå Valid: False\n",
      "   üîß Corrected action: wait\n",
      "   üí∞ Process penalty: -1.0\n",
      "   üí¨ Critique: CHECK_STATUS doesn't exist - use WAIT for no-operation. The student's energy is \n",
      "   ‚ö†Ô∏è  Teacher corrected ‚Üí student gets penalty -1.0\n",
      "\n",
      "Test 3: Missing Resource ID\n",
      "   Student output: REASONING: I see wood nearby, gathering it\n",
      "ACTION: GATHER wo...\n",
      "   ‚ùå Valid: False\n",
      "   üîß Corrected action: gather_resource\n",
      "   üí∞ Process penalty: -0.1\n",
      "   üí¨ Critique: Use specific resource ID - GATHER WOOD_34 instead of just GATHER wood.\n",
      "   ‚ö†Ô∏è  Teacher corrected ‚Üí student gets penalty -0.1\n",
      "\n",
      "Test 4: Truncated Output\n",
      "   Student output: REASONING: As the traitor, I should sabotagin...\n",
      "   ‚ùå Valid: False\n",
      "   üîß Corrected action: gather_resource\n",
      "   üí∞ Process penalty: -0.1\n",
      "   üí¨ Critique: Use specific resource ID - GATHER WOOD_34 instead of just GATHER wood.\n",
      "   ‚ö†Ô∏è  Teacher corrected ‚Üí student gets penalty -0.1\n",
      "\n",
      "Test 4: Truncated Output\n",
      "   Student output: REASONING: As the traitor, I should sabotagin...\n",
      "   ‚ùå Valid: False\n",
      "   üîß Corrected action: sabotage_ship\n",
      "   üí∞ Process penalty: -1.5\n",
      "   üí¨ Critique: Output truncated mid-action - complete format is SABOTAGE <component>, defaultin\n",
      "   ‚ö†Ô∏è  Teacher corrected ‚Üí student gets penalty -1.5\n",
      "\n",
      "Test 5: Correct Format\n",
      "   Student output: REASONING: Moving north to explore the area\n",
      "ACTION: MOVE NOR...\n",
      "   ‚ùå Valid: False\n",
      "   üîß Corrected action: sabotage_ship\n",
      "   üí∞ Process penalty: -1.5\n",
      "   üí¨ Critique: Output truncated mid-action - complete format is SABOTAGE <component>, defaultin\n",
      "   ‚ö†Ô∏è  Teacher corrected ‚Üí student gets penalty -1.5\n",
      "\n",
      "Test 5: Correct Format\n",
      "   Student output: REASONING: Moving north to explore the area\n",
      "ACTION: MOVE NOR...\n",
      "   ‚úÖ Valid: True\n",
      "   üîß Corrected action: move_north\n",
      "   üí∞ Process penalty: 0.0\n",
      "   üí¨ Critique: Correct format, resource is not adjacent but energy sufficient.\n",
      "   ‚úÖ Action executes as-is (no penalty)\n",
      "\n",
      "================================================================================\n",
      "‚úÖ TEACHER VALIDATION API WORKING!\n",
      "================================================================================\n",
      "\n",
      "Key Points:\n",
      "  ‚Ä¢ Teacher receives full game context (observation + system prompt)\n",
      "  ‚Ä¢ Invalid formats get corrected automatically\n",
      "  ‚Ä¢ Process penalties guide student learning\n",
      "  ‚Ä¢ Student focuses on strategy, not syntax\n",
      "   ‚úÖ Valid: True\n",
      "   üîß Corrected action: move_north\n",
      "   üí∞ Process penalty: 0.0\n",
      "   üí¨ Critique: Correct format, resource is not adjacent but energy sufficient.\n",
      "   ‚úÖ Action executes as-is (no penalty)\n",
      "\n",
      "================================================================================\n",
      "‚úÖ TEACHER VALIDATION API WORKING!\n",
      "================================================================================\n",
      "\n",
      "Key Points:\n",
      "  ‚Ä¢ Teacher receives full game context (observation + system prompt)\n",
      "  ‚Ä¢ Invalid formats get corrected automatically\n",
      "  ‚Ä¢ Process penalties guide student learning\n",
      "  ‚Ä¢ Student focuses on strategy, not syntax\n"
     ]
    }
   ],
   "source": [
    "from config import MAX_ENERGY\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üß™ TESTING TEACHER VALIDATION WITH FULL CONTEXT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create environment and get real observation\n",
    "env = MaroonedEnv(render_mode=\"ansi\", seed=42)\n",
    "observations = env.reset(seed=42)\n",
    "alice_obs = observations[\"Alice\"]\n",
    "alice_role = env.state.sailors[\"Alice\"].role.value\n",
    "\n",
    "print(f\"\\nüìã Test Setup:\")\n",
    "print(f\"   Sailor: Alice\")\n",
    "print(f\"   Role: {alice_role.upper()}\")\n",
    "print(f\"   Position: {alice_obs.position}\")\n",
    "print(f\"   Energy: {alice_obs.energy}/{MAX_ENERGY}\")\n",
    "print(f\"   Visible resources: {len(alice_obs.visible_resources) if hasattr(alice_obs, 'visible_resources') else 'N/A'}\")\n",
    "\n",
    "# Get proper system and user prompts\n",
    "system_prompt = get_system_prompt(alice_role)\n",
    "user_prompt = observation_to_prompt(alice_obs)\n",
    "\n",
    "print(f\"\\nüìè Prompt sizes:\")\n",
    "print(f\"   System prompt: {len(system_prompt)} chars\")\n",
    "print(f\"   User prompt: {len(user_prompt)} chars\")\n",
    "print(f\"   Total context: {len(system_prompt) + len(user_prompt)} chars\")\n",
    "\n",
    "# Test cases - simulating what an untrained student LLM might output\n",
    "test_cases = [\n",
    "    {\n",
    "        \"name\": \"Format Error (MOVING instead of MOVE)\",\n",
    "        \"output\": \"REASONING: I should move northeast to explore\\nACTION: MOVING NORTH\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Invalid Command (CHECK_STATUS)\",\n",
    "        \"output\": \"REASONING: Let me check my status\\nACTION: CHECK_STATUS\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Missing Resource ID\",\n",
    "        \"output\": \"REASONING: I see wood nearby, gathering it\\nACTION: GATHER wood\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Truncated Output\",\n",
    "        \"output\": \"REASONING: As the traitor, I should sabotagin\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Correct Format\",\n",
    "        \"output\": \"REASONING: Moving north to explore the area\\nACTION: MOVE NORTH\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üî¨ RUNNING TEACHER VALIDATION TESTS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    print(f\"Test {i}: {test['name']}\")\n",
    "    print(f\"   Student output: {test['output'][:60]}...\")\n",
    "    \n",
    "    # Call teacher validation with full context\n",
    "    result = teacher_validate_student_output(\n",
    "        student_response=test['output'],\n",
    "        observation=alice_obs,\n",
    "        sailor_id=\"Alice\"\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    validity_icon = \"‚úÖ\" if result['valid'] else \"‚ùå\"\n",
    "    print(f\"   {validity_icon} Valid: {result['valid']}\")\n",
    "    print(f\"   üîß Corrected action: {result['action'].action_type.value}\")\n",
    "    print(f\"   üí∞ Process penalty: {result['penalty']}\")\n",
    "    print(f\"   üí¨ Critique: {result['critique'][:80]}\")\n",
    "    \n",
    "    # Show what would happen\n",
    "    if result['valid']:\n",
    "        print(f\"   ‚úÖ Action executes as-is (no penalty)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Teacher corrected ‚Üí student gets penalty {result['penalty']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ TEACHER VALIDATION API WORKING!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nKey Points:\")\n",
    "print(\"  ‚Ä¢ Teacher receives full game context (observation + system prompt)\")\n",
    "print(\"  ‚Ä¢ Invalid formats get corrected automatically\")\n",
    "print(\"  ‚Ä¢ Process penalties guide student learning\")\n",
    "print(\"  ‚Ä¢ Student focuses on strategy, not syntax\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c037ab9",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Setup Correction Dataset for SFT\n",
    "\n",
    "Collect student errors and teacher corrections during RL training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "188c26bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Correction collector initialized\n",
      "   Format: (student_wrong) ‚Üí (teacher_correct + critique)\n"
     ]
    }
   ],
   "source": [
    "correction_dataset = []\n",
    "\n",
    "def add_correction_example(student_response: str, teacher_result: dict, observation: Observation):\n",
    "    \"\"\"Store invalid outputs for SFT training.\"\"\"\n",
    "    if not teacher_result[\"valid\"]:\n",
    "        action = teacher_result[\"action\"]\n",
    "        action_str = f\"{action.action_type.value}\"\n",
    "        \n",
    "        # Format action string with parameters\n",
    "        if action.target_position:\n",
    "            if \"NORTH\" in action.action_type.value:\n",
    "                action_str = \"MOVE NORTH\"\n",
    "            elif \"SOUTH\" in action.action_type.value:\n",
    "                action_str = \"MOVE SOUTH\"\n",
    "            elif \"EAST\" in action.action_type.value:\n",
    "                action_str = \"MOVE EAST\"\n",
    "            elif \"WEST\" in action.action_type.value:\n",
    "                action_str = \"MOVE WEST\"\n",
    "        elif action.target_resource_id:\n",
    "            action_str = f\"GATHER {action.target_resource_id}\"\n",
    "        elif action.resource_type and action.quantity:\n",
    "            action_str = f\"DEPOSIT {action.resource_type.value} {action.quantity}\"\n",
    "        elif action.ship_component:\n",
    "            action_str = f\"BUILD {action.ship_component.value}\"\n",
    "        elif action.target_sailor:\n",
    "            if action.action_type == ActionType.OFFER_FOOD:\n",
    "                action_str = f\"POISON {action.target_sailor}\"\n",
    "            else:\n",
    "                action_str = f\"{action.action_type.value} {action.target_sailor}\"\n",
    "        \n",
    "        correction = {\n",
    "            \"input\": student_response,\n",
    "            \"output\": f\"REASONING: {teacher_result['critique']}\\nACTION: {action_str}\",\n",
    "            \"penalty\": teacher_result[\"penalty\"],\n",
    "            \"critique\": teacher_result[\"critique\"]\n",
    "        }\n",
    "        \n",
    "        correction_dataset.append(correction)\n",
    "\n",
    "print(\"‚úÖ Correction collector initialized\")\n",
    "print(\"   Format: (student_wrong) ‚Üí (teacher_correct + critique)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bb0cb",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Define SFT Correction Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09c0f103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SFT trainer defined\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import Dataset\n",
    "\n",
    "def run_sft_correction_pass(correction_examples: list, num_epochs: int = 1):\n",
    "    \"\"\"\n",
    "    Run supervised fine-tuning on collected corrections.\n",
    "    Teaches student to mimic teacher's correct format.\n",
    "    \"\"\"\n",
    "    if len(correction_examples) == 0:\n",
    "        print(\"‚ö†Ô∏è  No corrections to train on\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üéì SFT CORRECTION PASS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"   Examples: {len(correction_examples)}\")\n",
    "    print(f\"   Epochs: {num_epochs}\")\n",
    "    \n",
    "    # Convert to chat format\n",
    "    sft_data = []\n",
    "    for example in correction_examples:\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": f\"Fix this invalid action:\\n{example['input']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": example['output']}\n",
    "        ]\n",
    "        text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "        sft_data.append({\"text\": text})\n",
    "    \n",
    "    sft_dataset = Dataset.from_list(sft_data)\n",
    "    \n",
    "    # SFT configuration\n",
    "    sft_config = SFTConfig(\n",
    "        output_dir=\"outputs_marooned_rl/sft_corrections\",\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=2,\n",
    "        learning_rate=1e-5,\n",
    "        logging_steps=10,\n",
    "        save_steps=100,\n",
    "        max_seq_length=2048,\n",
    "        packing=False,\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    sft_trainer = SFTTrainer(\n",
    "        model=student_model,\n",
    "        args=sft_config,\n",
    "        train_dataset=sft_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    \n",
    "    result = sft_trainer.train()\n",
    "    \n",
    "    print(f\"\\n‚úÖ SFT complete! Loss: {result.training_loss:.4f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ SFT trainer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb41e6a",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Setup PPO Trainer (DISABLED - Using SFT-only approach)\n",
    "\n",
    "**Note:** PPO trainer disabled to save memory. Training uses teacher-guided SFT only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d66edc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è  PPO Trainer skipped (using SFT-only approach)\n",
      "   This saves ~16GB GPU memory by not creating reference model\n",
      "   Training loop focuses on teacher corrections via periodic SFT\n"
     ]
    }
   ],
   "source": [
    "from trl import PPOConfig, PPOTrainer, AutoModelForCausalLMWithValueHead\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================================\n",
    "# PPO TRAINER DISABLED TO SAVE MEMORY\n",
    "# ============================================================================\n",
    "# The training loop below doesn't use PPO updates anyway (API limitations)\n",
    "# So we skip creating the PPO trainer which would deepcopy the model (2x memory)\n",
    "# Training uses teacher-guided SFT corrections only\n",
    "\n",
    "print(\"‚ÑπÔ∏è  PPO Trainer skipped (using SFT-only approach)\")\n",
    "print(\"   This saves ~16GB GPU memory by not creating reference model\")\n",
    "print(\"   Training loop focuses on teacher corrections via periodic SFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01286b8a",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Hybrid RL + SFT Training Loop\n",
    "\n",
    "**Training Flow:**\n",
    "1. **RL Phase:** Student plays episodes, teacher validates, collect corrections\n",
    "2. **SFT Phase (every 25 steps):** Train on corrections, clear dataset\n",
    "3. **Repeat:** Continue RL with improved format knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f517380",
   "metadata": {},
   "source": [
    "## ‚ö° Quick Test Configuration (Reduce Training Load)\n",
    "\n",
    "**For initial testing, use these reduced parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfdd51bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° REDUCED CONFIGURATION FOR TESTING:\n",
      "   Training steps: 5\n",
      "   Episode max turns: 10\n",
      "   Batch size: 1\n",
      "   SFT interval: 10\n",
      "\n",
      "   Estimated time: ~8.3 minutes\n",
      "   (assumes ~2sec per teacher API call)\n",
      "\n",
      "‚ö†Ô∏è  Run this cell, then RESTART the training loop cell!\n"
     ]
    }
   ],
   "source": [
    "# TEMPORARY: Reduce load for testing\n",
    "# Comment these out once you confirm training works\n",
    "\n",
    "NUM_TRAINING_STEPS = 5          # Was 100 - test with just 5 steps\n",
    "EPISODE_MAX_TURNS = 10          # Was 100 - shorter episodes\n",
    "BATCH_SIZE = 1                  # Was 4 - single episode per step\n",
    "SFT_INTERVAL = 10               # Was 25 - faster SFT testing\n",
    "\n",
    "print(\"‚ö° REDUCED CONFIGURATION FOR TESTING:\")\n",
    "print(f\"   Training steps: {NUM_TRAINING_STEPS}\")\n",
    "print(f\"   Episode max turns: {EPISODE_MAX_TURNS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   SFT interval: {SFT_INTERVAL}\")\n",
    "print(f\"\\n   Estimated time: ~{NUM_TRAINING_STEPS * EPISODE_MAX_TURNS * 5 * 2 / 60:.1f} minutes\")\n",
    "print(f\"   (assumes ~2sec per teacher API call)\")\n",
    "print(f\"\\n‚ö†Ô∏è  Run this cell, then RESTART the training loop cell!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee74b37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Game state visualization function loaded\n",
      "   Use: visualize_game_state(env, turn_num, sailor_actions, sailor_reasoning)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from config import MAX_ENERGY, MapLevel, ShipComponent, ResourceType\n",
    "\n",
    "def visualize_game_state(env, turn_num, sailor_actions=None, sailor_reasoning=None):\n",
    "    \"\"\"\n",
    "    Display comprehensive game state visualization with map, sailor status, and actions.\n",
    "    \n",
    "    Args:\n",
    "        env: MaroonedEnv instance\n",
    "        turn_num: Current turn number\n",
    "        sailor_actions: Dict of sailor_id -> action string\n",
    "        sailor_reasoning: Dict of sailor_id -> reasoning string\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    \n",
    "    # Header\n",
    "    output.append(\"=\"*100)\n",
    "    output.append(f\"üè¥‚Äç‚ò†Ô∏è  TURN {turn_num} | DAY {env.state.current_day} | PHASE: {env.state.current_phase.upper()}\")\n",
    "    output.append(\"=\"*100)\n",
    "    \n",
    "    # Sailor Status Table\n",
    "    output.append(\"\\nüìä SAILOR STATUS:\")\n",
    "    output.append(\"‚îÄ\"*100)\n",
    "    output.append(f\"{'Name':<8} | {'Role':<10} | {'HP':<10} | {'Energy':<12} | {'Position':<15} | {'Status':<15}\")\n",
    "    output.append(\"‚îÄ\"*100)\n",
    "    \n",
    "    for sailor_id in sorted(env.state.sailors.keys()):\n",
    "        sailor = env.state.sailors[sailor_id]\n",
    "        role = sailor.role.value\n",
    "        \n",
    "        # Health status\n",
    "        hp_icon = \"üíö\" if sailor.alive else \"üíÄ\"\n",
    "        hp_str = f\"{hp_icon} {'ALIVE' if sailor.alive else 'DEAD'}\"\n",
    "        \n",
    "        # Energy bar (visual representation)\n",
    "        if sailor.alive:\n",
    "            energy_pct = sailor.energy / MAX_ENERGY\n",
    "            energy_bars = int(energy_pct * 10)\n",
    "            energy_visual = \"‚ñà\" * energy_bars + \"‚ñë\" * (10 - energy_bars)\n",
    "            energy_str = f\"{energy_visual} {sailor.energy}/{MAX_ENERGY}\"\n",
    "        else:\n",
    "            energy_str = \"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0/100\"\n",
    "        \n",
    "        # Position\n",
    "        if sailor.position:\n",
    "            pos = sailor.position\n",
    "            pos_str = f\"({pos.x:2d},{pos.y:2d}) {pos.level.name}\"\n",
    "        else:\n",
    "            pos_str = \"Unknown\"\n",
    "        \n",
    "        # Status indicators\n",
    "        status_parts = []\n",
    "        if not sailor.alive:\n",
    "            if sailor.death_cause:\n",
    "                status_parts.append(f\"üíÄ {sailor.death_cause.value}\")\n",
    "            else:\n",
    "                status_parts.append(\"üíÄ DEAD\")\n",
    "        else:\n",
    "            if sailor_id == env.state.traitor_id:\n",
    "                status_parts.append(\"üî™TRAITOR\")\n",
    "            if sailor.is_poisoned():\n",
    "                poison_icon = \"‚ò†Ô∏è\" if sailor.poison_state.value == \"severe_symptoms\" else \"ü§¢\"\n",
    "                status_parts.append(f\"{poison_icon} POISON\")\n",
    "            if not status_parts:\n",
    "                status_parts.append(\"OK\")\n",
    "        status_str = \" \".join(status_parts)\n",
    "        \n",
    "        output.append(f\"{sailor_id:<8} | {role:<10} | {hp_str:<10} | {energy_str:<12} | {pos_str:<15} | {status_str:<15}\")\n",
    "    \n",
    "    output.append(\"‚îÄ\"*100)\n",
    "    \n",
    "    # Ship Progress\n",
    "    ship = env.state.ship_progress\n",
    "    ship_pct = ship.total_percentage\n",
    "    ship_bars = int(ship_pct / 10)\n",
    "    ship_visual = \"‚ñì\" * ship_bars + \"‚ñë\" * (10 - ship_bars)\n",
    "    output.append(f\"\\nüö¢ SHIP PROGRESS: {ship_visual} {ship_pct:.1f}%\")\n",
    "    \n",
    "    # Show component details\n",
    "    components_str = []\n",
    "    for comp in [ShipComponent.HULL, ShipComponent.MAST, ShipComponent.SAIL, ShipComponent.RUDDER, ShipComponent.SUPPLIES]:\n",
    "        if comp in ship.components:\n",
    "            comp_progress = ship.components[comp]\n",
    "            if comp_progress.completed:\n",
    "                status = \"‚úì\"\n",
    "            else:\n",
    "                status = f\"{comp_progress.progress_percentage}%\"\n",
    "            components_str.append(f\"{comp.value.title()}: {status}\")\n",
    "        else:\n",
    "            components_str.append(f\"{comp.value.title()}: 0%\")\n",
    "    output.append(f\"   {' | '.join(components_str)}\")\n",
    "    \n",
    "    # Common Inventory (Base Storage)\n",
    "    output.append(f\"\\nüì¶ COMMON INVENTORY (Base Camp):\")\n",
    "    inventory_items = []\n",
    "    \n",
    "    # Building materials\n",
    "    wood_count = env.state.get_common_inventory_count(ResourceType.WOOD)\n",
    "    metal_count = env.state.get_common_inventory_count(ResourceType.METAL)\n",
    "    plant_fiber_count = env.state.get_common_inventory_count(ResourceType.PLANT_FIBER)\n",
    "    \n",
    "    # Food (sum all food types)\n",
    "    apple_count = env.state.get_common_inventory_count(ResourceType.APPLE)\n",
    "    berry_count = env.state.get_common_inventory_count(ResourceType.BERRY)\n",
    "    mushroom_count = env.state.get_common_inventory_count(ResourceType.MUSHROOM)\n",
    "    total_food = apple_count + berry_count + mushroom_count\n",
    "    \n",
    "    # Special items\n",
    "    antidote_count = env.state.get_common_inventory_count(ResourceType.ANTIDOTE_HERB)\n",
    "    \n",
    "    inventory_items = [\n",
    "        f\"üå≤ Wood: {wood_count}\",\n",
    "        f\"‚öôÔ∏è Metal: {metal_count}\",\n",
    "        f\"üßµ Fiber: {plant_fiber_count}\",\n",
    "        f\"üçé Food: {total_food}\",\n",
    "        f\"üåø Antidote: {antidote_count}\",\n",
    "    ]\n",
    "    output.append(f\"   {' | '.join(inventory_items)}\")\n",
    "    \n",
    "    # Actions this turn (if provided)\n",
    "    if sailor_actions:\n",
    "        output.append(f\"\\n‚öîÔ∏è  ACTIONS THIS TURN:\")\n",
    "        output.append(\"‚îÄ\"*100)\n",
    "        for sailor_id in sorted(sailor_actions.keys()):\n",
    "            sailor = env.state.sailors[sailor_id]\n",
    "            if not sailor.alive:\n",
    "                continue\n",
    "            \n",
    "            action = sailor_actions[sailor_id]\n",
    "            reasoning = sailor_reasoning.get(sailor_id, \"N/A\") if sailor_reasoning else \"N/A\"\n",
    "            \n",
    "            # Truncate long reasoning\n",
    "            reasoning_short = (reasoning[:65] + \"...\") if len(reasoning) > 65 else reasoning\n",
    "            \n",
    "            output.append(f\"  [{sailor_id:<7}] {action}\")\n",
    "            output.append(f\"            üí≠ {reasoning_short}\")\n",
    "        output.append(\"‚îÄ\"*100)\n",
    "    \n",
    "    # Map visualization (all 3 levels)\n",
    "    output.append(f\"\\nüó∫Ô∏è  ISLAND MAP (Day {env.state.current_day}, Turn {turn_num}):\")\n",
    "    output.append(\"\")\n",
    "    \n",
    "    # Render all three levels\n",
    "    for level in [MapLevel.GROUND, MapLevel.MOUNTAIN, MapLevel.CAVE]:\n",
    "        map_str = env.render_map(level, use_emoji=True)\n",
    "        output.append(map_str)\n",
    "    \n",
    "    # Game Status Footer\n",
    "    output.append(\"\\n\" + \"=\"*100)\n",
    "    if env.state.game_over:\n",
    "        winner_str = \"üèÜ \" + (env.state.winner.upper() if env.state.winner else \"UNKNOWN\")\n",
    "        output.append(f\"GAME OVER! Winner: {winner_str}\")\n",
    "        output.append(\"=\"*100)\n",
    "    \n",
    "    # Print everything\n",
    "    print(\"\\n\".join(output))\n",
    "\n",
    "\n",
    "print(\"‚úÖ Game state visualization function loaded\")\n",
    "print(\"   Use: visualize_game_state(env, turn_num, sailor_actions, sailor_reasoning)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fecdf",
   "metadata": {},
   "source": [
    "## üéÆ Test Game Visualization (Optional)\n",
    "\n",
    "Before training, you can test the visualization with a quick demo episode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dd2c7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üè¥‚Äç‚ò†Ô∏è  TURN 4 | DAY 1 | PHASE: MORNING\n",
      "====================================================================================================\n",
      "\n",
      "üìä SAILOR STATUS:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Name     | Role       | HP         | Energy       | Position        | Status         \n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Alice    | traitor    | üíö ALIVE    | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100 | (15,15) GROUND  | üî™TRAITOR       \n",
      "Bob      | honest     | üíö ALIVE    | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100 | (15,15) GROUND  | OK             \n",
      "Charlie  | honest     | üíö ALIVE    | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100 | (15,15) GROUND  | OK             \n",
      "Diana    | honest     | üíö ALIVE    | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100 | (15,15) GROUND  | OK             \n",
      "Eve      | honest     | üíö ALIVE    | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100 | (15,15) GROUND  | OK             \n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üö¢ SHIP PROGRESS: ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.0%\n",
      "   Hull: 0% | Mast: 0% | Sail: 0% | Rudder: 0% | Supplies: 0%\n",
      "\n",
      "üì¶ COMMON INVENTORY (Base Camp):\n",
      "   üå≤ Wood: 0 | ‚öôÔ∏è Metal: 0 | üßµ Fiber: 0 | üçé Food: 0 | üåø Antidote: 0\n",
      "\n",
      "‚öîÔ∏è  ACTIONS THIS TURN:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  [Alice  ] wait (demo)\n",
      "            üí≠ This is a demo - just waiting\n",
      "  [Bob    ] wait (demo)\n",
      "            üí≠ This is a demo - just waiting\n",
      "  [Charlie] wait (demo)\n",
      "            üí≠ This is a demo - just waiting\n",
      "  [Diana  ] wait (demo)\n",
      "            üí≠ This is a demo - just waiting\n",
      "  [Eve    ] wait (demo)\n",
      "            üí≠ This is a demo - just waiting\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üó∫Ô∏è  ISLAND MAP (Day 1, Turn 4):\n",
      "\n",
      "\n",
      "   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 \n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ üèùÔ∏è  GROUND LEVEL (Z=0)                                       ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Legend: üü´ land | üå≤ wood | ‚öôÔ∏è metal | üçé food | üåø antidote | ‚ò†Ô∏è poison\n",
      "‚îÇ         ‚¨ÜÔ∏è stairs up | ‚¨áÔ∏è stairs down | üè† base | A/B/C/D/E sailors\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      " 0 üü´üü´üü´üü´üçéüü´üü´üü´üå≤üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üçéüü´üü´\n",
      " 1 üçéüü´üü´üü´‚öôÔ∏èüü´üü´üü´üçéüü´üü´üü´üü´üü´‚ò†Ô∏èüü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´üü´\n",
      " 2 üü´üü´üü´üü´üå≤üü´üçéüü´üü´üü´üü´üå≤üü´üü´üü´üü´‚ò†Ô∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´\n",
      " 3 üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´‚öôÔ∏èüü´‚öôÔ∏èüü´‚öôÔ∏èüçéüü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´\n",
      " 4 üü´üü´üå≤üü´üçéüü´üå≤üçéüü´üü´üü´üü´üü´üü´üü´üü´‚¨áÔ∏èüü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´\n",
      " 5 üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüå≤üü´üü´üü´\n",
      " 6 üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üçéüü´üü´üü´üü´üü´üçéüçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´\n",
      " 7 üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üå≤üçéüü´üü´üü´üü´\n",
      " 8 ‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üçéüü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üå≤\n",
      " 9 üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üå≤üü´üü´üå≤‚ò†Ô∏èüü´üå≤üå≤\n",
      "10 üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüçéüü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´\n",
      "11 üü´‚ò†Ô∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üçéüçéüü´üü´üü´üå≤üü´üü´üå≤üü´\n",
      "12 üü´üçéüü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üå≤üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´\n",
      "13 üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´\n",
      "14 üü´üü´üü´üå≤üü´üü´üü´üü´üü´‚ò†Ô∏èüü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤üçéüü´üü´üü´\n",
      "15 üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´5üë•üü´üü´üü´‚¨ÜÔ∏èüü´üü´üü´üå≤üü´üü´üå≤üü´üü´üü´\n",
      "16 üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üçéüçéüü´üå≤üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´\n",
      "17 üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üå≤üü´üü´‚öôÔ∏èüü´\n",
      "18 üü´üå≤üü´üü´üü´üü´üü´üü´‚ò†Ô∏èüü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´\n",
      "19 üü´üü´üü´üü´üü´üü´üå≤üçéüü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏è\n",
      "20 üü´üü´‚öôÔ∏èüü´üå≤üü´üçé‚öôÔ∏èüü´‚öôÔ∏èüü´üü´üü´üçéüçéüü´üü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´\n",
      "21 üü´üü´üçéüçéüü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤üå≤üü´üü´üçéüü´üü´\n",
      "22 üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏è\n",
      "23 üü´üçéüü´üçéüçéüü´üü´üü´üü´üü´üå≤üå≤üü´üü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üçéüå≤üü´üü´üü´üü´üü´\n",
      "24 üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üü´üçéüü´üü´üü´\n",
      "25 üü´üü´üü´üü´üü´üü´üü´üü´üü´‚ò†Ô∏èüå≤üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´\n",
      "26 üå≤üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´üü´üü´üü´\n",
      "27 üü´üü´üü´üçéüü´üü´üü´üçéüçéüü´üü´üü´üå≤üü´üü´üçéüü´üü´üå≤üü´üü´üü´üü´üå≤üü´üü´üçéüü´üü´üü´\n",
      "28 üü´üü´üü´üå≤üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´‚öôÔ∏èüü´üü´üü´üü´üü´üçéüå≤üü´üü´üü´\n",
      "29 üü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´\n",
      "\n",
      "üë• Sailors on GROUND: Alice, Bob, Charlie, Diana, Eve\n",
      "\n",
      "\n",
      "   0 1 2 3 4 5 6 7 8 9 \n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ ‚õ∞Ô∏è  MOUNTAIN LEVEL (Z=2) ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Legend: ‚õ∞Ô∏è mountain | üå≤ wood | ‚öôÔ∏è metal | üçé food | üåø antidote | ‚ò†Ô∏è poison\n",
      "‚îÇ         ‚¨ÜÔ∏è stairs up | ‚¨áÔ∏è stairs down | üè† base | A/B/C/D/E sailors\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      " 0 ‚¨áÔ∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüåø‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è\n",
      " 1 üçé‚ò†Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüåø‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è\n",
      " 2 ‚õ∞Ô∏èüçéüçé‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è\n",
      " 3 ‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüçé‚õ∞Ô∏è\n",
      " 4 ‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è\n",
      " 5 ‚õ∞Ô∏è‚õ∞Ô∏èüçé‚õ∞Ô∏èüçé‚õ∞Ô∏èüåøüçé‚õ∞Ô∏è‚õ∞Ô∏è\n",
      " 6 ‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüçé‚õ∞Ô∏è‚ò†Ô∏èüçé\n",
      " 7 ‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è\n",
      " 8 ‚õ∞Ô∏è‚õ∞Ô∏èüåø‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüåø‚õ∞Ô∏è\n",
      " 9 üåø‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüåø‚õ∞Ô∏è‚õ∞Ô∏è‚ò†Ô∏è‚õ∞Ô∏è‚ò†Ô∏è\n",
      "\n",
      "\n",
      "   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 \n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ üï≥Ô∏è  CAVE LEVEL (Z=-1)          ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Legend: ü™® cave | üå≤ wood | ‚öôÔ∏è metal | üçé food | üåø antidote | ‚ò†Ô∏è poison\n",
      "‚îÇ         ‚¨ÜÔ∏è stairs up | ‚¨áÔ∏è stairs down | üè† base | A/B/C/D/E sailors\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      " 0 ‚¨ÜÔ∏èü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®\n",
      " 1 ü™®ü™®üå≤ü™®ü™®ü™®ü™®ü™®üå≤ü™®ü™®ü™®ü™®ü™®ü™®\n",
      " 2 ü™®‚öôÔ∏èü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®\n",
      " 3 ü™®ü™®‚öôÔ∏èü™®‚öôÔ∏èüå≤ü™®ü™®üå≤ü™®ü™®ü™®ü™®ü™®ü™®\n",
      " 4 ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®\n",
      " 5 ü™®ü™®ü™®‚ò†Ô∏èü™®üå≤ü™®ü™®ü™®ü™®‚öôÔ∏èü™®ü™®ü™®ü™®\n",
      " 6 ü™®ü™®ü™®üå≤ü™®ü™®ü™®ü™®ü™®üå≤ü™®ü™®ü™®ü™®ü™®\n",
      " 7 ‚ò†Ô∏è‚öôÔ∏è‚öôÔ∏èü™®ü™®ü™®ü™®‚öôÔ∏èü™®ü™®ü™®ü™®ü™®ü™®ü™®\n",
      " 8 ü™®üå≤ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®\n",
      " 9 ü™®ü™®‚öôÔ∏èü™®ü™®ü™®ü™®ü™®ü™®ü™®‚öôÔ∏èü™®‚öôÔ∏èü™®ü™®\n",
      "10 ü™®ü™®ü™®ü™®ü™®ü™®ü™®‚öôÔ∏èüå≤‚ò†Ô∏èü™®ü™®‚öôÔ∏èü™®ü™®\n",
      "11 ü™®ü™®ü™®ü™®üå≤ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®\n",
      "12 ü™®ü™®‚öôÔ∏èü™®ü™®üå≤ü™®ü™®‚ò†Ô∏èü™®ü™®ü™®ü™®ü™®‚ò†Ô∏è\n",
      "13 ü™®ü™®ü™®ü™®ü™®‚öôÔ∏èüå≤ü™®ü™®ü™®üå≤üå≤ü™®ü™®ü™®\n",
      "14 ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®‚ò†Ô∏èü™®ü™®‚öôÔ∏è\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "‚úÖ Demo complete! You can now run the training loop.\n",
      "   The first episode will show this same visualization.\n",
      "\n",
      "‚úÖ Demo complete! You can now run the training loop.\n",
      "   The first episode will show this same visualization.\n"
     ]
    }
   ],
   "source": [
    "# TEST VISUALIZATION - Run a quick 5-turn demo episode with visualization\n",
    "# This will show you what the training visualization looks like\n",
    "\n",
    "print(\"üé¨ Running demo episode with visualization...\")\n",
    "print(\"   This will show the full game state for 5 turns\\n\")\n",
    "\n",
    "demo_env = MaroonedEnv(seed=42, render_mode=\"ansi\")\n",
    "demo_obs = demo_env.reset(seed=42)\n",
    "\n",
    "for demo_turn in range(5):\n",
    "    # Collect actions for all sailors\n",
    "    demo_actions = {}\n",
    "    demo_reasoning = {}\n",
    "    \n",
    "    for sailor_id in demo_env.agents:\n",
    "        sailor = demo_env.state.sailors[sailor_id]\n",
    "        if not sailor.alive:\n",
    "            continue\n",
    "        \n",
    "        # Random action for demo\n",
    "        action = Action(sailor_id=sailor_id, action_type=ActionType.WAIT)\n",
    "        demo_actions[sailor_id] = f\"{action.action_type.value} (demo)\"\n",
    "        demo_reasoning[sailor_id] = \"This is a demo - just waiting\"\n",
    "    \n",
    "    # Show visualization\n",
    "    clear_output(wait=True)\n",
    "    visualize_game_state(demo_env, demo_turn, demo_actions, demo_reasoning)\n",
    "    \n",
    "    # Execute actions\n",
    "    actions_dict = {sid: Action(sailor_id=sid, action_type=ActionType.WAIT) for sid in demo_env.agents}\n",
    "    demo_obs, _, dones, _, _ = demo_env.step(actions_dict)\n",
    "    \n",
    "    time.sleep(1.5)  # Pause to see each turn\n",
    "\n",
    "print(\"\\n‚úÖ Demo complete! You can now run the training loop.\")\n",
    "print(\"   The first episode will show this same visualization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b74b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üè¥‚Äç‚ò†Ô∏è  TURN 5 | DAY 1 | PHASE: EXPLORATION\n",
      "====================================================================================================\n",
      "\n",
      "üìä SAILOR STATUS:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Name     | Role       | HP         | Energy       | Position        | Status         \n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Alice    | honest     | üíö ALIVE    | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 98/100 | (17,15) GROUND  | OK             \n",
      "Bob      | traitor    | üíö ALIVE    | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100 | (15,15) GROUND  | üî™TRAITOR       \n",
      "Charlie  | honest     | üíö ALIVE    | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 96/100 | (19,15) GROUND  | OK             \n",
      "Diana    | honest     | üíö ALIVE    | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 96/100 | (19,15) GROUND  | OK             \n",
      "Eve      | honest     | üíö ALIVE    | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 96/100 | (19,15) GROUND  | OK             \n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üö¢ SHIP PROGRESS: ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.0%\n",
      "   Hull: 0% | Mast: 0% | Sail: 0% | Rudder: 0% | Supplies: 0%\n",
      "\n",
      "üì¶ COMMON INVENTORY (Base Camp):\n",
      "   üå≤ Wood: 0 | ‚öôÔ∏è Metal: 0 | üßµ Fiber: 0 | üçé Food: 0 | üåø Antidote: 0\n",
      "\n",
      "‚öîÔ∏è  ACTIONS THIS TURN:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  [Alice  ] gather_resource (resource WOOD_35) | Reward: +0.0\n",
      "            üí≠ <your reasoning>\n",
      "  [Bob    ] sabotage_ship | Reward: -3.0\n",
      "            üí≠ Alice is weak and asking for help. I will give her poison disguis...\n",
      "  [Charlie] gather_resource (resource WOOD_47) | Reward: -0.1\n",
      "            üí≠ <your reasoning>\n",
      "  [Diana  ] gather_resource (resource WOOD_47) | Reward: -0.1\n",
      "            üí≠ <your reasoning>\n",
      "  [Eve    ] gather_resource (resource WOOD_47) | Reward: -0.1\n",
      "            üí≠ <your reasoning>\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üó∫Ô∏è  ISLAND MAP (Day 1, Turn 5):\n",
      "\n",
      "\n",
      "   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 \n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ üèùÔ∏è  GROUND LEVEL (Z=0)                                       ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Legend: üü´ land | üå≤ wood | ‚öôÔ∏è metal | üçé food | üåø antidote | ‚ò†Ô∏è poison\n",
      "‚îÇ         ‚¨ÜÔ∏è stairs up | ‚¨áÔ∏è stairs down | üè† base | A/B/C/D/E sailors\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      " 0 üü´üü´üü´üü´üü´üü´üü´üçéüü´‚öôÔ∏èüü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üå≤üçé\n",
      " 1 üü´üü´üü´üü´üçéüü´‚öôÔ∏èüü´üü´üü´üü´üü´‚öôÔ∏èüü´üçéüçéüü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´\n",
      " 2 üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üçéüü´üü´üü´üü´\n",
      " 3 üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤\n",
      " 4 üü´üü´üå≤üü´üü´üü´üü´‚öôÔ∏èüçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´‚öôÔ∏è\n",
      " 5 üçéüü´üü´üü´üü´üü´üçéüå≤üü´üü´üü´üü´üå≤‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´\n",
      " 6 üå≤üçéüü´üü´üü´üü´üü´üçéüçéüü´üü´üå≤üçéüü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´\n",
      " 7 üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´üçéüü´üü´‚öôÔ∏èüçéüü´üü´\n",
      " 8 üå≤üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´\n",
      " 9 üçéüü´üü´üå≤üü´üü´üå≤üü´üü´üü´üü´üü´üå≤üü´‚ò†Ô∏èüü´üü´üå≤üü´üü´üü´üü´üü´üü´üü´üçé‚ò†Ô∏èüü´üü´üçé\n",
      "10 üü´üü´üü´‚¨ÜÔ∏èüü´üçéüü´‚öôÔ∏èüü´üü´üü´üçé‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üå≤üü´üü´üçéüü´üü´\n",
      "11 üü´üü´üü´üü´üü´üü´üçéüü´üçéüü´üçéüü´üçéüçéüü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´\n",
      "12 ‚ò†Ô∏èüü´üü´üü´üçéüü´üå≤üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üçéüü´üü´üü´\n",
      "13 üü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´\n",
      "14 üü´üü´üü´üü´üü´üü´üü´üçéüü´üå≤üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´\n",
      "15 üü´üü´üü´üü´üü´üü´üü´üü´üü´‚ò†Ô∏èüü´üü´üü´‚öôÔ∏èüå≤Büü´Aüü´3üë•üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´\n",
      "16 üü´üü´üü´üå≤üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üå≤üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´\n",
      "17 üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üå≤üü´üü´üü´üçéüü´üü´\n",
      "18 üü´üü´üü´üü´üçéüü´‚ò†Ô∏èüü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üçéüü´üü´üü´üå≤üü´\n",
      "19 üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´‚ò†Ô∏èüü´üü´üü´üü´üü´üü´üü´üçéüü´üü´\n",
      "20 üü´üü´üü´üü´üü´üü´üü´üü´üü´üçé‚öôÔ∏èüü´üü´‚öôÔ∏èüü´üü´üü´üü´üçé‚öôÔ∏èüü´üçéüü´üü´üü´üü´üü´üü´üü´üü´\n",
      "21 üü´üü´üå≤üçéüü´üü´üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüçéüü´üü´üü´üü´üü´üçéüü´üü´\n",
      "22 üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üå≤üü´üü´üå≤üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´\n",
      "23 üü´üü´üü´‚ò†Ô∏è‚öôÔ∏èüå≤üü´üü´üü´üü´‚ò†Ô∏è‚öôÔ∏èüü´üü´üçéüü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´\n",
      "24 üçéüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´\n",
      "25 üü´üü´üü´üü´üü´üü´üçéüü´üü´üå≤üü´üü´‚öôÔ∏èüü´üü´üü´üü´üå≤üü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´üü´üü´\n",
      "26 üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´üü´üçéüü´\n",
      "27 üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´\n",
      "28 üå≤üçéüü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üü´üü´üü´üü´üü´üü´üü´üü´üå≤üü´üçé‚¨áÔ∏èüü´üå≤üü´üü´üü´üü´\n",
      "29 üü´üü´üå≤üü´üü´üå≤üü´üü´üü´üü´üü´‚öôÔ∏èüü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üü´üçéüü´üü´üü´üü´üü´\n",
      "\n",
      "üë• Sailors on GROUND: Alice, Bob, Charlie, Diana, Eve\n",
      "\n",
      "\n",
      "   0 1 2 3 4 5 6 7 8 9 \n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ ‚õ∞Ô∏è  MOUNTAIN LEVEL (Z=2) ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Legend: ‚õ∞Ô∏è mountain | üå≤ wood | ‚öôÔ∏è metal | üçé food | üåø antidote | ‚ò†Ô∏è poison\n",
      "‚îÇ         ‚¨ÜÔ∏è stairs up | ‚¨áÔ∏è stairs down | üè† base | A/B/C/D/E sailors\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      " 0 ‚¨áÔ∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüåø‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è\n",
      " 1 ‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚ò†Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è\n",
      " 2 üåø‚õ∞Ô∏è‚õ∞Ô∏èüåø‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüåøüçé\n",
      " 3 ‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è\n",
      " 4 ‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüçé‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è\n",
      " 5 ‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüåø‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüçé‚õ∞Ô∏è\n",
      " 6 üçé‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è\n",
      " 7 ‚õ∞Ô∏è‚õ∞Ô∏èüçéüçé‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚ò†Ô∏èüçé‚õ∞Ô∏è\n",
      " 8 ‚õ∞Ô∏è‚õ∞Ô∏èüçé‚õ∞Ô∏è‚õ∞Ô∏èüçé‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏èüåø\n",
      " 9 ‚õ∞Ô∏è‚õ∞Ô∏è‚ò†Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è‚õ∞Ô∏è\n",
      "\n",
      "\n",
      "   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 \n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ üï≥Ô∏è  CAVE LEVEL (Z=-1)          ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Legend: ü™® cave | üå≤ wood | ‚öôÔ∏è metal | üçé food | üåø antidote | ‚ò†Ô∏è poison\n",
      "‚îÇ         ‚¨ÜÔ∏è stairs up | ‚¨áÔ∏è stairs down | üè† base | A/B/C/D/E sailors\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      " 0 ‚¨ÜÔ∏èü™®‚öôÔ∏èü™®ü™®ü™®ü™®üå≤ü™®ü™®ü™®ü™®ü™®üå≤ü™®\n",
      " 1 ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®‚öôÔ∏èü™®\n",
      " 2 ü™®ü™®ü™®ü™®ü™®ü™®ü™®‚öôÔ∏èü™®ü™®ü™®ü™®ü™®ü™®ü™®\n",
      " 3 ü™®ü™®ü™®‚öôÔ∏èüå≤ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®\n",
      " 4 ü™®ü™®ü™®ü™®‚ò†Ô∏èü™®üå≤ü™®ü™®üå≤ü™®ü™®ü™®ü™®ü™®\n",
      " 5 ü™®‚ò†Ô∏èü™®ü™®ü™®ü™®‚öôÔ∏èü™®‚öôÔ∏è‚öôÔ∏èü™®üå≤ü™®ü™®ü™®\n",
      " 6 ‚öôÔ∏èüå≤ü™®ü™®ü™®‚öôÔ∏èü™®ü™®ü™®ü™®ü™®‚öôÔ∏è‚öôÔ∏èü™®ü™®\n",
      " 7 ü™®ü™®ü™®ü™®ü™®üå≤ü™®ü™®ü™®ü™®ü™®‚öôÔ∏èü™®ü™®ü™®\n",
      " 8 ü™®ü™®ü™®‚öôÔ∏èü™®ü™®ü™®‚ò†Ô∏èü™®ü™®ü™®ü™®ü™®ü™®ü™®\n",
      " 9 üå≤ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®‚öôÔ∏èü™®ü™®ü™®ü™®ü™®\n",
      "10 ü™®ü™®ü™®ü™®‚öôÔ∏èü™®ü™®ü™®ü™®‚öôÔ∏èü™®ü™®ü™®‚öôÔ∏èü™®\n",
      "11 ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®üå≤ü™®ü™®\n",
      "12 ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®‚ò†Ô∏è‚ò†Ô∏èüå≤ü™®ü™®ü™®ü™®\n",
      "13 ü™®ü™®ü™®ü™®ü™®‚öôÔ∏èü™®üå≤ü™®ü™®ü™®ü™®‚ò†Ô∏èü™®ü™®\n",
      "14 ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®ü™®\n",
      "\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Set memory optimization for AMD GPU\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Use variables from config cell above if defined, otherwise defaults\n",
    "if 'NUM_TRAINING_STEPS' not in dir():\n",
    "    NUM_TRAINING_STEPS = 100\n",
    "    EPISODE_MAX_TURNS = 100\n",
    "    BATCH_SIZE = 4\n",
    "    SFT_INTERVAL = 25\n",
    "    print(\"‚ö†Ô∏è  Using default configuration - run config cell above to reduce load!\")\n",
    "\n",
    "# CRITICAL: Ultra-reduced sequence length for stability (prevents GPU crashes)\n",
    "# The issue: Memory access faults on MI300X with longer sequences\n",
    "EPISODE_MAX_SEQ_LENGTH = 2048  # Reduced from 4096 - SAFE MODE\n",
    "\n",
    "# Aggressive GPU memory cleanup\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "print(\"üßπ GPU memory aggressively cleared\")\n",
    "print(f\"üìè Max sequence length: {EPISODE_MAX_SEQ_LENGTH} tokens (reduced for stability)\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD SAVED MODEL IF AVAILABLE (Resume Training)\n",
    "# ============================================================================\n",
    "saved_model_path = \"outputs_marooned_rl/final_model\"\n",
    "\n",
    "if os.path.exists(saved_model_path) and os.path.exists(os.path.join(saved_model_path, \"adapter_config.json\")):\n",
    "    print(f\"üîÑ Saved checkpoint found at {saved_model_path}\")\n",
    "    print(f\"‚ö†Ô∏è  NOTE: Model already loaded from earlier cells\")\n",
    "    print(f\"   To resume from checkpoint, reload the student model cell first\")\n",
    "    print(f\"   For now, continuing with current model weights\\n\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è  No saved checkpoint found\")\n",
    "    print(f\"   Training from current model state\\n\")\n",
    "\n",
    "def generate_episode_with_teacher(max_turns=None, verbose=False, visualize=False):\n",
    "    \"\"\"\n",
    "    Play one episode with teacher validation.\n",
    "    Returns training data (prompts, responses) and rewards.\n",
    "    \n",
    "    Args:\n",
    "        max_turns: Maximum turns per episode\n",
    "        verbose: Print detailed action logs\n",
    "        visualize: Show full game state visualization every turn\n",
    "    \"\"\"\n",
    "    if max_turns is None:\n",
    "        max_turns = EPISODE_MAX_TURNS\n",
    "        \n",
    "    env = MaroonedEnv(render_mode=\"ansi\")\n",
    "    observations = env.reset()\n",
    "    sailor_ids = list(env.agents)\n",
    "    \n",
    "    # Collect episode data\n",
    "    episode_data = []\n",
    "    total_reward = 0.0\n",
    "    \n",
    "    FastLanguageModel.for_inference(student_model)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nüéÆ Starting episode (max {max_turns} turns)...\")\n",
    "    \n",
    "    for turn in range(max_turns):\n",
    "        # Collect turn data for visualization\n",
    "        turn_actions = {}\n",
    "        turn_reasoning = {}\n",
    "        turn_actions_count = 0\n",
    "        \n",
    "        for sailor_id in sailor_ids:\n",
    "            sailor = env.state.sailors[sailor_id]\n",
    "            \n",
    "            # Skip dead sailors\n",
    "            if not sailor.alive:\n",
    "                continue\n",
    "            \n",
    "            obs = observations[sailor_id]\n",
    "            role = sailor.role.value\n",
    "            \n",
    "            # Student generates action\n",
    "            system_prompt = get_system_prompt(role)\n",
    "            user_prompt = observation_to_prompt(obs)\n",
    "            \n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            \n",
    "            full_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "            inputs = tokenizer(full_prompt, return_tensors=\"pt\", truncation=True, max_length=EPISODE_MAX_SEQ_LENGTH).to(\"cuda\")\n",
    "            \n",
    "            # Timeout mechanism: if generation takes > 60 seconds, fall back to WAIT\n",
    "            student_response = \"\"\n",
    "            generation_start = time.time()\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    # SAFE MODE: Minimal generation parameters to prevent crashes\n",
    "                    outputs = student_model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=128,  # Increased to allow REASONING + ACTION format\n",
    "                        temperature=0.7,    # Higher temp = less computation\n",
    "                        do_sample=False,    # Greedy = faster and safer\n",
    "                        pad_token_id=tokenizer.eos_token_id,\n",
    "                        use_cache=False,    # CRITICAL: Disabled to prevent memory corruption\n",
    "                    )\n",
    "                \n",
    "                generation_time = time.time() - generation_start\n",
    "                \n",
    "                # Check if generation took too long (> 120 seconds in safe mode)\n",
    "                if generation_time > 120:\n",
    "                    print(f\"   ‚ö†Ô∏è  {sailor_id} generation timeout ({generation_time:.1f}s) - using WAIT\")\n",
    "                    student_response = \"REASONING: Generation timeout\\nACTION: WAIT\"\n",
    "                else:\n",
    "                    student_response = tokenizer.decode(outputs[0][len(inputs[\"input_ids\"][0]):], skip_special_tokens=True).strip()\n",
    "                    \n",
    "                    # DEBUG: Print first student response to verify generation\n",
    "                    if turn == 0 and verbose:\n",
    "                        print(f\"\\nüîç DEBUG - {sailor_id} raw response:\")\n",
    "                        print(f\"   {student_response[:200]}\")\n",
    "                        print()\n",
    "                \n",
    "                # Explicitly delete tensors BEFORE cache clear\n",
    "                del outputs\n",
    "                del inputs\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå {sailor_id} generation error: {e} - using WAIT\")\n",
    "                student_response = \"REASONING: Generation error\\nACTION: WAIT\"\n",
    "                # Clean up on error\n",
    "                try:\n",
    "                    if 'inputs' in locals():\n",
    "                        del inputs\n",
    "                    if 'outputs' in locals():\n",
    "                        del outputs\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # CRITICAL: Wait before cleanup to let GPU finish\n",
    "            torch.cuda.synchronize()\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "            # Parse reasoning from student response\n",
    "            reasoning = \"N/A\"\n",
    "            if \"REASONING:\" in student_response:\n",
    "                try:\n",
    "                    reasoning = student_response.split(\"REASONING:\")[1].split(\"ACTION:\")[0].strip()\n",
    "                except:\n",
    "                    reasoning = student_response[:100]\n",
    "            \n",
    "            # DEBUG: Print full student response for first turn to diagnose issues\n",
    "            if turn == 0 and sailor_id == \"Alice\":\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"üîç DEBUG - Student Model Raw Output (Alice, Turn 0):\")\n",
    "                print(f\"{'='*80}\")\n",
    "                print(student_response)\n",
    "                print(f\"{'='*80}\")\n",
    "                print(f\"Extracted reasoning: {reasoning}\")\n",
    "                print(f\"{'='*80}\\n\")\n",
    "            \n",
    "            # Teacher validates and potentially corrects\n",
    "            teacher_result = teacher_validate_student_output(student_response, obs, sailor_id)\n",
    "            action = teacher_result[\"action\"]\n",
    "            process_penalty = teacher_result[\"penalty\"]\n",
    "            \n",
    "            # Collect correction if needed\n",
    "            add_correction_example(student_response, teacher_result, obs)\n",
    "            \n",
    "            # Execute action in environment (only this sailor acts, others WAIT)\n",
    "            actions_dict = {sid: Action(sailor_id=sid, action_type=ActionType.WAIT) for sid in env.agents}\n",
    "            actions_dict[sailor_id] = action\n",
    "            \n",
    "            observations, rewards_dict, dones, truncated, info = env.step(actions_dict)\n",
    "            env_reward = rewards_dict[sailor_id]\n",
    "            \n",
    "            # Combined reward (environment + process penalty)\n",
    "            step_reward = env_reward + process_penalty\n",
    "            total_reward += step_reward\n",
    "            \n",
    "            # Store for visualization\n",
    "            action_str = action.action_type.value\n",
    "            if action.target_position:\n",
    "                action_str = f\"{action.action_type.value}\"\n",
    "            elif action.target_resource_id:\n",
    "                action_str = f\"{action.action_type.value} (resource {action.target_resource_id})\"\n",
    "            elif action.target_sailor:\n",
    "                action_str = f\"{action.action_type.value} {action.target_sailor}\"\n",
    "            \n",
    "            turn_actions[sailor_id] = f\"{action_str} | Reward: {step_reward:+.1f}\"\n",
    "            turn_reasoning[sailor_id] = reasoning\n",
    "            \n",
    "            # Store training example\n",
    "            episode_data.append({\n",
    "                \"prompt\": full_prompt,\n",
    "                \"response\": student_response,\n",
    "                \"reward\": step_reward,\n",
    "                \"sailor_id\": sailor_id,\n",
    "                \"action\": action.action_type.value,\n",
    "            })\n",
    "            \n",
    "            turn_actions_count += 1\n",
    "        \n",
    "        # Visualize game state after all sailors acted this turn\n",
    "        if visualize and turn_actions_count > 0:\n",
    "            clear_output(wait=True)\n",
    "            visualize_game_state(env, turn, turn_actions, turn_reasoning)\n",
    "            time.sleep(0.5)  # Brief pause to see the state\n",
    "        \n",
    "        if verbose and not visualize:\n",
    "            print(f\"--- Turn {turn}: {turn_actions_count} sailors acted ---\")\n",
    "        \n",
    "        # Check if episode is over\n",
    "        if env.state.game_over or all(dones.values()):\n",
    "            if verbose or visualize:\n",
    "                print(f\"\\n‚úÖ Episode ended at turn {turn}: game_over={env.state.game_over}\")\n",
    "            break\n",
    "        \n",
    "        # Early exit if no one acted (all dead)\n",
    "        if turn_actions_count == 0:\n",
    "            if verbose or visualize:\n",
    "                print(f\"\\n‚ö†Ô∏è  No sailors acted at turn {turn} (all dead)\")\n",
    "            break\n",
    "    \n",
    "    if verbose or visualize:\n",
    "        print(f\"\\nüìä Episode complete: {len(episode_data)} actions, total reward: {total_reward:.1f}\")\n",
    "    \n",
    "    return episode_data, total_reward\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SIMPLIFIED TRAINING LOOP (Without PPO.step)\n",
    "# ============================================================================\n",
    "print(\"üöÄ Starting Hybrid RL + SFT Training (SIMPLIFIED)\")\n",
    "print(f\"   Steps: {NUM_TRAINING_STEPS}\")\n",
    "print(f\"   Episode max turns: {EPISODE_MAX_TURNS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   SFT interval: Every {SFT_INTERVAL} steps\\n\")\n",
    "print(\"‚ö†Ô∏è  NOTE: This is a simplified training loop focused on SFT corrections\")\n",
    "print(\"   PPO updates are disabled due to UnslothPPOTrainer API limitations\")\n",
    "print(\"   The student learns primarily through teacher corrections\\n\")\n",
    "\n",
    "stats_rewards = []\n",
    "stats_sft_runs = 0\n",
    "stats_corrections = []\n",
    "\n",
    "for step in range(NUM_TRAINING_STEPS):\n",
    "    start_time = time.time()\n",
    "    batch_data = []\n",
    "    batch_reward = 0.0\n",
    "    \n",
    "    # RL Phase: Collect episodes\n",
    "    for episode_num in range(BATCH_SIZE):\n",
    "        print(f\"\\nüìç Step {step+1}/{NUM_TRAINING_STEPS} - Episode {episode_num+1}/{BATCH_SIZE}\")\n",
    "        \n",
    "        # Only visualize the first episode of the first step\n",
    "        should_visualize = (step == 0 and episode_num == 0)\n",
    "        \n",
    "        episode_data, episode_reward = generate_episode_with_teacher(\n",
    "            max_turns=EPISODE_MAX_TURNS,\n",
    "            verbose=False,  # Disable verbose when visualizing\n",
    "            visualize=should_visualize\n",
    "        )\n",
    "        \n",
    "        batch_data.extend(episode_data)\n",
    "        batch_reward += episode_reward\n",
    "        \n",
    "        print(f\"   ‚úì Episode complete: {len(episode_data)} actions, reward: {episode_reward:.1f}\")\n",
    "    \n",
    "    stats_rewards.append(batch_reward)\n",
    "    stats_corrections.append(len(correction_dataset))\n",
    "    \n",
    "    # Clear GPU cache after each step to prevent memory buildup\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    avg_reward = np.mean(stats_rewards[-10:]) if len(stats_rewards) >= 10 else np.mean(stats_rewards)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Step {step+1:03d}/{NUM_TRAINING_STEPS} | \"\n",
    "          f\"Reward: {batch_reward:+6.1f} | \"\n",
    "          f\"Avg(10): {avg_reward:+6.1f} | \"\n",
    "          f\"Corrections: {len(correction_dataset):4d} | \"\n",
    "          f\"Time: {elapsed:4.1f}s\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # SFT Phase: Train on corrections\n",
    "    if (step + 1) % SFT_INTERVAL == 0 and len(correction_dataset) >= 10:\n",
    "        print(f\"\\n{'‚îÄ'*80}\")\n",
    "        print(f\"üéì SFT PASS #{stats_sft_runs + 1}\")\n",
    "        print(f\"{'‚îÄ'*80}\")\n",
    "        run_sft_correction_pass(correction_dataset, num_epochs=1)\n",
    "        stats_sft_runs += 1\n",
    "        correction_dataset.clear()\n",
    "        print(f\"{'‚îÄ'*80}\\n\")\n",
    "    \n",
    "    # Checkpoint\n",
    "    if (step + 1) % 50 == 0:\n",
    "        checkpoint_path = f\"outputs_marooned_rl/checkpoint_step{step+1}\"\n",
    "        student_model.save_pretrained(checkpoint_path)\n",
    "        tokenizer.save_pretrained(checkpoint_path)\n",
    "        print(f\"   üíæ Checkpoint ‚Üí {checkpoint_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"   Total steps: {NUM_TRAINING_STEPS}\")\n",
    "print(f\"   SFT passes: {stats_sft_runs}\")\n",
    "print(f\"   Avg reward: {np.mean(stats_rewards):.2f}\")\n",
    "print(f\"   Final avg (10): {np.mean(stats_rewards[-10:]):.2f}\")\n",
    "print(f\"   Total corrections: {sum(stats_corrections)}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5fb0f6",
   "metadata": {},
   "source": [
    "## GPU Memory Management (Run if you get OOM errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4e5ff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ GPU Memory Cleanup Complete\n",
      "   Total VRAM: 191.69 GB\n",
      "   Allocated: 30.62 GB\n",
      "   Reserved: 30.76 GB\n",
      "   Free: 161.07 GB\n",
      "\n",
      "‚úÖ PYTORCH_CUDA_ALLOC_CONF set to 'expandable_segments:True'\n",
      "   This helps reduce memory fragmentation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Set environment variable to reduce memory fragmentation\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Check GPU memory status\n",
    "if torch.cuda.is_available():\n",
    "    gpu_props = torch.cuda.get_device_properties(0)\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    total = gpu_props.total_memory / 1024**3\n",
    "    free = total - allocated\n",
    "    \n",
    "    print(\"üßπ GPU Memory Cleanup Complete\")\n",
    "    print(f\"   Total VRAM: {total:.2f} GB\")\n",
    "    print(f\"   Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"   Reserved: {reserved:.2f} GB\")\n",
    "    print(f\"   Free: {free:.2f} GB\")\n",
    "    print(f\"\\n‚úÖ PYTORCH_CUDA_ALLOC_CONF set to 'expandable_segments:True'\")\n",
    "    print(f\"   This helps reduce memory fragmentation\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11c7418",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f7b0f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to outputs_marooned_rl/final_model\n",
      "\n",
      "To load:\n",
      "```python\n",
      "from unsloth import FastLanguageModel\n",
      "model, tokenizer = FastLanguageModel.from_pretrained('outputs_marooned_rl/final_model')\n",
      "```\n",
      "\n",
      "üéâ Training complete with hybrid RL + SFT approach!\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"outputs_marooned_rl/final_model\"\n",
    "\n",
    "student_model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"‚úÖ Model saved to {output_dir}\")\n",
    "print(f\"\\nTo load:\")\n",
    "print(f\"```python\")\n",
    "print(f\"from unsloth import FastLanguageModel\")\n",
    "print(f\"model, tokenizer = FastLanguageModel.from_pretrained('{output_dir}')\")\n",
    "print(f\"```\")\n",
    "print(f\"\\nüéâ Training complete with hybrid RL + SFT approach!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70c6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
